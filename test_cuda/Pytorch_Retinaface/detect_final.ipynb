{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f120377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "from data import cfg_mnet, cfg_re50\n",
    "from layers.functions.prior_box import PriorBox\n",
    "from utils.nms.py_cpu_nms import py_cpu_nms\n",
    "import cv2\n",
    "from models.retinaface import RetinaFace\n",
    "from utils.box_utils import decode, decode_landm\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import crop, center_crop, rotate, InterpolationMode, pad, resize\n",
    "\n",
    "try:\n",
    "    import torchinfo\n",
    "    import cv2\n",
    "except ModuleNotFoundError:\n",
    "    !pip install torchinfo\n",
    "    !pip install opencv-python-headless\n",
    "    import torchinfo\n",
    "    import cv2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf5bb58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_keys(model, pretrained_state_dict):\n",
    "    ckpt_keys = set(pretrained_state_dict.keys())\n",
    "    model_keys = set(model.state_dict().keys())\n",
    "    used_pretrained_keys = model_keys & ckpt_keys\n",
    "    unused_pretrained_keys = ckpt_keys - model_keys\n",
    "    missing_keys = model_keys - ckpt_keys\n",
    "    assert len(used_pretrained_keys) > 0, 'load NONE from pretrained checkpoint'\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d696dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix(state_dict, prefix):\n",
    "    ''' Old style model is stored with all names of parameters sharing common prefix 'module.' '''\n",
    "    f = lambda x: x.split(prefix, 1)[-1] if x.startswith(prefix) else x\n",
    "    return {f(key): value for key, value in state_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be376796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, pretrained_path, load_to_cpu):\n",
    "    print('Loading pretrained model from {}'.format(pretrained_path))\n",
    "    if load_to_cpu:\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n",
    "    else:\n",
    "        device = torch.cuda.current_device()\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))\n",
    "        print(\"Model loaded to GPU\")\n",
    "    if \"state_dict\" in pretrained_dict.keys():\n",
    "        pretrained_dict = remove_prefix(pretrained_dict['state_dict'], 'module.')\n",
    "    else:\n",
    "        pretrained_dict = remove_prefix(pretrained_dict, 'module.')\n",
    "    check_keys(model, pretrained_dict)\n",
    "    model.load_state_dict(pretrained_dict, strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8556b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_model(network=\"resnet50\"):\n",
    "    if network == \"mobile0.25\":\n",
    "        cfg = cfg_mnet\n",
    "        trained_model = \"./weights/mobilenet0.25_Final.pth\"\n",
    "    elif network == \"resnet50\":\n",
    "        cfg = cfg_re50\n",
    "        trained_model = \"./weights/Resnet50_Final.pth\"\n",
    "    # net and model\n",
    "    net = RetinaFace(cfg=cfg, phase = 'test')\n",
    "    net = load_model(net, trained_model, False)\n",
    "    net.eval()\n",
    "    cudnn.benchmark = True\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\") # Defines the computation device (cuda:0 => GPU)\n",
    "    net = net.to(device)\n",
    "    \n",
    "    return net, cfg, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84dbdc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_select(dets, selec_thresh):\n",
    "    previous_area = 0\n",
    "    max_area = 0\n",
    "    prev_coords = np.zeros_like(dets[0])\n",
    "    coords = np.zeros_like(dets[0])\n",
    "\n",
    "    for b in dets:\n",
    "        #if b[4] < selec_thresh: # Excludes lower score detections indicating possible background faces\n",
    "            #continue\n",
    "        \n",
    "        height = b[3]-b[1] #ymax-ymin\n",
    "        width = b[2]-b[0] #xmax-xmin\n",
    "    \n",
    "        b = list(map(int, b))\n",
    "        bbox_area = width*height\n",
    "        #print(len(dets))\n",
    "        \n",
    "        if len(dets) == 1: # Only one face present in the picture\n",
    "            max_area = bbox_area\n",
    "            coords[:] = b\n",
    "        else:\n",
    "            if bbox_area > previous_area:\n",
    "                previous_area = bbox_area\n",
    "                prev_coords[:] = b\n",
    "            else:\n",
    "                max_area = previous_area\n",
    "                coords [:] = prev_coords\n",
    "    face = np.append(coords, max_area)\n",
    "\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2ad9e5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_align(img, dets, selec_thresh, net, cfg, device, final_dir, save=False):\n",
    "    '''\n",
    "    b[0], b[1] is the top left corner of the bounding box\n",
    "    b[2], b[3] is the lower right corner of the bounding box\n",
    "    b[4] relates to the the score of the detection\n",
    "    b[5], b[6] is the left eye\n",
    "    b[7], b[8] is the right eye\n",
    "    b[9], b[10] is the nose\n",
    "    b[11], b[12] is the left of the mouth\n",
    "    b[13], b[14] is the right of the mouth\n",
    "    '''\n",
    "    \n",
    "    img_raw = cv2.imread(\"/test_cuda/Pytorch_Retinaface/test/4.jpg\", cv2.IMREAD_COLOR)\n",
    "    \n",
    "    face_coords = face_select(dets, selec_thresh)\n",
    "    face_coords = list(map(int, face_coords)) # Coordinates must be integers\n",
    "    \n",
    "    # -------------------- Rotation Stage ---------------------\n",
    "    left_eye = (face_coords[5], face_coords[6]) # Components: (x, y)\n",
    "    right_eye = (face_coords[7], face_coords[8])\n",
    "    if left_eye[1] > right_eye[1]:               # Right eye is higher\n",
    "        # Clock-wise rotation\n",
    "        aux_point = (right_eye[0], left_eye[1])\n",
    "        a = right_eye[0] - left_eye[0]\n",
    "        b = right_eye[1] - aux_point[1]\n",
    "        \n",
    "        cv2.line(img_raw, left_eye, right_eye, (255, 0, 0), 2)\n",
    "        cv2.line(img_raw, aux_point, right_eye, (255, 0, 0), 2)\n",
    "        cv2.line(img_raw, left_eye, aux_point, (255, 0, 0), 2)\n",
    "        \n",
    "        cv2.circle(img_raw, left_eye, 4, (0, 0, 255), cv2.FILLED)\n",
    "        cv2.circle(img_raw, right_eye, 4, (0, 0, 255), cv2.FILLED)\n",
    "        cv2.circle(img_raw, aux_point, 4, (0, 255, 0), cv2.FILLED)\n",
    "        \n",
    "        #plt.imshow(cv2.cvtColor(img_raw[face_coords[1]:face_coords[3], face_coords[0]:face_coords[2]], cv2.COLOR_BGR2RGB)) \n",
    "        #cv2.imwrite(\"/test_cuda/2.jpg\", img_raw[face_coords[1]:face_coords[3], face_coords[0]:face_coords[2]])\n",
    "        try:\n",
    "            theta = np.rad2deg(np.arctan(b/a)) # Angle of rotation in degrees\n",
    "            print(\"Right eye is higher, therefore, a counter clock-wise rotation of {} degrees is applied\".format(-theta))\n",
    "            rotated_tensor = rotate(img.squeeze(), angle=theta, interpolation=InterpolationMode.BILINEAR, center=right_eye)\n",
    "        except ZeroDivisionError:\n",
    "            print(\"Already aligned\")\n",
    "            rotated_tensor = img.squeeze()\n",
    "\n",
    "    else:                                        # Left eye is higher\n",
    "        # Counter clock-wise rotation\n",
    "        aux_point = (left_eye[0], right_eye[1])\n",
    "        a = right_eye[0] - left_eye[0]\n",
    "        b = left_eye[1] - aux_point[1]\n",
    "        \n",
    "\n",
    "        cv2.line(img_raw, left_eye, right_eye, (255, 0, 0), 2)\n",
    "        cv2.line(img_raw, aux_point, right_eye, (255, 0, 0), 2)\n",
    "        cv2.line(img_raw, left_eye, aux_point, (255, 0, 0), 2)\n",
    "        \n",
    "        cv2.circle(img_raw, left_eye, 4, (0, 0, 255), cv2.FILLED)\n",
    "        cv2.circle(img_raw, right_eye, 4, (0, 0, 255), cv2.FILLED)\n",
    "        cv2.circle(img_raw, aux_point, 4, (0, 255, 0), cv2.FILLED)\n",
    "        \n",
    "        #plt.imshow(cv2.cvtColor(img_raw[face_coords[1]:face_coords[3], face_coords[0]:face_coords[2]], cv2.COLOR_BGR2RGB))\n",
    "        #cv2.imwrite(\"/test_cuda/2.jpg\", img_raw[face_coords[1]:face_coords[3], face_coords[0]:face_coords[2]])\n",
    "        try:\n",
    "            theta = np.rad2deg(np.arctan(b/a))\n",
    "            print(\"Left eye is higher, therefore, a clock-wise rotation of {} degrees is applied\".format(-theta))\n",
    "            rotated_tensor = rotate(img.squeeze(), angle=-theta, interpolation=InterpolationMode.BILINEAR, center=left_eye)\n",
    "        except ZeroDivisionError:\n",
    "            print(\"Already aligned\")\n",
    "            rotated_tensor = img.squeeze()\n",
    "        \n",
    "    #plt.imshow(rotated_tensor.squeeze().permute(1, 2, 0).cpu().numpy().astype(int))\n",
    "    \n",
    "    loc, conf, _ = net(rotated_tensor.unsqueeze(0))  # Forward pass that gives the results <--------------\n",
    "    \n",
    "    im_height = rotated_tensor.shape[1]\n",
    "    im_width = rotated_tensor.shape[2]\n",
    "    \n",
    "    resize1 = 1\n",
    "    new_scale = torch.Tensor([rotated_tensor.shape[2], rotated_tensor.shape[1], rotated_tensor.shape[2], rotated_tensor.shape[1]])\n",
    "    new_scale = new_scale.to(device)\n",
    "    \n",
    "    new_priorbox = PriorBox(cfg, image_size=(im_height, im_width))\n",
    "    new_priors = new_priorbox.forward()\n",
    "    new_priors = new_priors.to(device)\n",
    "    new_prior_data = new_priors.data\n",
    "    \n",
    "    new_boxes = decode(loc.data.squeeze(0), new_prior_data, cfg['variance'])\n",
    "    new_boxes = new_boxes * new_scale / resize1\n",
    "    new_boxes = new_boxes.cpu().numpy() # Tensor is moved to CPU (numpy doesn't support GPU)\n",
    "    new_scores = conf.squeeze(0).data.cpu().numpy()[:, 1]\n",
    "    \n",
    "    # Score's threshold\n",
    "    confidence_threshold = 0.0004 # Default value\n",
    "    inds = np.where(new_scores > confidence_threshold)[0]\n",
    "    new_boxes = new_boxes[inds]\n",
    "    new_scores = new_scores[inds]\n",
    "    \n",
    "    # keep top-K before NMS\n",
    "    top_k = 500 # Default value\n",
    "    order = new_scores.argsort()[::-1][:top_k] # Extracts the indexes relating to the top scores\n",
    "    new_boxes = new_boxes[order] # Array [300, 4] where in each line are the coordinates\n",
    "    new_scores = new_scores[order] # Array [1, 300]\n",
    "    \n",
    "    # do NMS\n",
    "    nms_threshold = 0.0004 # Default value\n",
    "    new_dets = np.hstack((new_boxes, new_scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "    keep = py_cpu_nms(new_dets, nms_threshold)\n",
    "    new_dets = new_dets[keep, :]\n",
    "    \n",
    "    # keep top-K faster NMS\n",
    "    #keep_top_k = 500 # Default value\n",
    "    #new_dets = new_dets[:keep_top_k, :]\n",
    "    \n",
    "    #rotated_bbox = new_dets[0]\n",
    "    rotated_bbox = face_select(new_dets, selec_thresh)\n",
    "    #print(\"rotated_bbox 1\", rotated_bbox)\n",
    "    rotated_bbox = list(map(int, rotated_bbox))\n",
    "    #print(\"rotated_bbox 2\", rotated_bbox)\n",
    "    \n",
    "    \n",
    "    # -------------------- Cropping Stage ---------------------\n",
    "    crop_height = rotated_bbox[3]-rotated_bbox[1] #ymax-ymin\n",
    "    crop_width = rotated_bbox[2]-rotated_bbox[0] #xmax-xZmin\n",
    "    crop_coordinates = (rotated_bbox[1], rotated_bbox[0], crop_height, crop_width)\n",
    "    cropped_tensor = crop(rotated_tensor, *crop_coordinates)\n",
    "    \n",
    "    #plt.imshow(cropped_tensor.squeeze().permute(1, 2, 0).cpu().numpy().astype(int))\n",
    "        \n",
    "    image_array = cropped_tensor.permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    # Convert the numpy array to BGR format (required by OpenCV)\n",
    "    cropped_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(\"/test_cuda/3.jpg\", image_array)\n",
    "    \n",
    "    final_size = (160, 160)\n",
    "    #resized_tensor = resize(padded_tensor, final_size)\n",
    "    resized_tensor = resize(cropped_tensor, final_size)\n",
    "        \n",
    "    image_array = resized_tensor.permute(1,2,0).cpu().numpy()\n",
    "        \n",
    "    cv2.imwrite(\"/test_cuda/4.jpg\", image_array)\n",
    "        \n",
    "    if save == True:\n",
    "    \n",
    "        final_size = (160, 160)\n",
    "        #resized_tensor = resize(padded_tensor, final_size)\n",
    "        resized_tensor = resize(cropped_tensor, final_size)\n",
    "        \n",
    "        image_array = resized_tensor.permute(1,2,0).cpu().numpy()\n",
    "        \n",
    "        # Convert the numpy array to BGR format (required by OpenCV)\n",
    "        cropped_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        cv2.imwrite(final_dir, cropped_image)\n",
    " \n",
    "    return cropped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ac87cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/biubug6/Pytorch_Retinaface/\n",
    "def face_detection(net, cfg, device, img, final_dir, img_raw, save=False):\n",
    "    torch.set_grad_enabled(False)\n",
    "    \n",
    "    resize1 = 1\n",
    "    im_height, im_width, _ = img.shape\n",
    "    scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
    "    \n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = torch.from_numpy(img).unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    scale = scale.to(device)\n",
    "    \n",
    "    #tic = time.time()\n",
    "    loc, conf, landms = net(img)  # Forward pass that gives the results <--------------\n",
    "    #print('Forward time: {:.4f}'.format(time.time() - tic))\n",
    "        \n",
    "    priorbox = PriorBox(cfg, image_size=(im_height, im_width))\n",
    "    priors = priorbox.forward()\n",
    "    priors = priors.to(device)\n",
    "    prior_data = priors.data\n",
    "    boxes = decode(loc.data.squeeze(0), prior_data, cfg['variance'])\n",
    "    \n",
    "    boxes = boxes * scale / resize1\n",
    "    boxes = boxes.cpu().numpy() # Tensor is moved to CPU (numpy doesn't support GPU)\n",
    "    scores = conf.squeeze(0).data.cpu().numpy()[:,1]\n",
    "    landms = decode_landm(landms.data.squeeze(0), prior_data, cfg['variance'])\n",
    "    scale1 = torch.Tensor([img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                            img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                            img.shape[3], img.shape[2]])\n",
    "    scale1 = scale1.to(device)\n",
    "    landms = landms * scale1 / resize1\n",
    "    landms = landms.cpu().numpy()\n",
    "    \n",
    "    \n",
    "    # Score's threshold\n",
    "    confidence_threshold = 0.02 # Default value\n",
    "    inds = np.where(scores > confidence_threshold)[0]\n",
    "    boxes = boxes[inds]\n",
    "    landms = landms[inds]\n",
    "    scores = scores[inds]\n",
    "    \n",
    "    # keep top-K before NMS\n",
    "    top_k = 500 # Default value\n",
    "    order = scores.argsort()[::-1][:top_k] # Extracts the indexes relating to the top scores\n",
    "    boxes = boxes[order] # Array [300, 4] where in each line are the coordinates\n",
    "    landms = landms[order] # Array [300, 10]\n",
    "    scores = scores[order] # Array [1, 300]\n",
    "\n",
    "    # do NMS\n",
    "    nms_threshold = 0.04 # Default value\n",
    "    dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "    keep = py_cpu_nms(dets, nms_threshold)\n",
    "    dets = dets[keep, :]\n",
    "    landms = landms[keep]\n",
    "    \n",
    "    \n",
    "    # keep top-K faster NMS\n",
    "    keep_top_k = 750 # Default value\n",
    "    dets = dets[:keep_top_k, :]\n",
    "    landms = landms[:keep_top_k, :]\n",
    "\n",
    "    dets = np.concatenate((dets, landms), axis=1)\n",
    "    \n",
    "    for b in dets:\n",
    "        text = \"{:.4f}\".format(b[4])\n",
    "        b = list(map(int, b))\n",
    "        cv2.rectangle(img_raw, (b[0], b[1]), (b[2], b[3]), (0, 0, 255), 10)\n",
    "        cx = b[0]\n",
    "        cy = b[1] + 12\n",
    "        #cv2.circle(img_raw, (0, 0), 10, (0, 255, 0), 4)\n",
    "        #cv2.circle(img_raw, (b[0], b[1]), 1, (255, 0, 255), 4)\n",
    "        #cv2.circle(img_raw, (b[2], b[3]), 1, (255, 0, 255), 4)\n",
    "        cv2.putText(img_raw, text, (cx, cy),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255))\n",
    "        # landms\n",
    "        cv2.circle(img_raw, (b[5], b[6]), 1, (0, 0, 255), 8)\n",
    "        cv2.circle(img_raw, (b[7], b[8]), 1, (0, 255, 255), 8)\n",
    "        cv2.circle(img_raw, (b[9], b[10]), 1, (255, 0, 255), 8)\n",
    "        cv2.circle(img_raw, (b[11], b[12]), 1, (0, 255, 0), 8)\n",
    "        cv2.circle(img_raw, (b[13], b[14]), 1, (255, 0, 0), 8)\n",
    "    \n",
    "    #plt.imshow(cropped.permute(1, 2, 0).cpu().numpy().astype(int))\n",
    "    \n",
    "    \n",
    "    #cv2.imwrite(\"/test_cuda/2.jpg\", img_raw)\n",
    "    \n",
    "    \n",
    "    #plt.imshow(cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    if len(dets) == 0:\n",
    "        final_size = (160, 160)\n",
    "        resized_tensor = resize(img, final_size)\n",
    "        image_array = resized_tensor.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "        cropped_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(final_dir, cropped_image)\n",
    "        \n",
    "    else:\n",
    "        cropped = crop_align(img, dets, 0.1, net, cfg, device, final_dir, save)\n",
    "    \n",
    "    #plt.imshow(cropped.squeeze().permute(1, 2, 0).cpu().numpy().astype(int))\n",
    "    \n",
    "    if cropped.is_cuda: print(\"tensor in GPU\")\n",
    "    # show image\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b16aba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------- Splitting dataset -------------\n",
    "#from dataset_split import DatasetSplitter\n",
    "#import torchvision.io as io\n",
    "#\n",
    "#splitter = DatasetSplitter('/app/datasets/', '/app/data/', split = [80,20]) #Class isntance\n",
    "#splitter.split_dataset() #Splitting dataset into train, test (and val if needed)\n",
    "#\n",
    "#train_dir, test_dir = splitter.data_dir()\n",
    "#\n",
    "#data_transform = transforms.Compose([\n",
    "#    # Resize the images to 64x64\n",
    "#    #transforms.Resize(size=(64, 64)),\n",
    "#    # Flip the images randomly on the horizontal\n",
    "#    #transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
    "#    # Turn the image into a torch.Tensor\n",
    "#    transforms.Lambda(lambda image: torch.tensor(np.array(image).astype(np.float32)).unsqueeze(0)) # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 \n",
    "#])\n",
    "#\n",
    "#train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n",
    "#                                  transform=data_transform, # transforms to perform on data (images)\n",
    "#                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
    "#\n",
    "#test_data = datasets.ImageFolder(root=test_dir, \n",
    "#                                 transform=data_transform\n",
    "#                                )\n",
    "#\n",
    "#print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6db5b9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from ./weights/Resnet50_Final.pth\n",
      "Model loaded to GPU\n",
      "Left eye is higher, therefore, a clock-wise rotation of 4.1849161251184155 degrees is applied\n",
      "tensor in GPU\n"
     ]
    }
   ],
   "source": [
    "# Debug mode\n",
    "# Image 52 from identity 9902 results in a poor crop\n",
    "net, cfg, device = detection_model()\n",
    "file_path = \"/test_cuda/Pytorch_Retinaface/test/4.jpg\"\n",
    "final_dir = \"/test_cuda/Pytorch_Retinaface/test/4.jpg\"\n",
    "img_raw = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "#img_raw_rgb = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "img = np.float32(img_raw)\n",
    "\n",
    "face_detection(net, cfg, device, img, final_dir, img_raw, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ede1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing folder\n",
    "#root = \"/test_cuda/data\"\n",
    "dest_dir = \"/test_cuda/digiface_cropped\"\n",
    "root=\"/test_cuda/Pytorch_Retinaface/test/4.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82d01746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from ./weights/Resnet50_Final.pth\n",
      "Model loaded to GPU\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '/test_cuda/Pytorch_Retinaface/test/4.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m         os\u001b[38;5;241m.\u001b[39mmakedirs(dest_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stage \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     12\u001b[0m     data_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, stage)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m identity \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(data_path):\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/test_cuda/Pytorch_Retinaface/test/4.jpg'"
     ]
    }
   ],
   "source": [
    "net, cfg, device = detection_model()\n",
    "\n",
    "t_tic = time.time()\n",
    "\n",
    "while True:\n",
    "    if os.path.exists(dest_dir) and os.path.isdir(dest_dir):\n",
    "        break\n",
    "    else:\n",
    "        os.makedirs(dest_dir, exist_ok=True)\n",
    "                \n",
    "for stage in os.listdir(root):\n",
    "    data_path = os.path.join(root, stage)\n",
    "    for identity in os.listdir(data_path):\n",
    "        id_path = os.path.join(root, stage, identity)\n",
    "        cropped_id_path = os.path.join(dest_dir, stage, identity)\n",
    "        os.makedirs(cropped_id_path, exist_ok=True)\n",
    "        for files in os.listdir(id_path):\n",
    "            if not files.startswith('.'):\n",
    "                file_path = os.path.join(id_path, files)\n",
    "                final_dir = os.path.join(cropped_id_path, files)\n",
    "                \n",
    "                print(file_path)\n",
    "                \n",
    "                img_raw = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "                #cropped_img_raw = c_crop(img_raw, 22)\n",
    "                img_raw_rgb = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                img = np.float32(img_raw_rgb)\n",
    "                face_detection(net, cfg, device, img, final_dir, img_raw, save=False)\n",
    "                        \n",
    "print('Total time: {:.4f}'.format(time.time() - t_tic)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b97257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
