{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ff3c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "from data import cfg_mnet, cfg_re50\n",
    "from layers.functions.prior_box import PriorBox\n",
    "from utils.nms.py_cpu_nms import py_cpu_nms\n",
    "import cv2\n",
    "from models.retinaface import RetinaFace\n",
    "from utils.box_utils import decode, decode_landm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import crop\n",
    "from torchvision.transforms.functional import rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affbb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser = argparse.ArgumentParser(description='Retinaface')\n",
    "\n",
    "#parser.add_argument('-m', '--trained_model', default='./weights/Resnet50_Final.pth',type=str, help='Trained state_dict file path to open')\n",
    "#parser.add_argument('--network', default='resnet50', help='Backbone network mobile0.25 or resnet50')\n",
    "#parser.add_argument('--cpu', action=\"store_true\", default=False, help='Use cpu inference')\n",
    "#parser.add_argument('--confidence_threshold', default=0.02, type=float, help='confidence_threshold')\n",
    "#parser.add_argument('--top_k', default=5000, type=int, help='top_k')\n",
    "#parser.add_argument('--nms_threshold', default=0.4, type=float, help='nms_threshold')\n",
    "#parser.add_argument('--keep_top_k', default=750, type=int, help='keep_top_k')\n",
    "#parser.add_argument('-s', '--save_image', action=\"store_true\", default=True, help='show detection results')\n",
    "#parser.add_argument('--vis_thres', default=0.6, type=float, help='visualization_threshold')\n",
    "#args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c42f739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_keys(model, pretrained_state_dict):\n",
    "    ckpt_keys = set(pretrained_state_dict.keys())\n",
    "    model_keys = set(model.state_dict().keys())\n",
    "    used_pretrained_keys = model_keys & ckpt_keys\n",
    "    unused_pretrained_keys = ckpt_keys - model_keys\n",
    "    missing_keys = model_keys - ckpt_keys\n",
    "    #print('Missing keys:{}'.format(len(missing_keys)))\n",
    "    #print('Unused checkpoint keys:{}'.format(len(unused_pretrained_keys)))\n",
    "    #print('Used keys:{}'.format(len(used_pretrained_keys)))\n",
    "    assert len(used_pretrained_keys) > 0, 'load NONE from pretrained checkpoint'\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dbdffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix(state_dict, prefix):\n",
    "    ''' Old style model is stored with all names of parameters sharing common prefix 'module.' '''\n",
    "    #print('remove prefix \\'{}\\''.format(prefix))\n",
    "    f = lambda x: x.split(prefix, 1)[-1] if x.startswith(prefix) else x\n",
    "    return {f(key): value for key, value in state_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d05ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, pretrained_path, load_to_cpu):\n",
    "    print('Loading pretrained model from {}'.format(pretrained_path))\n",
    "    if load_to_cpu:\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n",
    "    else:\n",
    "        device = torch.cuda.current_device()\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))\n",
    "        print(\"Model loaded to GPU\")\n",
    "    if \"state_dict\" in pretrained_dict.keys():\n",
    "        pretrained_dict = remove_prefix(pretrained_dict['state_dict'], 'module.')\n",
    "    else:\n",
    "        pretrained_dict = remove_prefix(pretrained_dict, 'module.')\n",
    "    check_keys(model, pretrained_dict)\n",
    "    model.load_state_dict(pretrained_dict, strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "480420f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_select(dets, selec_thresh):\n",
    "    previous_area = 0\n",
    "    max_area = 0\n",
    "    #print(\"dets\", dets)\n",
    "    prev_coords = np.zeros_like(dets[0])\n",
    "    coords = np.zeros_like(dets[0])\n",
    "\n",
    "    for b in dets:\n",
    "        if b[4] < selec_thresh: # Excludes lower score detections indicating possible background faces\n",
    "            continue\n",
    "        \n",
    "        height = b[3]-b[1] #ymax-ymin\n",
    "        width = b[2]-b[0] #xmax-xmin\n",
    "    \n",
    "        b = list(map(int, b))\n",
    "        bbox_area = width*height\n",
    "        #print(len(dets))\n",
    "        #print(\"test\", bbox_area, previous_area)\n",
    "        \n",
    "        if len(dets) == 1: # Only one face present in the picture\n",
    "            max_area = bbox_area\n",
    "            coords[:] = b\n",
    "        else:\n",
    "            if bbox_area > previous_area:\n",
    "                previous_area = bbox_area\n",
    "                prev_coords[:] = b\n",
    "            else:\n",
    "                max_area = previous_area\n",
    "                coords [:] = prev_coords\n",
    "    face = np.append(coords, max_area)\n",
    "\n",
    "    return face\n",
    "    #if tensor is not None:\n",
    "        #percentage = 10\n",
    "        #w_margin = 1 + (percentage/100)\n",
    "        #h_margin = 1 + (percentage/100)\n",
    "    \n",
    "        #pre_crop_height = (coords[3]-coords[1]) * h_margin #ymax-ymin\n",
    "        #pre_crop_width = (coords[2]-coords[0]) * w_margin #xmax-xmin\n",
    "    \n",
    "        #pre_crop_coordinates = [int(coords[1]), int(coords[0]), int(pre_crop_height), int(pre_crop_width)]\n",
    "        #pre_cropped_tensor = crop(tensor, *pre_crop_coordinates)\n",
    "    \n",
    "        #print(\"The maximum area corresponds to the face closer to the camera and is equal to {}.\".format(max_area))\n",
    "        #return face, pre_cropped_tensor\n",
    "    #else:\n",
    "        #return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe4b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_model(network=\"resnet50\"):\n",
    "    if network == \"mobile0.25\":\n",
    "        cfg = cfg_mnet\n",
    "        trained_model = \"./weights/mobilenet0.25_Final.pth\"\n",
    "    elif network == \"resnet50\":\n",
    "        cfg = cfg_re50\n",
    "        trained_model = \"./weights/Resnet50_Final.pth\"\n",
    "    # net and model\n",
    "    net = RetinaFace(cfg=cfg, phase = 'test')\n",
    "    net = load_model(net, trained_model, False)\n",
    "    net.eval()\n",
    "    cudnn.benchmark = True\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\") # Defines the computation device (cuda:0 => GPU)\n",
    "    net = net.to(device)\n",
    "    \n",
    "    return net, cfg, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b176e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_align(img, img_name, dets, selec_thresh, net, cfg, device, save=True):\n",
    "    '''\n",
    "    b[0], b[1] is the top left corner of the bounding box\n",
    "    b[2], b[3] is the lower right corner of the bounding box\n",
    "    b[4] relates to the the score of the detection\n",
    "    b[5], b[6] is the left eye\n",
    "    b[7], b[8] is the right eye\n",
    "    b[9], b[10] is the nose\n",
    "    b[11], b[12] is the left of the mouth\n",
    "    b[13], b[14] is the right of the mouth\n",
    "    '''\n",
    "    \n",
    "    #img_raw = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    face_coords = face_select(dets, selec_thresh)\n",
    "    face_coords = list(map(int, face_coords)) # Coordinates must be integers\n",
    "    \n",
    "    \n",
    "    # -------------------- Rotation Stage ---------------------\n",
    "    left_eye = (face_coords[5], face_coords[6]) # Components: (x, y)\n",
    "    right_eye = (face_coords[7], face_coords[8])\n",
    "    if left_eye[1] > right_eye[1]:               # Right eye is higher\n",
    "        # Clock-wise rotation\n",
    "        aux_point = (right_eye[0], left_eye[1])\n",
    "        a = right_eye[0] - left_eye[0]\n",
    "        b = right_eye[1] - aux_point[1]\n",
    "        \n",
    "        #cv2.circle(img_raw, left_eye, 10, (0, 255, 0), 4)\n",
    "        #cv2.circle(img_raw, right_eye, 10, (0, 255, 0), 4)\n",
    "        #cv2.circle(img_raw, aux_point, 10, (0, 255, 0), 4)\n",
    "        \n",
    "        #cv2.line(img_raw, left_eye, right_eye, (23, 23, 23), 2)\n",
    "        #cv2.line(img_raw, aux_point, right_eye, (23, 23, 23), 2)\n",
    "        #cv2.line(img_raw, left_eye, aux_point, (23, 23, 23), 2)\n",
    "        #plt.imshow(cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)) \n",
    "        \n",
    "        theta = np.rad2deg(np.arctan(b/a)) # Angle of rotation in degrees\n",
    "        #print(\"Right eye is higher, therefore, a clock-wise rotation of {} is applied\".format(-theta))\n",
    "        rotated_tensor = rotate(img.squeeze(), angle=theta, center=right_eye)\n",
    "\n",
    "    else:                                        # Left eye is higher\n",
    "        # Counter clock-wise rotation\n",
    "        aux_point = (left_eye[0], right_eye[1])\n",
    "        a = right_eye[0] - left_eye[0]\n",
    "        b = left_eye[1] - aux_point[1]\n",
    "        \n",
    "        #cv2.circle(img_raw, left_eye, 10, (0, 255, 0), 4)\n",
    "        #cv2.circle(img_raw, right_eye, 10, (0, 255, 0), 4)\n",
    "        #cv2.circle(img_raw, aux_point, 10, (0, 255, 0), 4)\n",
    "        \n",
    "        #plt.imshow(img_raw)\n",
    "        \n",
    "        theta = np.rad2deg(np.arctan(b/a))\n",
    "        #print(\"Left eye is higher, therefore, a clock-wise rotation of {} degrees is applied\".format(-theta))\n",
    "        rotated_tensor = rotate(img.squeeze(), angle=-theta, center=left_eye)\n",
    "        \n",
    "    #plt.imshow(rotated_tensor.squeeze().permute(1, 2, 0).cpu().numpy().astype(int))\n",
    "    \n",
    "    # -------------------- New Bounding Box computing ---------------------\n",
    "    # The image is rotated, a new bbox must be generated. \n",
    "    \n",
    "    # TBD: optimization by performing a preliminary crop in order to try and isolate only the relevant face\n",
    "    \n",
    "    loc, conf, _ = net(rotated_tensor.unsqueeze(0))  # Forward pass that gives the results <--------------\n",
    "    \n",
    "    im_height = rotated_tensor.shape[1]\n",
    "    im_width = rotated_tensor.shape[2]\n",
    "    \n",
    "    resize = 1\n",
    "    new_scale = torch.Tensor([rotated_tensor.shape[2], rotated_tensor.shape[1], rotated_tensor.shape[2], rotated_tensor.shape[1]])\n",
    "    new_scale = new_scale.to(device)\n",
    "    \n",
    "    new_priorbox = PriorBox(cfg, image_size=(im_height, im_width))\n",
    "    new_priors = new_priorbox.forward()\n",
    "    new_priors = new_priors.to(device)\n",
    "    new_prior_data = new_priors.data\n",
    "    \n",
    "    new_boxes = decode(loc.data.squeeze(0), new_prior_data, cfg['variance'])\n",
    "    new_boxes = new_boxes * new_scale / resize\n",
    "    new_boxes = new_boxes.cpu().numpy() # Tensor is moved to CPU (numpy doesn't support GPU)\n",
    "    new_scores = conf.squeeze(0).data.cpu().numpy()[:, 1]\n",
    "\n",
    "    # Score's threshold\n",
    "    confidence_threshold = 0.02 # Default value\n",
    "    inds = np.where(new_scores > confidence_threshold)[0]\n",
    "    new_boxes = new_boxes[inds]\n",
    "    new_scores = new_scores[inds]\n",
    "\n",
    "    # keep top-K before NMS\n",
    "    top_k = 500 # Default value\n",
    "    order = new_scores.argsort()[::-1][:top_k] # Extracts the indexes relating to the top scores\n",
    "    new_boxes = new_boxes[order] # Array [300, 4] where in each line are the coordinates\n",
    "    new_scores = new_scores[order] # Array [1, 300]\n",
    "    \n",
    "    # do NMS\n",
    "    nms_threshold = 0.4 # Default value\n",
    "    new_dets = np.hstack((new_boxes, new_scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "    keep = py_cpu_nms(new_dets, nms_threshold)\n",
    "    new_dets = new_dets[keep, :]\n",
    "\n",
    "    # keep top-K faster NMS\n",
    "    #keep_top_k = 500 # Default value\n",
    "    #new_dets = new_dets[:keep_top_k, :]\n",
    "    \n",
    "    #rotated_bbox = new_dets[0]\n",
    "    rotated_bbox = face_select(new_dets, selec_thresh)\n",
    "    #print(\"rotated_bbox 1\", rotated_bbox)\n",
    "    rotated_bbox = list(map(int, rotated_bbox))\n",
    "    #print(\"rotated_bbox 2\", rotated_bbox)\n",
    "    \n",
    "    \n",
    "    # -------------------- Cropping Stage ---------------------\n",
    "    crop_height = rotated_bbox[3]-rotated_bbox[1] #ymax-ymin\n",
    "    crop_width = rotated_bbox[2]-rotated_bbox[0] #xmax-xZmin\n",
    "    crop_coordinates = (rotated_bbox[1], rotated_bbox[0], crop_height, crop_width)\n",
    "    cropped_tensor = crop(rotated_tensor, *crop_coordinates)\n",
    "    \n",
    "    image_array = cropped_tensor.permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    # Convert the numpy array to BGR format (required by OpenCV)\n",
    "    cropped_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    if save == True:\n",
    "        new_name = \"cropped_\" + img_name\n",
    "        if not os.path.exists(\"cropped/\"):\n",
    "            print(\"Result's directory created!\")\n",
    "            os.makedirs(\"cropped/\")\n",
    "        new_name = \"cropped/\" + new_name\n",
    "        cv2.imwrite(new_name, cropped_image)\n",
    "    return cropped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed2b9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/biubug6/Pytorch_Retinaface/\n",
    "def face_detection(net, cfg, device, img, img_name):\n",
    "    save_image = False\n",
    "    torch.set_grad_enabled(False)\n",
    "    \n",
    "    resize = 1\n",
    "\n",
    "    # Testing stage\n",
    "\n",
    "    im_height, im_width, _ = img.shape\n",
    "    scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
    "\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = torch.from_numpy(img).unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    scale = scale.to(device)\n",
    "    \n",
    "    print(img.shape)\n",
    "    tic = time.time()\n",
    "    loc, conf, landms = net(img)  # Forward pass that gives the results <--------------\n",
    "    print('Forward time: {:.4f}'.format(time.time() - tic))\n",
    "        \n",
    "    priorbox = PriorBox(cfg, image_size=(im_height, im_width))\n",
    "    print(priorbox)\n",
    "    priors = priorbox.forward()\n",
    "    priors = priors.to(device)\n",
    "    prior_data = priors.data\n",
    "    boxes = decode(loc.data.squeeze(0), prior_data, cfg['variance'])\n",
    "    \n",
    "    boxes = boxes * scale / resize\n",
    "    boxes = boxes.cpu().numpy() # Tensor is moved to CPU (numpy doesn't support GPU)\n",
    "    scores = conf.squeeze(0).data.cpu().numpy()[:, 1]\n",
    "    landms = decode_landm(landms.data.squeeze(0), prior_data, cfg['variance'])\n",
    "    scale1 = torch.Tensor([img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                            img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                            img.shape[3], img.shape[2]])\n",
    "    scale1 = scale1.to(device)\n",
    "    landms = landms * scale1 / resize\n",
    "    landms = landms.cpu().numpy()\n",
    "\n",
    "    # Score's threshold\n",
    "    confidence_threshold = 0.02 # Default value\n",
    "    inds = np.where(scores > confidence_threshold)[0]\n",
    "    boxes = boxes[inds]\n",
    "    landms = landms[inds]\n",
    "    scores = scores[inds]\n",
    "\n",
    "    # keep top-K before NMS\n",
    "    top_k = 500 # Default value\n",
    "    order = scores.argsort()[::-1][:top_k] # Extracts the indexes relating to the top scores\n",
    "    boxes = boxes[order] # Array [300, 4] where in each line are the coordinates\n",
    "    landms = landms[order] # Array [300, 10]\n",
    "    scores = scores[order] # Array [1, 300]\n",
    "\n",
    "    # do NMS\n",
    "    print(boxes, boxes.shape)\n",
    "    print(\"\")\n",
    "    print(scores, scores.shape)\n",
    "    nms_threshold = 0.4 # Default value\n",
    "    dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "    keep = py_cpu_nms(dets, nms_threshold)\n",
    "    dets = dets[keep, :]\n",
    "    landms = landms[keep]\n",
    "\n",
    "    # keep top-K faster NMS\n",
    "    #keep_top_k = 750 # Default value\n",
    "    #dets = dets[:keep_top_k, :]\n",
    "    #landms = landms[:keep_top_k, :]\n",
    "        \n",
    "    dets = np.concatenate((dets, landms), axis=1)\n",
    "\n",
    "    cropped = crop_align(img, img_name, dets, 0.1, net, cfg, device, save=False)\n",
    "    \n",
    "    #if cropped.is_cuda: print(\"tensor in GPU\")\n",
    "\n",
    "        # show image\n",
    "        #vis_thres = 0.6\n",
    "        #for b in dets:\n",
    "            #if b[4] < vis_thres:\n",
    "                #continue\n",
    "            #text = \"{:.4f}\".format(b[4])\n",
    "            #b = list(map(int, b))\n",
    "            #cv2.rectangle(img_raw, (b[0], b[1]), (b[2], b[3]), (0, 0, 255), 2)\n",
    "            #cx = b[0]\n",
    "            #cy = b[1] + 12\n",
    "            #cv2.circle(img_raw, (0, 0), 10, (0, 255, 0), 4)\n",
    "            #cv2.circle(img_raw, (b[0], b[1]), 1, (255, 0, 255), 4)\n",
    "            #cv2.circle(img_raw, (b[2], b[3]), 1, (255, 0, 255), 4)\n",
    "            #cv2.putText(img_raw, text, (cx, cy),\n",
    "                        #cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 255, 255))\n",
    "\n",
    "            # landms\n",
    "            #cv2.circle(img_raw, (b[5], b[6]), 1, (0, 0, 255), 4)\n",
    "            #cv2.circle(img_raw, (b[7], b[8]), 1, (0, 255, 255), 4)\n",
    "            #cv2.circle(img_raw, (b[9], b[10]), 1, (255, 0, 255), 4)\n",
    "            #cv2.circle(img_raw, (b[11], b[12]), 1, (0, 255, 0), 4)\n",
    "            #cv2.circle(img_raw, (b[13], b[14]), 1, (255, 0, 0), 4)\n",
    "        \n",
    "    \n",
    "    #plt.imshow(cropped.permute(1, 2, 0).cpu().numpy().astype(int))\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ab01f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  78\n",
      "Loading pretrained model from ./weights/Resnet50_Final.pth\n",
      "Model loaded to GPU\n",
      "test [[[244. 239. 234.]\n",
      "  [244. 240. 234.]\n",
      "  [245. 241. 236.]\n",
      "  ...\n",
      "  [241. 237. 233.]\n",
      "  [243. 239. 234.]\n",
      "  [243. 239. 235.]]\n",
      "\n",
      " [[239. 234. 227.]\n",
      "  [239. 233. 226.]\n",
      "  [241. 236. 229.]\n",
      "  ...\n",
      "  [240. 235. 230.]\n",
      "  [241. 236. 230.]\n",
      "  [241. 236. 231.]]\n",
      "\n",
      " [[237. 231. 224.]\n",
      "  [238. 232. 224.]\n",
      "  [239. 234. 227.]\n",
      "  ...\n",
      "  [240. 235. 228.]\n",
      "  [242. 237. 231.]\n",
      "  [240. 234. 228.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 87.  75.  52.]\n",
      "  [ 94.  82.  57.]\n",
      "  [103.  92.  64.]\n",
      "  ...\n",
      "  [172. 165. 128.]\n",
      "  [165. 158. 121.]\n",
      "  [162. 154. 117.]]\n",
      "\n",
      " [[ 88.  77.  52.]\n",
      "  [100.  89.  61.]\n",
      "  [112. 101.  71.]\n",
      "  ...\n",
      "  [165. 158. 122.]\n",
      "  [159. 151. 115.]\n",
      "  [159. 150. 115.]]\n",
      "\n",
      " [[ 96.  85.  58.]\n",
      "  [109.  99.  69.]\n",
      "  [124. 114.  81.]\n",
      "  ...\n",
      "  [156. 148. 114.]\n",
      "  [153. 143. 110.]\n",
      "  [153. 143. 109.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0042\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f1f0>\n",
      "[[ 26.811901   18.638924  102.43434   108.559944 ]\n",
      " [ 27.775757   18.73256   102.045586  109.519295 ]\n",
      " [ 26.796385   18.327179  102.663216  107.78265  ]\n",
      " [ 27.059853   17.011404  102.722374  108.751366 ]\n",
      " [ 27.559847   17.618298  101.49171   109.61173  ]\n",
      " [ 27.370903   21.013638  101.7436    107.01709  ]\n",
      " [ 28.734339   17.744537  101.53546   110.77361  ]\n",
      " [ 27.392582   17.341074  100.92894   109.49985  ]\n",
      " [ 26.152958   16.558945  101.765175  107.67913  ]\n",
      " [ 27.510479   16.97835   100.96993   106.60492  ]\n",
      " [ 25.969269   17.175846  101.36823   107.74327  ]\n",
      " [ 26.377747   16.041119  102.22917   109.43113  ]\n",
      " [ 26.515835   16.09934   100.71188   106.66037  ]\n",
      " [ 27.132927   19.495623  101.27196   107.95574  ]\n",
      " [ 25.356726   16.226402  100.71989   106.60455  ]\n",
      " [ 25.521448   16.244888  101.81586   106.5755   ]\n",
      " [ 25.74858    13.882387  100.4059    109.09811  ]\n",
      " [ 26.649632   16.532925  101.50858   108.54175  ]\n",
      " [ 26.880735   16.718851  101.461365  109.482376 ]\n",
      " [ 26.750969   15.751612  101.67469   110.737526 ]\n",
      " [ 26.698334   21.140144  104.9305    106.37961  ]\n",
      " [ 26.314083   21.403664  100.67684   110.48895  ]\n",
      " [ 25.54187    18.376673  102.829025  108.00906  ]\n",
      " [ 26.730713   16.381386  101.691826  108.57092  ]\n",
      " [ 26.977186   20.555897  103.949814  107.37473  ]\n",
      " [ 26.428549   15.812531  102.73996   106.79086  ]\n",
      " [ 25.747696   19.420675  102.79796   108.45849  ]\n",
      " [ 26.403187   19.534683   99.56923   109.998276 ]\n",
      " [ 26.20918    10.24414   100.91936   110.385124 ]\n",
      " [ 27.490599   11.838852  103.28382   110.48538  ]\n",
      " [ 25.46381    10.883991  101.00227   109.05032  ]\n",
      " [ 24.721304   11.449371   98.93538   109.94895  ]\n",
      " [ 31.075535    7.169243  101.39654   108.03501  ]\n",
      " [ 25.993645    3.459138  102.98434   109.92968  ]\n",
      " [ 30.983557   12.224329  105.84643   107.43067  ]\n",
      " [ 25.051891    7.1423864 105.026886  109.90273  ]\n",
      " [ 24.781858    7.5583773 104.46292   110.29718  ]\n",
      " [ 28.520529    7.5406866  96.94713   106.054474 ]\n",
      " [ 30.395906   28.235447  106.09247   109.274994 ]\n",
      " [ 26.4179      1.1319184 103.592125  111.12245  ]] (40, 4)\n",
      "\n",
      "[0.99814224 0.9973023  0.9954266  0.9947819  0.9726219  0.95007765\n",
      " 0.943909   0.9428662  0.93443054 0.9097775  0.9095569  0.9047179\n",
      " 0.899876   0.89148897 0.8866083  0.86634713 0.8198825  0.78091717\n",
      " 0.73660874 0.68597895 0.59923905 0.57182497 0.5206442  0.5084951\n",
      " 0.46187103 0.45430347 0.4437529  0.40175837 0.25097743 0.15958005\n",
      " 0.12035592 0.05316161 0.04294338 0.03424969 0.02850102 0.02837108\n",
      " 0.02416398 0.02301469 0.02266252 0.02265169] (40,)\n",
      "Tensor in gpu\n",
      "test [[[162. 121.  73.]\n",
      "  [164. 123.  74.]\n",
      "  [162. 121.  73.]\n",
      "  ...\n",
      "  [ 30.  37.  15.]\n",
      "  [ 30.  39.  15.]\n",
      "  [ 34.  43.  16.]]\n",
      "\n",
      " [[158. 118.  70.]\n",
      "  [161. 121.  72.]\n",
      "  [164. 122.  74.]\n",
      "  ...\n",
      "  [ 31.  40.  15.]\n",
      "  [ 34.  43.  15.]\n",
      "  [ 38.  48.  16.]]\n",
      "\n",
      " [[156. 116.  69.]\n",
      "  [157. 115.  68.]\n",
      "  [160. 118.  69.]\n",
      "  ...\n",
      "  [ 33.  44.  16.]\n",
      "  [ 36.  47.  16.]\n",
      "  [ 41.  52.  17.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[112.  35.  33.]\n",
      "  [113.  35.  33.]\n",
      "  [111.  35.  33.]\n",
      "  ...\n",
      "  [133. 129. 123.]\n",
      "  [133. 129. 122.]\n",
      "  [133. 129. 122.]]\n",
      "\n",
      " [[112.  34.  32.]\n",
      "  [113.  35.  32.]\n",
      "  [111.  34.  32.]\n",
      "  ...\n",
      "  [134. 130. 124.]\n",
      "  [134. 130. 123.]\n",
      "  [133. 130. 123.]]\n",
      "\n",
      " [[111.  34.  32.]\n",
      "  [109.  32.  30.]\n",
      "  [108.  32.  30.]\n",
      "  ...\n",
      "  [135. 131. 125.]\n",
      "  [135. 131. 125.]\n",
      "  [134. 131. 124.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f3d0>\n",
      "[[  4.929195   17.882412   81.39349   108.80176  ]\n",
      " [  4.4711437  17.041824   81.60286   108.844284 ]\n",
      " [  4.085781   18.452606   83.08106   109.02673  ]\n",
      " [  3.9671068  18.179317   83.06296   107.59089  ]\n",
      " [  5.506935   20.68534    81.23505   107.83272  ]\n",
      " [  4.8481083  18.312973   82.47805   109.20354  ]\n",
      " [  5.265975   17.614119   82.73329   107.62664  ]\n",
      " [  5.132227   17.408419   80.521965  106.96337  ]\n",
      " [  4.84458    19.573845   81.41107   108.7669   ]\n",
      " [  5.142948   16.587109   82.21612   108.4435   ]\n",
      " [  4.752592   16.985907   80.51383   108.04185  ]\n",
      " [  3.9920673  17.289696   82.00034   107.11057  ]\n",
      " [  4.4703393  18.099934   81.23875   109.07968  ]\n",
      " [  4.9333706  17.931946   80.58799   106.48213  ]\n",
      " [  4.554517   16.52934    81.59374   108.711914 ]\n",
      " [  5.474064   21.932234   83.155876  108.487434 ]\n",
      " [  5.5730014  14.950863   82.76495   109.95525  ]\n",
      " [  4.3373356  17.412317   82.27533   107.72202  ]\n",
      " [  4.374626   17.792841   81.51126   106.249664 ]\n",
      " [  5.2857184  17.540686   81.16438   107.24039  ]\n",
      " [  3.018714   17.038788   81.174866  109.5392   ]\n",
      " [  5.44164    14.933873   81.52674   107.423775 ]\n",
      " [  4.638851   19.264393   81.884445  107.24641  ]\n",
      " [  2.848136   15.6930065  77.697784  109.01849  ]\n",
      " [  5.2154164  19.991058   80.61062   107.17673  ]\n",
      " [  2.9147363  15.229778   78.95915   109.45511  ]\n",
      " [  5.1584725  19.433832   79.9532    106.097984 ]\n",
      " [  5.6972466  18.811068   83.23129   108.3408   ]\n",
      " [  1.7403836  10.469939   80.67975   109.03018  ]\n",
      " [  3.544794   23.282625   80.0049    109.78406  ]\n",
      " [  8.835703   19.852564   83.61346   107.11141  ]\n",
      " [  2.0282474  14.981968   79.82123   108.88132  ]\n",
      " [  7.6980033  22.79385    85.49561   106.506165 ]\n",
      " [ -0.3914609  20.02084    77.346924  111.260925 ]\n",
      " [  2.0173993   8.563841   81.81182   107.92423  ]\n",
      " [  9.015276    9.673136   84.419205  109.3969   ]\n",
      " [  6.830724    9.641926   80.24297   110.96635  ]\n",
      " [  2.403129    9.880289   83.039055  109.820206 ]\n",
      " [  1.9155412   8.66381    83.60027   110.7015   ]\n",
      " [  8.706171   13.599644   85.278534  109.99689  ]] (40, 4)\n",
      "\n",
      "[0.9991049  0.9989993  0.9967211  0.9941537  0.97460836 0.97299284\n",
      " 0.96896374 0.9602436  0.95920515 0.95370936 0.95127344 0.9446468\n",
      " 0.93550646 0.9211935  0.9201219  0.88969505 0.8875364  0.86815226\n",
      " 0.86729634 0.8564011  0.8365765  0.7092311  0.6927166  0.64732367\n",
      " 0.6256588  0.61979806 0.6112856  0.457258   0.27380738 0.23454179\n",
      " 0.22984333 0.19729635 0.17938894 0.09127502 0.08034019 0.0647262\n",
      " 0.05804382 0.05603991 0.05112674 0.02897011] (40,)\n",
      "Tensor in gpu\n",
      "test [[[ 64.  84.  77.]\n",
      "  [ 63.  80.  65.]\n",
      "  [ 63.  77.  52.]\n",
      "  ...\n",
      "  [139.  96.  53.]\n",
      "  [137.  93.  51.]\n",
      "  [131.  88.  48.]]\n",
      "\n",
      " [[ 62.  78.  59.]\n",
      "  [ 61.  74.  44.]\n",
      "  [ 60.  72.  33.]\n",
      "  ...\n",
      "  [138.  94.  52.]\n",
      "  [140.  96.  53.]\n",
      "  [133.  90.  49.]]\n",
      "\n",
      " [[ 61.  73.  38.]\n",
      "  [ 60.  71.  30.]\n",
      "  [ 60.  70.  26.]\n",
      "  ...\n",
      "  [137.  93.  51.]\n",
      "  [137.  93.  51.]\n",
      "  [131.  88.  48.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[175. 160. 136.]\n",
      "  [175. 161. 137.]\n",
      "  [176. 162. 138.]\n",
      "  ...\n",
      "  [ 40.  10.  10.]\n",
      "  [ 40.   8.  10.]\n",
      "  [ 42.   8.  10.]]\n",
      "\n",
      " [[176. 162. 137.]\n",
      "  [176. 162. 137.]\n",
      "  [176. 161. 137.]\n",
      "  ...\n",
      "  [ 40.   8.  10.]\n",
      "  [ 41.   9.  11.]\n",
      "  [ 44.  10.  12.]]\n",
      "\n",
      " [[175. 161. 137.]\n",
      "  [175. 161. 136.]\n",
      "  [176. 162. 137.]\n",
      "  ...\n",
      "  [ 43.   9.  11.]\n",
      "  [ 45.  10.  13.]\n",
      "  [ 63.  15.  17.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f2b0>\n",
      "[[ 33.885746  24.239304 102.81644  103.71086 ]\n",
      " [ 33.37774   24.623257 102.251625 103.95572 ]\n",
      " [ 33.934002  25.031998 103.55757  104.0685  ]\n",
      " [ 35.714222  24.141474 102.37966  104.45467 ]\n",
      " [ 33.638252  27.467113 102.22355  103.39947 ]\n",
      " [ 35.12461   22.304764 101.957405 104.78127 ]\n",
      " [ 33.11435   25.479057 103.82468  105.364265]\n",
      " [ 33.199867  23.434332 102.588036 104.00037 ]\n",
      " [ 33.34547   27.672836 101.74838  104.44588 ]\n",
      " [ 35.538666  20.929955 101.76197  103.73382 ]\n",
      " [ 31.200294  19.710758 102.11067  103.67783 ]\n",
      " [ 31.822948  20.015745 101.841835 104.44837 ]\n",
      " [ 33.245655  18.77985  103.61393  104.44521 ]\n",
      " [ 32.59506   19.620783 101.66852  103.3015  ]\n",
      " [ 31.772575  28.056437  99.53326  104.46762 ]\n",
      " [ 30.883404  19.730429 102.550186 103.74974 ]\n",
      " [ 32.354305  20.768602 102.57785  105.10199 ]\n",
      " [ 31.307224  16.790245 102.20879  106.17364 ]\n",
      " [ 30.554909  19.68665  102.78202  104.48373 ]\n",
      " [ 33.13672   18.33765  104.3927   102.52704 ]\n",
      " [ 30.613157  18.580257 102.87721  104.35043 ]\n",
      " [ 31.729004  18.243938 105.110695 104.509094]\n",
      " [ 31.787376  16.634573 102.46411  103.66815 ]\n",
      " [ 35.111496  31.118256 104.70812  106.55167 ]\n",
      " [ 34.85777   16.448341 105.68623  106.02189 ]\n",
      " [ 30.732075  22.333017 105.659424 104.28215 ]\n",
      " [ 31.609152  15.064341 101.79679  107.856   ]\n",
      " [ 31.917747  24.456411 104.34118  106.91751 ]\n",
      " [ 31.805862  22.943497  97.31809  102.46026 ]\n",
      " [ 35.38654   16.290173 104.77881  108.862625]\n",
      " [ 35.57039   11.511639 101.89057  105.49135 ]\n",
      " [ 30.719355  20.854519 104.79624  104.066734]\n",
      " [ 29.205635  22.289421 102.76406  105.00713 ]\n",
      " [ 31.153437  10.239758 101.9307   107.567505]] (34, 4)\n",
      "\n",
      "[0.9983115  0.9981559  0.9938292  0.99030274 0.98110104 0.9606314\n",
      " 0.92116386 0.9052297  0.8009292  0.7519211  0.34751457 0.3073662\n",
      " 0.3061287  0.29427907 0.27703452 0.25918812 0.23267277 0.22680286\n",
      " 0.22146322 0.21100831 0.20667878 0.16598305 0.13354446 0.12968099\n",
      " 0.1295989  0.12677832 0.12337986 0.09739786 0.09687848 0.09116689\n",
      " 0.07759427 0.06440338 0.04971816 0.02391935] (34,)\n",
      "Tensor in gpu\n",
      "test [[[193. 198. 206.]\n",
      "  [189. 194. 202.]\n",
      "  [168. 171. 178.]\n",
      "  ...\n",
      "  [214. 216. 218.]\n",
      "  [214. 217. 218.]\n",
      "  [215. 217. 219.]]\n",
      "\n",
      " [[194. 198. 205.]\n",
      "  [183. 186. 194.]\n",
      "  [146. 146. 150.]\n",
      "  ...\n",
      "  [213. 216. 217.]\n",
      "  [214. 216. 218.]\n",
      "  [213. 215. 217.]]\n",
      "\n",
      " [[193. 197. 203.]\n",
      "  [172. 175. 180.]\n",
      "  [158. 159. 162.]\n",
      "  ...\n",
      "  [213. 215. 217.]\n",
      "  [213. 215. 217.]\n",
      "  [213. 215. 217.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 23.  26.  17.]\n",
      "  [ 23.  26.  17.]\n",
      "  [ 24.  27.  17.]\n",
      "  ...\n",
      "  [ 50.  49.  36.]\n",
      "  [ 49.  49.  36.]\n",
      "  [ 48.  48.  35.]]\n",
      "\n",
      " [[ 23.  25.  16.]\n",
      "  [ 23.  26.  17.]\n",
      "  [ 23.  26.  17.]\n",
      "  ...\n",
      "  [ 49.  49.  35.]\n",
      "  [ 48.  48.  35.]\n",
      "  [ 47.  47.  35.]]\n",
      "\n",
      " [[ 22.  24.  16.]\n",
      "  [ 22.  25.  16.]\n",
      "  [ 23.  26.  16.]\n",
      "  ...\n",
      "  [ 48.  49.  34.]\n",
      "  [ 46.  48.  34.]\n",
      "  [ 46.  47.  34.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f2e0>\n",
      "[[ 12.93873     10.273075    94.05175    106.735756  ]\n",
      " [ 12.4655285   10.722822    93.56035    106.22063   ]\n",
      " [ 12.919101    12.641041    93.418076   106.84685   ]\n",
      " [ 13.916677    11.07494     92.900955   107.90924   ]\n",
      " [ 12.362009    12.310429    93.93362    106.57093   ]\n",
      " [ 12.927181     9.681761    92.906975   105.326256  ]\n",
      " [ 12.50613     11.8537655   91.6324     105.01207   ]\n",
      " [ 11.74172     10.912577    91.975586   105.104385  ]\n",
      " [ 12.181503     9.587362    91.15235    104.81915   ]\n",
      " [ 12.750181    10.011264    92.32186    104.36377   ]\n",
      " [ 12.048336     9.359767    91.98918    106.576355  ]\n",
      " [ 13.418989    12.046888    93.492584   104.82928   ]\n",
      " [ 11.925751     9.899432    93.8746     105.55623   ]\n",
      " [ 13.34577      9.817137    92.40872    105.18208   ]\n",
      " [ 13.113321    10.027208    94.431145   107.23192   ]\n",
      " [ 13.277229    11.131746    92.96581    106.15924   ]\n",
      " [ 13.38858     10.245041    90.67056    106.84843   ]\n",
      " [ 12.359662    10.810305    94.31585    105.047516  ]\n",
      " [ 13.613603    11.562918    94.37049    105.63386   ]\n",
      " [ 12.614658    11.498384    93.701385   106.22856   ]\n",
      " [ 13.504671     7.5116405   92.25226    106.794556  ]\n",
      " [ 14.217304    15.230582    93.24482    105.96416   ]\n",
      " [ 14.824919     8.871078    92.667145   108.27761   ]\n",
      " [ 13.89888      9.201843    92.60776    106.67144   ]\n",
      " [ 13.763363    12.03805     93.15189    107.12808   ]\n",
      " [ 14.20406      6.313162    92.01213    109.36137   ]\n",
      " [ 12.558418    12.180072    92.43686    104.84191   ]\n",
      " [ 13.451142    12.134977    93.60731    104.97905   ]\n",
      " [ 12.263485     6.2643356   94.27377    107.19479   ]\n",
      " [ 16.19         5.4944715   92.70519    109.96648   ]\n",
      " [ 11.640894    16.145866    91.869415   107.51816   ]\n",
      " [ 12.62832      5.9965825   90.4985     108.5215    ]\n",
      " [ 12.000028     5.47112     93.535255   107.38251   ]\n",
      " [ 11.864938    13.110577    92.21739    105.212234  ]\n",
      " [  7.768075     4.601861    91.5992     108.02005   ]\n",
      " [ 16.098166    18.50295     95.71977    109.62001   ]\n",
      " [  8.980666     3.261877    94.19689    107.149086  ]\n",
      " [  9.465179    20.296402    89.74098    105.631805  ]\n",
      " [ 15.396097    12.484985    97.9314     113.13911   ]\n",
      " [  9.303477    17.174288    89.068535   104.6503    ]\n",
      " [ 13.391942     3.23216     91.2915     105.75398   ]\n",
      " [  6.239809     6.613379    90.844376   107.73425   ]\n",
      " [  3.7990422    0.66402054  89.519966   108.629074  ]\n",
      " [ 13.517542    -1.7665758   95.290405   111.34422   ]\n",
      " [ 18.592001    -1.7706213   98.27397    109.60851   ]] (45, 4)\n",
      "\n",
      "[0.997593   0.9952767  0.9942795  0.99297076 0.9890954  0.9884017\n",
      " 0.98444885 0.9828655  0.98084635 0.9805474  0.97746605 0.9713695\n",
      " 0.9694624  0.9626555  0.9626227  0.96259135 0.9595011  0.9372008\n",
      " 0.93014216 0.9296     0.91987836 0.8433564  0.7997406  0.7739759\n",
      " 0.75758964 0.7303011  0.7294207  0.6871888  0.5006718  0.46909207\n",
      " 0.37288263 0.36643532 0.2916576  0.25256598 0.11975971 0.07315084\n",
      " 0.07250599 0.06936771 0.05769002 0.04036944 0.03781934 0.0341096\n",
      " 0.02414087 0.02176379 0.02170807] (45,)\n",
      "Tensor in gpu\n",
      "test [[[10.  8.  9.]\n",
      "  [ 9.  7.  8.]\n",
      "  [ 9.  7.  8.]\n",
      "  ...\n",
      "  [10.  8.  9.]\n",
      "  [10.  8.  9.]\n",
      "  [10.  8.  9.]]\n",
      "\n",
      " [[ 9.  7.  8.]\n",
      "  [ 9.  7.  8.]\n",
      "  [ 9.  7.  8.]\n",
      "  ...\n",
      "  [10.  8.  9.]\n",
      "  [10.  8.  9.]\n",
      "  [10.  8.  9.]]\n",
      "\n",
      " [[ 9.  7.  8.]\n",
      "  [ 9.  7.  8.]\n",
      "  [ 9.  7.  8.]\n",
      "  ...\n",
      "  [10.  8.  9.]\n",
      "  [10.  8.  9.]\n",
      "  [10.  8.  9.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[18. 22. 25.]\n",
      "  [16. 20. 23.]\n",
      "  [15. 19. 22.]\n",
      "  ...\n",
      "  [12.  8.  7.]\n",
      "  [10.  9.  7.]\n",
      "  [10.  9.  7.]]\n",
      "\n",
      " [[17. 21. 24.]\n",
      "  [16. 20. 23.]\n",
      "  [15. 19. 22.]\n",
      "  ...\n",
      "  [10.  9.  7.]\n",
      "  [10.  9.  7.]\n",
      "  [10.  9.  7.]]\n",
      "\n",
      " [[17. 21. 24.]\n",
      "  [16. 20. 23.]\n",
      "  [15. 19. 22.]\n",
      "  ...\n",
      "  [10.  9.  7.]\n",
      "  [10.  9.  7.]\n",
      "  [10.  9.  7.]]] (1000, 1500, 3)\n",
      "torch.Size([1, 3, 1000, 1500])\n",
      "Forward time: 0.0042\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f400>\n",
      "[[312.92786   84.181625 646.1271   567.4666  ]\n",
      " [314.11792   87.598    650.7001   555.49243 ]\n",
      " [311.74747   88.8623   648.7727   557.9231  ]\n",
      " [311.6636    92.94116  649.03217  556.1237  ]\n",
      " [312.35437   88.48931  648.0374   562.25385 ]\n",
      " [312.5072    93.67774  643.00116  571.4741  ]\n",
      " [313.92218   92.15261  648.5644   554.31805 ]\n",
      " [312.904     94.42828  641.3681   556.285   ]\n",
      " [315.11694   93.527435 638.86127  552.62805 ]\n",
      " [314.34177   91.97482  634.0746   557.8002  ]\n",
      " [318.27026   96.54672  640.4173   555.89514 ]\n",
      " [314.11664   90.14642  640.74835  559.9501  ]\n",
      " [319.74982   89.76689  640.3456   549.88586 ]\n",
      " [310.742     96.5405   647.61096  556.1767  ]\n",
      " [315.4841    91.81857  638.7115   553.4223  ]\n",
      " [313.90445   92.6065   640.422    559.7378  ]\n",
      " [315.12622   91.634735 636.01776  565.3305  ]\n",
      " [310.6011    93.87393  644.98157  567.1372  ]\n",
      " [315.54782   91.68501  638.70337  557.2638  ]\n",
      " [313.11465   92.40742  635.97766  554.0283  ]\n",
      " [315.1805    92.666435 638.589    564.54425 ]\n",
      " [316.0531    93.196526 638.49384  550.2956  ]\n",
      " [315.18945   94.398796 639.48456  559.9734  ]\n",
      " [318.33075   93.42486  643.57556  560.6826  ]\n",
      " [316.80783   94.591576 640.5386   547.86163 ]\n",
      " [313.07666   93.03226  636.13995  551.48505 ]\n",
      " [314.98755   93.04844  638.90735  561.83685 ]\n",
      " [312.88202   97.02373  636.4184   551.33344 ]\n",
      " [314.04953   90.78592  636.92993  551.8096  ]\n",
      " [317.23206   91.64773  640.1016   561.73755 ]\n",
      " [311.8841    98.82808  645.4935   555.7671  ]\n",
      " [313.1896    97.28546  634.93005  550.4404  ]\n",
      " [314.2278    94.08077  637.74725  556.20764 ]\n",
      " [315.0426    91.49602  637.6488   550.8773  ]\n",
      " [312.6627    91.8429   637.73285  552.25824 ]\n",
      " [316.60666   93.460175 639.498    566.3048  ]\n",
      " [315.3668    97.27359  639.6776   552.28094 ]\n",
      " [313.53995   97.371895 640.63     568.36835 ]\n",
      " [314.5077    99.369156 635.617    549.2496  ]\n",
      " [314.89926   95.83184  636.95886  552.359   ]\n",
      " [313.92722   92.57683  637.27716  566.38885 ]\n",
      " [316.443     99.62332  635.9489   553.77783 ]\n",
      " [318.7256   105.19342  641.0322   554.61926 ]\n",
      " [308.2195   100.867805 648.48816  555.523   ]\n",
      " [314.90836   98.81437  642.8306   559.074   ]\n",
      " [312.64612  100.45841  640.3144   552.0619  ]\n",
      " [314.33725   94.117256 642.35693  564.3431  ]\n",
      " [317.74875   94.546524 637.305    554.79956 ]\n",
      " [318.09842  103.27563  637.5631   550.2348  ]\n",
      " [314.92325   90.13714  634.3671   560.1378  ]\n",
      " [317.50085   99.6042   637.86804  552.9898  ]\n",
      " [315.32687   93.07237  635.7289   563.1964  ]\n",
      " [319.0742   107.36409  635.71716  550.3534  ]\n",
      " [315.40933   94.93765  642.69965  557.48914 ]\n",
      " [319.48956   99.234505 639.92645  555.7488  ]\n",
      " [312.49057   94.37291  644.6802   562.25616 ]\n",
      " [322.63242   98.10245  640.14374  550.53186 ]\n",
      " [312.67017  102.66273  639.3753   549.56805 ]\n",
      " [314.30957   95.179695 638.08673  551.864   ]\n",
      " [313.2498    90.44822  638.4035   551.3348  ]\n",
      " [312.90784   90.161964 639.3407   555.8611  ]\n",
      " [311.0852    96.89881  637.5375   554.23224 ]\n",
      " [313.32715   95.15543  638.8716   554.41504 ]\n",
      " [310.06216   94.576225 636.9254   554.48846 ]\n",
      " [310.13834   95.41885  638.8151   551.99713 ]\n",
      " [320.20233   92.64308  638.9739   554.5468  ]\n",
      " [312.89984   93.22356  638.1011   555.1973  ]\n",
      " [311.2741    94.85969  642.4942   567.531   ]\n",
      " [311.86835   92.2083   640.82916  554.6496  ]\n",
      " [314.51056   96.014824 639.10065  553.1799  ]\n",
      " [311.82147   90.09826  640.8534   562.003   ]\n",
      " [313.46274   91.10324  641.10626  553.9553  ]\n",
      " [314.30917   91.93528  637.2897   556.9038  ]\n",
      " [314.35297  102.69368  639.0114   552.9028  ]\n",
      " [313.9723    89.63865  638.6616   560.3636  ]\n",
      " [310.14807   90.67412  639.07825  558.3319  ]\n",
      " [320.6725    99.4035   640.3369   551.06067 ]\n",
      " [316.82904  102.06793  639.3089   552.6811  ]\n",
      " [315.631     89.685844 638.57935  570.09125 ]\n",
      " [312.10934   91.042015 639.02155  574.1153  ]\n",
      " [316.05682   89.95744  637.75775  571.80786 ]\n",
      " [315.44824   87.84367  635.6174   568.99274 ]\n",
      " [309.0882   106.29016  644.2204   553.5401  ]\n",
      " [315.53586   90.21364  633.7336   555.029   ]\n",
      " [319.964     96.22297  642.8535   561.91943 ]\n",
      " [314.9636   102.55812  636.5117   552.3288  ]\n",
      " [315.0877    91.59326  638.0221   563.1225  ]\n",
      " [320.00775   91.59434  637.61993  572.9144  ]\n",
      " [315.96085  108.278915 644.02136  547.54266 ]\n",
      " [315.79288   94.60898  641.3747   548.08295 ]\n",
      " [313.16992   94.85723  639.2481   552.05615 ]\n",
      " [320.77106   97.00605  638.8457   566.95294 ]\n",
      " [313.8597   101.906586 642.33307  555.11487 ]\n",
      " [315.44507   90.61465  639.8651   561.75757 ]\n",
      " [311.80325  102.96035  641.80084  552.1741  ]\n",
      " [305.15808  110.19042  650.52277  552.98914 ]\n",
      " [316.4606    94.88973  641.04034  556.1546  ]\n",
      " [311.07437  110.334305 640.275    552.39606 ]\n",
      " [314.38736   92.92454  642.315    552.7328  ]\n",
      " [304.40604  112.71432  644.50934  552.00397 ]\n",
      " [314.0778   112.185616 640.19556  550.4299  ]\n",
      " [315.19662  107.97976  639.2869   551.6826  ]\n",
      " [315.44727  114.973114 640.29236  548.77515 ]\n",
      " [316.5606    87.046295 637.8166   563.93896 ]\n",
      " [315.6265    86.869064 635.3775   561.2946  ]\n",
      " [316.8177    95.33987  636.2469   554.2691  ]\n",
      " [309.0304   108.355    647.2726   552.5114  ]\n",
      " [323.14795  111.9739   641.4887   548.6317  ]\n",
      " [312.36148   94.28637  635.914    555.413   ]\n",
      " [310.2996    88.435844 642.8229   566.8862  ]\n",
      " [312.88367   89.837555 636.90857  558.08185 ]\n",
      " [316.75986   85.47775  635.064    561.3953  ]\n",
      " [311.73102   88.485    643.7438   564.8722  ]\n",
      " [314.11612   88.37569  639.89496  566.79926 ]\n",
      " [307.39078   85.48866  635.18695  567.5458  ]\n",
      " [314.5516    92.01415  641.4998   565.3283  ]\n",
      " [313.01465   88.531525 639.2129   562.81793 ]\n",
      " [310.1244    89.03213  638.283    566.2134  ]\n",
      " [314.0742    88.147385 639.9532   568.47833 ]\n",
      " [322.4553    88.385956 639.7163   559.78107 ]\n",
      " [315.31375  127.55933  636.605    549.1612  ]\n",
      " [323.50955   91.97071  644.06335  556.11945 ]\n",
      " [310.31854   95.34861  629.95844  551.5674  ]\n",
      " [317.4091   130.41289  636.814    549.1629  ]\n",
      " [316.56427   93.75994  642.6523   559.4605  ]\n",
      " [315.67667   96.49613  645.12726  555.2436  ]\n",
      " [315.40073   89.114815 638.96423  562.0153  ]\n",
      " [310.58145  128.524    635.3219   552.29376 ]\n",
      " [306.68674   84.673065 629.47424  556.3765  ]\n",
      " [312.06143  120.08326  636.7487   557.37085 ]\n",
      " [309.23523  110.488785 643.0847   553.2539  ]\n",
      " [312.4653   123.56591  646.0474   557.7922  ]\n",
      " [319.72626  115.05386  641.5617   552.84796 ]\n",
      " [319.80844   82.062004 633.11884  549.8018  ]\n",
      " [323.67722  109.18969  649.4579   552.9569  ]\n",
      " [320.89078   82.185196 632.6223   549.956   ]\n",
      " [311.70938  105.42632  644.6648   554.0041  ]\n",
      " [304.7406   117.73543  650.55145  553.7503  ]\n",
      " [309.3975   135.10365  634.8587   548.5347  ]\n",
      " [309.52805   98.464874 648.21014  551.3437  ]\n",
      " [300.67236  122.97328  650.887    552.8801  ]\n",
      " [309.5528    94.37868  633.4851   551.9092  ]\n",
      " [306.30008  116.18078  650.22003  552.89545 ]\n",
      " [304.86386  117.34664  650.72894  551.1935  ]\n",
      " [326.4697   127.33391  648.1018   550.06757 ]\n",
      " [308.82797   92.118576 644.5788   560.19745 ]\n",
      " [320.8177   107.904274 640.3612   547.224   ]\n",
      " [319.74597  102.622314 640.8212   553.8861  ]\n",
      " [308.8297    95.82996  639.1875   560.40295 ]\n",
      " [319.9349   106.66655  641.56287  546.278   ]\n",
      " [308.41574  125.574585 638.14087  550.61163 ]\n",
      " [320.21494  100.20445  643.8794   551.6474  ]\n",
      " [304.7734   129.7007   647.7735   549.2443  ]\n",
      " [318.10635  133.72285  641.2647   556.2965  ]\n",
      " [321.22202   90.46325  650.3406   560.5685  ]\n",
      " [323.92715   98.808395 641.91565  542.23254 ]\n",
      " [308.31525   76.666504 639.50995  556.9123  ]\n",
      " [308.5653    72.78399  647.5099   558.4281  ]\n",
      " [321.57593  130.30086  646.7429   551.11334 ]\n",
      " [302.2456   138.30644  651.9549   557.1163  ]\n",
      " [304.11948  109.9811   623.38025  554.31647 ]\n",
      " [307.70328   75.53892  650.5751   561.4941  ]\n",
      " [317.35406   82.59967  626.3962   540.8953  ]\n",
      " [311.34918   80.049736 646.2615   550.5531  ]\n",
      " [305.1993    77.362854 645.00244  556.44745 ]\n",
      " [311.7135    72.82391  642.8176   564.69073 ]\n",
      " [308.1716    83.53457  623.0903   550.4972  ]\n",
      " [314.90228   73.219    639.2685   548.7099  ]\n",
      " [331.99783   83.013695 639.41644  539.9746  ]\n",
      " [309.34763   67.532005 642.58386  551.7214  ]\n",
      " [335.33     125.03097  655.08746  553.33545 ]\n",
      " [322.80353  157.01115  633.3881   553.65    ]\n",
      " [324.15973  164.57983  634.70447  553.86053 ]\n",
      " [322.97064   76.78287  646.14087  551.8944  ]\n",
      " [332.4746    94.28498  645.77466  537.19714 ]\n",
      " [307.18954   73.05183  631.32477  561.9049  ]] (176, 4)\n",
      "\n",
      "[0.9998246  0.99978226 0.99969935 0.99962604 0.999613   0.99957854\n",
      " 0.99951315 0.99949384 0.999395   0.9993806  0.99936897 0.9993598\n",
      " 0.9993179  0.9992994  0.99928844 0.9992663  0.9992612  0.99923694\n",
      " 0.9992199  0.99920386 0.99919266 0.99917233 0.9990883  0.99906415\n",
      " 0.9989812  0.9989718  0.99895334 0.99895215 0.99886763 0.9988337\n",
      " 0.9988336  0.99875    0.9987452  0.99842286 0.9981774  0.99815303\n",
      " 0.9981446  0.99787307 0.9977775  0.9975732  0.9975305  0.99726677\n",
      " 0.9970392  0.996485   0.99601823 0.9959407  0.9959145  0.99567974\n",
      " 0.99530196 0.99521613 0.99483746 0.9945411  0.99450374 0.99385506\n",
      " 0.99376464 0.99360305 0.9931585  0.9931452  0.99294597 0.99210125\n",
      " 0.99205184 0.99097365 0.9903627  0.9903289  0.98915243 0.98789585\n",
      " 0.98777175 0.9876565  0.98742825 0.98715055 0.9870604  0.986021\n",
      " 0.98495525 0.9824056  0.98220783 0.9819511  0.98188514 0.98156345\n",
      " 0.9806152  0.98030967 0.979218   0.97906053 0.9786347  0.9783734\n",
      " 0.97749925 0.9762981  0.9718193  0.9714488  0.9697705  0.96920544\n",
      " 0.96742654 0.9655975  0.96207005 0.96031916 0.9520446  0.9494907\n",
      " 0.94869244 0.9461159  0.94578725 0.94461733 0.937176   0.93706816\n",
      " 0.9369423  0.9302121  0.9232071  0.9217906  0.9113961  0.8935579\n",
      " 0.8693339  0.8517828  0.85065705 0.80794144 0.7626344  0.7493366\n",
      " 0.73843235 0.730295   0.72061765 0.6869304  0.67987937 0.67352885\n",
      " 0.6688832  0.648551   0.64779466 0.63377815 0.62851685 0.6200073\n",
      " 0.61312854 0.5307115  0.5078349  0.43636888 0.4157558  0.34280932\n",
      " 0.31689107 0.3081668  0.28642955 0.28259876 0.2765819  0.24753745\n",
      " 0.24366157 0.24306124 0.23006435 0.22880818 0.22327997 0.21964714\n",
      " 0.21920079 0.2168574  0.21225263 0.20948891 0.20508607 0.19586033\n",
      " 0.18416299 0.18248023 0.16578719 0.16061185 0.15985097 0.15680851\n",
      " 0.1452294  0.11607195 0.10744802 0.10008524 0.0982988  0.08569564\n",
      " 0.07354823 0.06511659 0.0626367  0.06101305 0.05729552 0.04307422\n",
      " 0.03626371 0.03609392 0.03250479 0.03196818 0.02850259 0.02351964\n",
      " 0.02307154 0.02295668] (176,)\n",
      "Tensor in gpu\n",
      "test [[[22.  8.  6.]\n",
      "  [21.  7.  5.]\n",
      "  [20.  6.  5.]\n",
      "  ...\n",
      "  [77. 47. 22.]\n",
      "  [77. 47. 22.]\n",
      "  [78. 48. 22.]]\n",
      "\n",
      " [[23.  8.  6.]\n",
      "  [22.  8.  6.]\n",
      "  [21.  7.  5.]\n",
      "  ...\n",
      "  [78. 48. 23.]\n",
      "  [79. 48. 23.]\n",
      "  [80. 49. 24.]]\n",
      "\n",
      " [[24.  9.  7.]\n",
      "  [23.  8.  6.]\n",
      "  [21.  7.  6.]\n",
      "  ...\n",
      "  [80. 49. 23.]\n",
      "  [80. 49. 24.]\n",
      "  [81. 50. 24.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[78. 30.  7.]\n",
      "  [79. 31.  7.]\n",
      "  [77. 30.  7.]\n",
      "  ...\n",
      "  [84. 54. 32.]\n",
      "  [84. 54. 32.]\n",
      "  [84. 54. 32.]]\n",
      "\n",
      " [[82. 32.  7.]\n",
      "  [81. 32.  7.]\n",
      "  [80. 32.  7.]\n",
      "  ...\n",
      "  [84. 54. 32.]\n",
      "  [84. 54. 32.]\n",
      "  [84. 54. 32.]]\n",
      "\n",
      " [[84. 34.  8.]\n",
      "  [85. 34.  8.]\n",
      "  [86. 34.  7.]\n",
      "  ...\n",
      "  [85. 55. 33.]\n",
      "  [84. 53. 32.]\n",
      "  [84. 54. 32.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0046\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f610>\n",
      "[[ 4.68192959e+00  8.04957390e+00  7.47293549e+01  1.09492249e+02]\n",
      " [ 4.94013643e+00  7.16207647e+00  7.42914047e+01  1.09784164e+02]\n",
      " [ 4.79379463e+00  9.69240761e+00  7.50364609e+01  1.10845276e+02]\n",
      " [ 6.06331968e+00  8.76799107e+00  7.54827423e+01  1.10007088e+02]\n",
      " [ 5.25587130e+00  8.22356224e+00  7.29986954e+01  1.09661804e+02]\n",
      " [ 5.78272247e+00  7.61420965e+00  7.44840164e+01  1.06903328e+02]\n",
      " [ 5.67059708e+00  1.02456646e+01  7.34683228e+01  1.07715134e+02]\n",
      " [ 5.21677160e+00  6.78096962e+00  7.31868973e+01  1.07050179e+02]\n",
      " [ 5.14420986e+00  8.54114723e+00  7.32852936e+01  1.09554054e+02]\n",
      " [ 5.21660471e+00  6.70722294e+00  7.27512131e+01  1.07523872e+02]\n",
      " [ 6.43005371e+00  8.45150566e+00  7.57023468e+01  1.09780830e+02]\n",
      " [ 5.10444260e+00  6.70649862e+00  7.43039169e+01  1.08994270e+02]\n",
      " [ 5.49913454e+00  7.44157553e+00  7.30857086e+01  1.07299850e+02]\n",
      " [ 3.44506884e+00  7.38192463e+00  7.03858414e+01  1.09427147e+02]\n",
      " [ 3.72605324e+00  6.26418543e+00  7.51750946e+01  1.08427231e+02]\n",
      " [ 4.85635948e+00  6.57542086e+00  7.23185349e+01  1.08131317e+02]\n",
      " [ 4.82642555e+00  6.76283169e+00  7.30398178e+01  1.07913788e+02]\n",
      " [ 4.30174065e+00  7.12567043e+00  7.34044647e+01  1.07899124e+02]\n",
      " [ 3.38878584e+00  5.62438774e+00  7.19225311e+01  1.11093849e+02]\n",
      " [ 2.69583607e+00  5.61593294e+00  7.27099380e+01  1.10059021e+02]\n",
      " [ 3.89331007e+00  7.40098047e+00  7.17342682e+01  1.11696159e+02]\n",
      " [ 7.28032017e+00  6.15938663e+00  7.57117615e+01  1.11115471e+02]\n",
      " [ 2.54716110e+00  5.24045706e+00  7.32553864e+01  1.09622025e+02]\n",
      " [ 5.30858946e+00  6.70663214e+00  7.58956070e+01  1.07546455e+02]\n",
      " [ 6.49891710e+00  4.91694164e+00  7.43712463e+01  1.14891144e+02]\n",
      " [ 6.94282579e+00  5.20664454e+00  7.54285889e+01  1.07558311e+02]\n",
      " [ 4.99655628e+00  9.18639565e+00  7.42517319e+01  1.09118790e+02]\n",
      " [ 4.27321863e+00  1.24405117e+01  7.15523605e+01  1.10404625e+02]\n",
      " [ 4.35397482e+00  8.62818527e+00  7.40774384e+01  1.07521530e+02]\n",
      " [ 4.56297493e+00  9.93620872e+00  7.29207230e+01  1.07952629e+02]\n",
      " [ 9.34775352e+00  1.38852615e+01  7.68166351e+01  1.11839340e+02]\n",
      " [ 1.93191004e+00  6.91724777e-01  7.48343201e+01  1.07772652e+02]\n",
      " [ 1.13032627e+00  1.08835068e+01  7.05608444e+01  1.11772224e+02]\n",
      " [ 8.83131027e-01  1.69632721e+00  7.53738632e+01  1.09607864e+02]\n",
      " [ 7.93018818e-01  2.45374441e+00  7.47851181e+01  1.12355827e+02]\n",
      " [ 7.02199316e+00  6.31783819e+00  7.83378448e+01  1.12971130e+02]\n",
      " [ 1.31252098e+01  1.30441236e+00  7.90180817e+01  1.08043205e+02]\n",
      " [ 1.30624218e+01 -5.60293198e-02  8.34320068e+01  1.11487869e+02]\n",
      " [ 2.47396517e+00  2.95422983e+00  6.99673157e+01  1.11644493e+02]\n",
      " [ 1.59590769e+01  1.35762825e+01  8.14544067e+01  1.06451233e+02]\n",
      " [-3.75345373e+00 -2.98766518e+00  7.32978745e+01  1.10262833e+02]] (41, 4)\n",
      "\n",
      "[0.99799454 0.99656075 0.99169683 0.9552071  0.94791716 0.9455039\n",
      " 0.943977   0.9430943  0.9318004  0.93099177 0.91956204 0.89607656\n",
      " 0.8941527  0.8917622  0.88370895 0.88180906 0.8793763  0.86418283\n",
      " 0.84317213 0.8268882  0.8058125  0.80115247 0.7378042  0.7324341\n",
      " 0.6028919  0.5849273  0.25342602 0.22857915 0.19467375 0.17992137\n",
      " 0.15761793 0.11362904 0.09854989 0.08832323 0.08169916 0.05291775\n",
      " 0.0411669  0.03854604 0.03405035 0.03221315 0.02203012] (41,)\n",
      "Tensor in gpu\n",
      "test [[[165. 156. 121.]\n",
      "  [166. 156. 120.]\n",
      "  [165. 154. 117.]\n",
      "  ...\n",
      "  [120. 138. 112.]\n",
      "  [106. 124.  87.]\n",
      "  [ 89. 107.  63.]]\n",
      "\n",
      " [[165. 155. 120.]\n",
      "  [165. 155. 119.]\n",
      "  [164. 152. 115.]\n",
      "  ...\n",
      "  [ 99. 117.  74.]\n",
      "  [ 88. 105.  58.]\n",
      "  [ 81.  98.  49.]]\n",
      "\n",
      " [[165. 156. 123.]\n",
      "  [164. 154. 118.]\n",
      "  [162. 150. 114.]\n",
      "  ...\n",
      "  [ 87. 104.  60.]\n",
      "  [ 81.  97.  50.]\n",
      "  [ 79.  94.  49.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 93. 113.  65.]\n",
      "  [ 91. 111.  65.]\n",
      "  [ 86. 107.  62.]\n",
      "  ...\n",
      "  [102.  90.  39.]\n",
      "  [105.  93.  41.]\n",
      "  [106.  95.  41.]]\n",
      "\n",
      " [[ 97. 117.  67.]\n",
      "  [ 90. 111.  64.]\n",
      "  [ 83. 106.  59.]\n",
      "  ...\n",
      "  [ 99.  89.  38.]\n",
      "  [107.  95.  40.]\n",
      "  [105.  94.  40.]]\n",
      "\n",
      " [[ 90. 113.  66.]\n",
      "  [ 88. 110.  64.]\n",
      "  [ 83. 106.  60.]\n",
      "  ...\n",
      "  [ 99.  91.  39.]\n",
      "  [106.  95.  41.]\n",
      "  [101.  93.  41.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7fa90>\n",
      "[[  5.673094    8.43273    91.53661   104.676414 ]\n",
      " [  5.280408    9.016955   90.49736   105.06148  ]\n",
      " [  5.932619    8.677498   91.38118   104.86395  ]\n",
      " [  5.051137    9.326979   92.204865  106.5404   ]\n",
      " [  4.0170445   9.045748   90.02858   105.265495 ]\n",
      " [  4.6627703   9.042009   92.66979   106.558754 ]\n",
      " [  4.4037123   9.579251   90.06481   104.95565  ]\n",
      " [  5.4531155   9.608745   90.679276  105.14992  ]\n",
      " [  5.125518    7.8467283  90.85128   105.49111  ]\n",
      " [  4.5296497   9.764767   92.27098   106.22676  ]\n",
      " [  5.7757063   9.001257   90.021324  105.55453  ]\n",
      " [  4.316948    9.321155   91.73354   106.10444  ]\n",
      " [  5.03362     8.137389   92.13839   104.33779  ]\n",
      " [  4.8130007   8.273781   90.546646  105.20187  ]\n",
      " [  4.244236    9.5806265  90.62212   105.01842  ]\n",
      " [  5.133839    9.522745   89.65392   107.121796 ]\n",
      " [  6.187011    8.300056   91.275505  106.85545  ]\n",
      " [  6.0391135   8.556061   90.725815  107.75024  ]\n",
      " [  3.4272113  10.107838   90.937355  104.18284  ]\n",
      " [  5.263228   10.510458   93.1755    105.12436  ]\n",
      " [  4.1467104  10.186525   92.534195  106.238235 ]\n",
      " [  6.0767913   6.1195726  91.59303   106.96269  ]\n",
      " [  4.788751    9.878217   90.91853   104.283646 ]\n",
      " [  4.8531985   6.8977847  90.919235  106.27091  ]\n",
      " [  4.845715    6.1011944  90.24823   106.55619  ]\n",
      " [  4.6083665   6.66091    89.613266  105.972984 ]\n",
      " [  6.4135013  12.801868   91.92671   105.82202  ]\n",
      " [  6.0810137  13.692526   94.05631   105.877815 ]\n",
      " [  4.798007    8.381594   91.800735  106.77475  ]\n",
      " [  4.2910094  12.171073   90.410965  105.259315 ]\n",
      " [  2.682695    6.268498   90.39518   105.118744 ]\n",
      " [  3.930941   14.030281   91.532455  105.12692  ]\n",
      " [  3.5524244   3.1214266  89.46543   105.12585  ]\n",
      " [  7.3855295   6.2868795  88.77968   106.92053  ]\n",
      " [  6.9920826   4.204175   90.77263   109.03179  ]\n",
      " [  4.4300146   5.3181825  89.90489   105.73205  ]\n",
      " [  4.1008515  14.040939   91.73796   106.24722  ]\n",
      " [  6.6417475  15.989868   92.54964   106.355705 ]\n",
      " [ 10.30514     9.058401   92.49846   105.80246  ]\n",
      " [ 10.174389    4.0540013  89.844604  106.17669  ]\n",
      " [  3.2179775   8.474329   87.52978   103.96258  ]\n",
      " [  7.515853    3.5236888  88.640015  105.746574 ]] (42, 4)\n",
      "\n",
      "[0.99417615 0.9929107  0.99270004 0.99237    0.9921854  0.9912862\n",
      " 0.9908167  0.9902952  0.98923653 0.9884376  0.98788506 0.98568845\n",
      " 0.9848881  0.9835722  0.98196936 0.9813002  0.9788519  0.9783945\n",
      " 0.9162317  0.9023592  0.8020122  0.780964   0.76004905 0.7546331\n",
      " 0.7043376  0.64828247 0.60302716 0.45982307 0.45945904 0.44608626\n",
      " 0.4382632  0.4363555  0.43056482 0.42170826 0.41293645 0.39602175\n",
      " 0.38140082 0.36216995 0.22482127 0.1846645  0.16777256 0.14004739] (42,)\n",
      "Tensor in gpu\n",
      "test [[[ 39.  17.   7.]\n",
      "  [ 40.  17.   7.]\n",
      "  [ 37.  15.   5.]\n",
      "  ...\n",
      "  [120. 109.  88.]\n",
      "  [120. 109.  89.]\n",
      "  [120. 110.  89.]]\n",
      "\n",
      " [[ 41.  18.   7.]\n",
      "  [ 41.  17.   7.]\n",
      "  [ 38.  16.   7.]\n",
      "  ...\n",
      "  [120. 109.  88.]\n",
      "  [120. 109.  89.]\n",
      "  [120. 109.  89.]]\n",
      "\n",
      " [[ 43.  19.   8.]\n",
      "  [ 43.  18.   7.]\n",
      "  [ 39.  17.   7.]\n",
      "  ...\n",
      "  [120. 109.  88.]\n",
      "  [120. 109.  88.]\n",
      "  [120. 109.  88.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[167. 124.  81.]\n",
      "  [171. 125.  80.]\n",
      "  [168. 124.  80.]\n",
      "  ...\n",
      "  [138. 130. 114.]\n",
      "  [139. 131. 115.]\n",
      "  [138. 131. 115.]]\n",
      "\n",
      " [[163. 122.  83.]\n",
      "  [167. 125.  84.]\n",
      "  [167. 125.  83.]\n",
      "  ...\n",
      "  [139. 131. 115.]\n",
      "  [139. 131. 116.]\n",
      "  [139. 131. 116.]]\n",
      "\n",
      " [[161. 121.  83.]\n",
      "  [164. 123.  84.]\n",
      "  [165. 125.  85.]\n",
      "  ...\n",
      "  [139. 132. 116.]\n",
      "  [139. 131. 116.]\n",
      "  [139. 131. 116.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f2b0>\n",
      "[[  5.8941736   13.848417    78.329834   107.2455    ]\n",
      " [  5.0416975   13.241381    78.4465     107.97082   ]\n",
      " [  5.537046    14.108647    79.32087    109.1386    ]\n",
      " [  5.4473276   14.347344    80.324      107.72682   ]\n",
      " [  5.2097287   15.114014    80.17141    106.97868   ]\n",
      " [  5.8693      14.263237    78.4477     108.30975   ]\n",
      " [  5.4292564   12.312478    79.44723    105.404236  ]\n",
      " [  5.656598    15.585998    78.15007    108.55546   ]\n",
      " [  5.9393983   17.6163      78.258415   106.69795   ]\n",
      " [  5.904948    12.013666    78.75462    107.88172   ]\n",
      " [  5.683962    12.411953    78.08631    106.42389   ]\n",
      " [  4.915837    13.194023    77.17078    107.2602    ]\n",
      " [  4.0369215   13.414319    78.36534    106.30284   ]\n",
      " [  6.2550464   11.654322    80.08298    109.30484   ]\n",
      " [  4.952707    12.219643    78.123085   108.37804   ]\n",
      " [  4.088805    14.488165    79.04399    106.026535  ]\n",
      " [  4.921401    13.613376    78.72237    107.1555    ]\n",
      " [  4.6352997   12.5132065   79.319176   107.99779   ]\n",
      " [  2.9566298   12.114029    77.84862    109.74857   ]\n",
      " [  3.9357944   14.47743     78.81229    105.92632   ]\n",
      " [  3.4142437   12.47879     74.96386    108.9362    ]\n",
      " [  2.8651857   11.46586     75.865616   110.17758   ]\n",
      " [  5.7250443   12.82783     79.99391    107.43677   ]\n",
      " [  3.5945983   11.415835    76.7517     109.02979   ]\n",
      " [  6.995237    19.974712    80.498146   108.298195  ]\n",
      " [  4.5436854   14.976128    79.80725    106.728134  ]\n",
      " [  4.8301806   14.558137    77.89052    106.06959   ]\n",
      " [  2.4167776    8.323172    77.98601    108.91646   ]\n",
      " [  4.8150268   14.851425    78.788506   106.50456   ]\n",
      " [  6.9994626    8.990172    78.982864   109.01405   ]\n",
      " [  5.372012    15.391013    81.48056    108.8492    ]\n",
      " [  3.9537454   19.995846    76.57497    109.81249   ]\n",
      " [  1.5593781    5.8662157   79.98972    105.93932   ]\n",
      " [ 10.1784      18.082657    82.942      105.13606   ]\n",
      " [  1.2599654    7.366347    80.140396   108.32081   ]\n",
      " [ -0.40253592  16.083118    74.922035   111.57752   ]\n",
      " [  0.98558664   7.4461083   80.791626   110.33178   ]\n",
      " [  9.956496    21.318134    83.863266   106.538635  ]\n",
      " [ 11.187141     5.2861824   82.81003    104.292946  ]\n",
      " [  8.386431     7.4415455   85.10718    108.65602   ]] (40, 4)\n",
      "\n",
      "[0.9978532  0.99637336 0.9869473  0.9864698  0.9677008  0.9452215\n",
      " 0.9395366  0.93385893 0.929744   0.92800057 0.9238428  0.9122826\n",
      " 0.90298396 0.8962232  0.8955014  0.87005407 0.86636424 0.8343293\n",
      " 0.78147256 0.7596456  0.7317419  0.701736   0.60965145 0.57917327\n",
      " 0.5404182  0.45105106 0.43962088 0.4090715  0.37318182 0.30509248\n",
      " 0.20942461 0.16538465 0.13416013 0.08438401 0.08226618 0.07968802\n",
      " 0.06345118 0.05265619 0.04507231 0.04079581] (40,)\n",
      "Tensor in gpu\n",
      "test [[[ 88. 115. 125.]\n",
      "  [ 94. 124. 138.]\n",
      "  [ 94. 123. 136.]\n",
      "  ...\n",
      "  [105. 137. 156.]\n",
      "  [105. 137. 156.]\n",
      "  [105. 138. 156.]]\n",
      "\n",
      " [[ 77.  99.  98.]\n",
      "  [ 83. 105. 109.]\n",
      "  [ 81. 103. 103.]\n",
      "  ...\n",
      "  [105. 138. 156.]\n",
      "  [105. 137. 156.]\n",
      "  [105. 138. 156.]]\n",
      "\n",
      " [[ 65.  81.  66.]\n",
      "  [ 72.  89.  79.]\n",
      "  [ 72.  89.  78.]\n",
      "  ...\n",
      "  [105. 138. 156.]\n",
      "  [105. 137. 155.]\n",
      "  [105. 137. 155.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[127. 112.  91.]\n",
      "  [125. 111.  90.]\n",
      "  [123. 109.  88.]\n",
      "  ...\n",
      "  [103.  89.  73.]\n",
      "  [102.  90.  73.]\n",
      "  [101.  88.  71.]]\n",
      "\n",
      " [[125. 111.  93.]\n",
      "  [124. 110.  92.]\n",
      "  [124. 110.  91.]\n",
      "  ...\n",
      "  [122. 104.  85.]\n",
      "  [123. 105.  86.]\n",
      "  [121. 104.  84.]]\n",
      "\n",
      " [[125. 112.  94.]\n",
      "  [125. 112.  94.]\n",
      "  [125. 112.  94.]\n",
      "  ...\n",
      "  [130. 112.  91.]\n",
      "  [131. 112.  92.]\n",
      "  [130. 111.  92.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f130>\n",
      "[[ 12.561058    6.754801   93.29706   107.42651  ]\n",
      " [ 12.187001    7.447133   92.91596   107.18713  ]\n",
      " [ 13.758986    7.98085    92.00477   107.979256 ]\n",
      " [ 12.3404255   8.489651   92.50362   107.82267  ]\n",
      " [ 12.846693    6.495973   91.88874   105.36264  ]\n",
      " [ 12.076545    8.226397   90.75138   106.35027  ]\n",
      " [ 11.798918    7.042434   90.109085  104.41852  ]\n",
      " [ 11.4066925   7.762474   90.65813   106.04243  ]\n",
      " [ 12.0876      8.4428005  92.66362   107.55292  ]\n",
      " [ 12.88835     7.763529   91.32387   104.47614  ]\n",
      " [ 11.137244    5.612148   92.6768    106.19211  ]\n",
      " [ 11.846887    6.0128345  91.435776  106.50293  ]\n",
      " [ 14.405159    8.270984   93.23773   105.194405 ]\n",
      " [ 12.842768    6.8319254  93.223175  107.62832  ]\n",
      " [ 12.456387    6.830657   91.309875  105.53382  ]\n",
      " [ 12.554636    7.377692   89.71571   106.10062  ]\n",
      " [ 12.44409     6.8262444  93.37549   105.687065 ]\n",
      " [ 14.012314    7.8522425  92.3282    105.99142  ]\n",
      " [ 12.638624    5.1338625  90.3322    107.35481  ]\n",
      " [ 12.9348955   8.84605    92.63182   106.29566  ]\n",
      " [ 13.435995    9.331876   93.9617    106.79704  ]\n",
      " [ 14.427753   12.066284   93.08399   107.250336 ]\n",
      " [ 13.116342    3.57615    90.55937   109.00165  ]\n",
      " [ 12.700257    8.598665   92.13731   105.5718   ]\n",
      " [ 13.168816    6.8386846  91.62435   108.10971  ]\n",
      " [ 14.514091    6.8566422  92.249344  108.23256  ]\n",
      " [ 13.4220495   8.248039   92.77334   107.16133  ]\n",
      " [ 13.37594     8.502905   93.26276   105.477005 ]\n",
      " [ 15.482721    4.267304   91.80689   110.02995  ]\n",
      " [ 13.101364    4.7483397  93.04918   107.43448  ]\n",
      " [ 12.076531    5.152992   89.083244  107.72304  ]\n",
      " [ 12.423769    3.7686577  92.634125  106.46061  ]\n",
      " [ 11.604585   12.219769   91.28882   108.38498  ]\n",
      " [ 11.975581    8.991434   91.89268   105.80655  ]\n",
      " [  9.942364    3.5141625  90.28894   108.20982  ]\n",
      " [ 11.513918    2.3896742  92.64993   107.91064  ]\n",
      " [ 13.080656    1.9918647  91.11553   108.4747   ]\n",
      " [  8.072578    3.8745246  90.12904   107.44637  ]\n",
      " [  6.971982   -1.4652071  88.445175  107.53482  ]\n",
      " [ 16.538553   16.107782   95.43233   110.52977  ]\n",
      " [ 10.20443    13.371277   88.039665  104.40502  ]\n",
      " [  9.551921   15.690035   88.86705   105.715    ]\n",
      " [ 14.777859    9.804423   96.85959   115.420425 ]\n",
      " [ 18.13232    -2.7513013  96.97778   108.76364  ]\n",
      " [  9.351326    7.718935   84.98514   102.85563  ]] (45, 4)\n",
      "\n",
      "[0.9967969  0.99427754 0.99367154 0.99216276 0.99011946 0.98869973\n",
      " 0.9865697  0.9858169  0.98457426 0.9844201  0.98375595 0.98162913\n",
      " 0.9811782  0.97805804 0.97488594 0.97049046 0.963488   0.9549591\n",
      " 0.9235347  0.912171   0.8038524  0.7657618  0.7601513  0.75212735\n",
      " 0.74880105 0.7441688  0.7200641  0.65853727 0.65520006 0.5672239\n",
      " 0.48371136 0.43653375 0.38119334 0.29910254 0.23204008 0.15567724\n",
      " 0.1376544  0.07281608 0.05801727 0.0557554  0.05089683 0.04841316\n",
      " 0.03786241 0.02717124 0.02513736] (45,)\n",
      "Tensor in gpu\n",
      "test [[[205. 202. 192.]\n",
      "  [205. 202. 192.]\n",
      "  [205. 202. 192.]\n",
      "  ...\n",
      "  [185. 183. 177.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[205. 202. 191.]\n",
      "  [205. 202. 192.]\n",
      "  [205. 202. 191.]\n",
      "  ...\n",
      "  [192. 190. 183.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[205. 203. 192.]\n",
      "  [206. 203. 192.]\n",
      "  [205. 202. 192.]\n",
      "  ...\n",
      "  [192. 191. 184.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[185. 158. 121.]\n",
      "  [196. 170. 129.]\n",
      "  [202. 178. 133.]\n",
      "  ...\n",
      "  [211. 207. 170.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[183. 155. 122.]\n",
      "  [194. 168. 129.]\n",
      "  [199. 174. 132.]\n",
      "  ...\n",
      "  [209. 204. 170.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[185. 160. 129.]\n",
      "  [193. 167. 130.]\n",
      "  [198. 173. 134.]\n",
      "  ...\n",
      "  [206. 201. 170.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f6d0>\n",
      "[[  5.5856085  14.658226   83.03073   106.66046  ]\n",
      " [  4.5288754  13.900545   83.11684   107.945274 ]\n",
      " [  4.072957   15.135941   83.84444   107.88147  ]\n",
      " [  4.5833325  15.577346   83.66347   106.39506  ]\n",
      " [  5.7455454  15.225565   83.50874   108.469986 ]\n",
      " [  4.4730062  13.403411   81.20628   106.39685  ]\n",
      " [  4.878426   13.318262   83.49727   105.4302   ]\n",
      " [  5.2290916  13.243447   82.07098   105.958336 ]\n",
      " [  5.6819625  13.749333   83.22141   107.47611  ]\n",
      " [  4.202873   13.75692    82.4198    104.92148  ]\n",
      " [  4.7238164  14.127951   81.46492   105.20274  ]\n",
      " [  6.1194625  13.62862    83.230995  108.54641  ]\n",
      " [  4.514713   13.372836   83.5661    107.17604  ]\n",
      " [  5.713365   17.602041   83.21597   107.159485 ]\n",
      " [  4.069419   14.215512   82.587234  109.19989  ]\n",
      " [  4.636595   13.4499035  83.06238   107.21755  ]\n",
      " [  4.4725122  15.10607    82.75935   105.892395 ]\n",
      " [  5.2192416  15.016502   82.053925  106.46536  ]\n",
      " [  5.181544   17.926275   82.93968   106.714806 ]\n",
      " [  5.5242386  15.841217   82.506226  107.45457  ]\n",
      " [  5.295809   13.25803    82.145035  107.14566  ]\n",
      " [  6.4076734  19.423061   84.78369   107.7345   ]\n",
      " [  4.4966917  12.215656   80.360085  108.450935 ]\n",
      " [  4.8968077  15.086483   82.76282   106.02368  ]\n",
      " [  4.8049097  14.817919   82.71449   105.26083  ]\n",
      " [  5.0318274  14.573958   84.180115  105.885544 ]\n",
      " [  3.1954002  11.889729   81.78924   107.88833  ]\n",
      " [  5.831622   13.545099   85.90065   107.18909  ]\n",
      " [  2.5909705   7.6184254  81.5028    108.97575  ]\n",
      " [  3.6027527  12.596517   81.57814   108.34663  ]\n",
      " [  8.936413   17.402355   84.74896   105.69929  ]\n",
      " [  7.9108887  20.538544   87.15899   106.87374  ]\n",
      " [  7.0934134   8.048565   85.09971   110.35142  ]\n",
      " [  1.7914529   8.5706835  84.23762   110.986755 ]\n",
      " [  1.8962884   7.509134   83.40152   109.41105  ]\n",
      " [  2.3224363   8.075779   85.675415  111.39023  ]\n",
      " [  7.40807     8.504687   82.35225   110.86612  ]\n",
      " [  3.2621274  22.720715   80.506905  109.4431   ]\n",
      " [  6.652749   11.272951   86.10618   110.27677  ]\n",
      " [ -2.216319   16.66116    79.38236   110.77781  ]\n",
      " [  9.39175     4.1928563  90.84505   111.28786  ]\n",
      " [ 16.254702   11.195707   88.58734   102.65823  ]\n",
      " [ 12.6519985   6.668951   85.679565  107.88298  ]\n",
      " [  7.3150873   6.9297614  89.656166  107.668365 ]] (44, 4)\n",
      "\n",
      "[0.9969007  0.99652725 0.98891276 0.9863462  0.9719396  0.9585692\n",
      " 0.95718396 0.9536844  0.943176   0.939258   0.9215249  0.9207842\n",
      " 0.9191047  0.9083909  0.8913774  0.89136493 0.88987476 0.8770508\n",
      " 0.8677106  0.82354283 0.7805682  0.71349454 0.6236816  0.60977316\n",
      " 0.58365864 0.56573766 0.53362375 0.33262753 0.2650261  0.18976758\n",
      " 0.15498272 0.12853485 0.12440921 0.11960511 0.10955166 0.09345476\n",
      " 0.06940503 0.06002201 0.05279046 0.03020873 0.0298298  0.02801652\n",
      " 0.02501243 0.02119172] (44,)\n",
      "Tensor in gpu\n",
      "test [[[252. 253. 253.]\n",
      "  [250. 251. 251.]\n",
      "  [252. 252. 253.]\n",
      "  ...\n",
      "  [144. 106.  58.]\n",
      "  [148. 109.  60.]\n",
      "  [153. 111.  60.]]\n",
      "\n",
      " [[250. 251. 251.]\n",
      "  [249. 249. 250.]\n",
      "  [251. 252. 252.]\n",
      "  ...\n",
      "  [144. 107.  58.]\n",
      "  [150. 113.  63.]\n",
      "  [154. 115.  62.]]\n",
      "\n",
      " [[250. 251. 251.]\n",
      "  [248. 249. 249.]\n",
      "  [250. 250. 251.]\n",
      "  ...\n",
      "  [147. 109.  61.]\n",
      "  [152. 116.  66.]\n",
      "  [153. 116.  63.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[139. 129. 114.]\n",
      "  [140. 130. 115.]\n",
      "  [140. 129. 115.]\n",
      "  ...\n",
      "  [140.  89.  59.]\n",
      "  [ 95.  57.  36.]\n",
      "  [ 85.  51.  32.]]\n",
      "\n",
      " [[140. 130. 115.]\n",
      "  [140. 130. 115.]\n",
      "  [140. 130. 115.]\n",
      "  ...\n",
      "  [137.  86.  50.]\n",
      "  [100.  55.  29.]\n",
      "  [ 78.  44.  27.]]\n",
      "\n",
      " [[140. 130. 114.]\n",
      "  [141. 131. 115.]\n",
      "  [140. 130. 114.]\n",
      "  ...\n",
      "  [130.  77.  42.]\n",
      "  [106.  53.  23.]\n",
      "  [ 80.  43.  23.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f0a0>\n",
      "[[ 27.655075   10.756054  101.663956  107.685135 ]\n",
      " [ 27.830908   11.074372  101.12441   108.369576 ]\n",
      " [ 27.850925   10.17339   102.07847   108.11024  ]\n",
      " [ 27.885368    8.688403  102.17059   108.74017  ]\n",
      " [ 26.895351   11.558912  101.50723   109.42141  ]\n",
      " [ 27.44492    11.678167  101.32347   110.7288   ]\n",
      " [ 27.608906   11.502409   99.686905  107.57544  ]\n",
      " [ 27.043116    9.271047  101.391235  106.54041  ]\n",
      " [ 26.570534    9.65638   101.189896  106.99894  ]\n",
      " [ 26.346464    8.386391  100.973114  108.75576  ]\n",
      " [ 26.464027    9.723287  101.77552   108.334984 ]\n",
      " [ 27.910484    9.015738  100.51159   106.4975   ]\n",
      " [ 28.075043    9.8595915 100.19246   105.70332  ]\n",
      " [ 27.14561     8.421127  100.5163    107.3808   ]\n",
      " [ 26.568419    8.986674  100.61639   107.115    ]\n",
      " [ 27.369064   11.384626  100.588684  108.82312  ]\n",
      " [ 26.84209     8.476883  102.101395  106.64531  ]\n",
      " [ 27.121136   10.735166  101.59927   109.87432  ]\n",
      " [ 29.16692    13.379528  101.39474   107.08389  ]\n",
      " [ 28.162682   13.27734   100.34363   109.19956  ]\n",
      " [ 25.706614    4.861837   99.36493   109.72028  ]\n",
      " [ 26.862457   10.322203  102.76457   108.15927  ]\n",
      " [ 27.396042    8.458609  103.01728   107.72894  ]\n",
      " [ 26.572905   10.263326  101.25033   108.347855 ]\n",
      " [ 26.36542    13.832977   98.570786  107.99079  ]\n",
      " [ 26.624912   11.465409  103.69736   109.38753  ]\n",
      " [ 27.905512    5.0196743 103.08099   110.56332  ]\n",
      " [ 28.044487   13.8737755 105.47706   106.96565  ]\n",
      " [ 26.366112    6.226905   98.2071    108.66514  ]\n",
      " [ 26.371408   14.7541065  98.31297   109.562065 ]\n",
      " [ 27.535858   13.472462  104.001625  107.4157   ]\n",
      " [ 27.89439     3.7211466 101.68955   110.041725 ]\n",
      " [ 26.824478    3.6297927  99.1495    108.93652  ]\n",
      " [ 23.548073    4.6635847 101.04322   109.702156 ]\n",
      " [ 24.019798    4.6814756 102.34525   108.989174 ]\n",
      " [ 25.84084     4.5708823 103.92468   109.78049  ]\n",
      " [ 25.73879     0.7521734 101.17815   107.1382   ]\n",
      " [ 23.683712    0.6285558 100.159706  109.66782  ]\n",
      " [ 25.149628    7.9210525  98.65171   106.7102   ]\n",
      " [ 23.676186    6.632605   96.83721   109.18991  ]\n",
      " [ 23.675491    5.1031275  97.14261   111.26502  ]\n",
      " [ 29.751156    8.277349  105.82251   108.649925 ]] (42, 4)\n",
      "\n",
      "[0.99639446 0.9949897  0.9912725  0.9894385  0.9876201  0.9842553\n",
      " 0.96574444 0.96047026 0.9553964  0.9531622  0.93847346 0.9370971\n",
      " 0.93457127 0.93456036 0.92206466 0.9170579  0.9162383  0.9131553\n",
      " 0.89496243 0.7435386  0.56545854 0.4655575  0.42945954 0.41200045\n",
      " 0.40435794 0.38477394 0.30675197 0.30471846 0.3015953  0.298064\n",
      " 0.29017842 0.26662362 0.19779587 0.18817113 0.18187393 0.14781024\n",
      " 0.14207922 0.12895246 0.09940379 0.08192322 0.07742901 0.06125289] (42,)\n",
      "Tensor in gpu\n",
      "test [[[ 97.  77.  36.]\n",
      "  [ 92.  73.  36.]\n",
      "  [ 86.  66.  32.]\n",
      "  ...\n",
      "  [156. 148.  98.]\n",
      "  [155. 146.  97.]\n",
      "  [157. 148.  98.]]\n",
      "\n",
      " [[ 97.  77.  37.]\n",
      "  [ 88.  69.  34.]\n",
      "  [ 82.  65.  31.]\n",
      "  ...\n",
      "  [158. 151.  98.]\n",
      "  [158. 150.  98.]\n",
      "  [158. 150.  97.]]\n",
      "\n",
      " [[ 95.  75.  37.]\n",
      "  [ 86.  68.  34.]\n",
      "  [ 83.  66.  33.]\n",
      "  ...\n",
      "  [161. 154. 100.]\n",
      "  [160. 153.  99.]\n",
      "  [160. 152.  98.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[182. 182. 178.]\n",
      "  [186. 186. 183.]\n",
      "  [189. 188. 187.]\n",
      "  ...\n",
      "  [100. 101. 100.]\n",
      "  [142. 142. 140.]\n",
      "  [174. 174. 172.]]\n",
      "\n",
      " [[183. 182. 181.]\n",
      "  [186. 184. 183.]\n",
      "  [186. 185. 183.]\n",
      "  ...\n",
      "  [ 23.  23.  25.]\n",
      "  [ 43.  44.  45.]\n",
      "  [ 87.  88.  87.]]\n",
      "\n",
      " [[183. 181. 180.]\n",
      "  [177. 176. 175.]\n",
      "  [161. 160. 157.]\n",
      "  ...\n",
      "  [ 15.  16.  18.]\n",
      "  [ 15.  16.  18.]\n",
      "  [ 16.  17.  19.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f370>\n",
      "[[ 11.234883   13.877474   88.98631   109.47893  ]\n",
      " [ 10.991049   15.480474   89.4189    109.55965  ]\n",
      " [ 10.953304   13.245213   89.53266   108.25439  ]\n",
      " [ 10.323063   13.946264   89.62644   109.13287  ]\n",
      " [ 10.795992   13.965229   88.460945  109.33169  ]\n",
      " [ 11.514709   12.727964   88.47856   108.300446 ]\n",
      " [ 11.006723   14.6509495  87.982056  107.98439  ]\n",
      " [  9.707014   13.865865   87.64772   108.73873  ]\n",
      " [ 10.619415   12.447688   88.407776  108.181885 ]\n",
      " [  9.913521   13.376024   87.799835  107.810135 ]\n",
      " [ 10.260319   15.493603   88.15308   108.52836  ]\n",
      " [ 10.042473   13.925125   87.75475   108.60336  ]\n",
      " [ 10.9520035  12.406715   88.24551   107.290436 ]\n",
      " [ 11.392858   14.742901   89.42397   109.58033  ]\n",
      " [  9.766409   14.620475   88.72808   108.652626 ]\n",
      " [ 10.126841   13.728935   87.9599    108.17492  ]\n",
      " [ 10.257251   14.377922   87.57265   108.379486 ]\n",
      " [ 11.761934   17.562054   88.38947   106.48447  ]\n",
      " [  8.806053   14.336634   88.24967   110.09391  ]\n",
      " [ 11.480937   15.418811   89.80659   108.28661  ]\n",
      " [ 10.184368   16.54863    88.23453   108.83243  ]\n",
      " [ 12.296116   15.469162   90.69975   106.72052  ]\n",
      " [ 10.431263   14.293982   88.2482    107.4084   ]\n",
      " [ 10.573186   14.278077   89.369675  107.353386 ]\n",
      " [ 10.238165   15.2145     88.919174  107.79156  ]\n",
      " [ 11.617266    9.7209835  89.248474  107.7776   ]\n",
      " [ 10.204889   13.594467   87.54849   106.22864  ]\n",
      " [ 11.296767   11.213254   89.66795   107.00034  ]\n",
      " [  9.38191    19.183357   87.787735  109.01486  ]\n",
      " [ 14.111278   11.020716   90.815094  107.32287  ]\n",
      " [  7.1851177   9.6987705  86.9554    111.11058  ]\n",
      " [ 12.993001    7.1300063  90.76548   110.94374  ]\n",
      " [  9.671009    8.8150015  91.76335   110.70649  ]\n",
      " [  8.723898   17.76315    87.61144   109.29314  ]\n",
      " [ 14.189554    7.170411   88.26267   108.08001  ]\n",
      " [  7.6921787   8.129445   89.50453   109.14822  ]\n",
      " [  6.2262573   9.8068905  86.29409   111.079956 ]\n",
      " [ 10.3474      7.2057824  88.98187   107.68718  ]\n",
      " [  6.332675    4.285692   90.018394  109.72956  ]\n",
      " [  3.5734596   3.8478384  86.024925  111.677864 ]\n",
      " [ 14.605768   22.01094    93.07646   109.83684  ]\n",
      " [ 11.773914    6.1733823  87.32528   106.06697  ]] (42, 4)\n",
      "\n",
      "[0.99694735 0.9959733  0.9930668  0.9919612  0.9800025  0.97496516\n",
      " 0.97303224 0.96713465 0.96605474 0.9629206  0.9617734  0.9495492\n",
      " 0.9416986  0.93558294 0.9196401  0.9173782  0.89068955 0.88362116\n",
      " 0.8652516  0.82237387 0.7758929  0.73298436 0.7098656  0.667522\n",
      " 0.6546433  0.55194914 0.50266933 0.3511603  0.31293538 0.2690637\n",
      " 0.24019665 0.19947954 0.17961538 0.1713412  0.13583244 0.11686364\n",
      " 0.10647601 0.08287777 0.04383178 0.02600321 0.0256175  0.02138933] (42,)\n",
      "Tensor in gpu\n",
      "test [[[106.  93.  73.]\n",
      "  [105.  92.  73.]\n",
      "  [106.  93.  74.]\n",
      "  ...\n",
      "  [125. 112.  92.]\n",
      "  [124. 111.  91.]\n",
      "  [122. 109.  89.]]\n",
      "\n",
      " [[104.  92.  72.]\n",
      "  [103.  90.  71.]\n",
      "  [103.  90.  72.]\n",
      "  ...\n",
      "  [124. 112.  92.]\n",
      "  [125. 112.  92.]\n",
      "  [123. 111.  91.]]\n",
      "\n",
      " [[104.  92.  72.]\n",
      "  [105.  92.  73.]\n",
      "  [106.  93.  74.]\n",
      "  ...\n",
      "  [125. 112.  92.]\n",
      "  [126. 113.  92.]\n",
      "  [124. 111.  91.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 87.  74.  54.]\n",
      "  [ 87.  74.  54.]\n",
      "  [ 86.  73.  53.]\n",
      "  ...\n",
      "  [ 95.  79.  61.]\n",
      "  [ 95.  79.  60.]\n",
      "  [ 94.  79.  60.]]\n",
      "\n",
      " [[ 88.  75.  55.]\n",
      "  [ 87.  74.  54.]\n",
      "  [ 87.  74.  53.]\n",
      "  ...\n",
      "  [ 95.  80.  61.]\n",
      "  [ 94.  79.  60.]\n",
      "  [ 93.  78.  60.]]\n",
      "\n",
      " [[ 87.  73.  54.]\n",
      "  [ 87.  74.  54.]\n",
      "  [ 87.  74.  54.]\n",
      "  ...\n",
      "  [ 93.  79.  60.]\n",
      "  [ 93.  79.  60.]\n",
      "  [ 92.  77.  59.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f400>\n",
      "[[  7.016666   20.20308    84.42523   107.361145 ]\n",
      " [  7.5231395  20.803604   84.54865   107.990295 ]\n",
      " [  6.477608   20.933393   84.94276   107.69599  ]\n",
      " [  6.5354567  20.927732   84.67202   106.48345  ]\n",
      " [  7.258604   22.989979   83.61351   106.793205 ]\n",
      " [  7.9432693  19.77844    84.56825   108.58971  ]\n",
      " [  7.8595157  19.411036   84.95395   105.92771  ]\n",
      " [  7.7014513  23.210808   85.14623   106.652725 ]\n",
      " [  7.5672727  22.738962   84.47223   107.82593  ]\n",
      " [  6.0501385  18.519032   83.558044  106.80579  ]\n",
      " [  7.3610897  19.467712   83.92819   107.12456  ]\n",
      " [  8.243824   19.350153   85.46666   108.185905 ]\n",
      " [  6.5069113  19.851429   83.09209   105.63905  ]\n",
      " [  6.7314725  19.568775   83.3927    105.90953  ]\n",
      " [  7.7177534  18.255272   84.76264   108.765396 ]\n",
      " [  7.876779   19.07999    86.09014   108.003815 ]\n",
      " [  7.37127    21.259266   83.60082   108.47687  ]\n",
      " [  6.348353   19.648954   83.54048   105.86751  ]\n",
      " [  7.056954   19.424458   83.80418   106.870476 ]\n",
      " [  6.2993364  18.453049   84.86005   107.79341  ]\n",
      " [  6.595388   19.864069   84.390854  108.694214 ]\n",
      " [  6.825824   17.437586   83.77353   107.383835 ]\n",
      " [  6.27004    20.552841   83.86458   106.182755 ]\n",
      " [  6.720481   20.479765   84.72165   105.94827  ]\n",
      " [  7.5323586  20.13432    83.31479   105.4587   ]\n",
      " [  8.466342   23.786076   86.72876   105.777626 ]\n",
      " [  7.25812    19.268684   85.84513   106.734436 ]\n",
      " [  9.022373   21.929852   85.30853   106.6616   ]\n",
      " [  4.5295362  15.01759    82.245224  109.743355 ]\n",
      " [  3.9105935  15.946026   81.57394   108.8515   ]\n",
      " [  5.192422   26.8056     80.829094  109.497025 ]\n",
      " [  8.714254   13.110256   85.95326   108.81529  ]\n",
      " [  4.085157   17.10889    81.38842   106.84361  ]\n",
      " [  1.2572184   8.848687   81.38838   109.38881  ]\n",
      " [  3.3939261  10.617526   87.80069   110.97997  ]\n",
      " [  2.8823557   8.476903   87.28415   109.23806  ]\n",
      " [  7.893098   15.338268   86.431725  109.58462  ]\n",
      " [  2.2192063   6.0268903  87.91484   111.720505 ]\n",
      " [ -1.1303964  20.246899   79.053955  112.45792  ]] (39, 4)\n",
      "\n",
      "[0.9980609  0.99804544 0.996402   0.995419   0.9486833  0.94767576\n",
      " 0.9305169  0.9272001  0.922048   0.92001545 0.91969144 0.9043818\n",
      " 0.90000904 0.87662435 0.8758327  0.83804387 0.8252027  0.8216766\n",
      " 0.77669084 0.75890434 0.73176545 0.678025   0.61244875 0.5845787\n",
      " 0.5404355  0.49495196 0.48812574 0.43936938 0.2421864  0.20635952\n",
      " 0.07016718 0.06584393 0.04286761 0.04193138 0.04152957 0.03404691\n",
      " 0.03316287 0.0273087  0.02149576] (39,)\n",
      "Tensor in gpu\n",
      "test [[[ 43.  33.  30.]\n",
      "  [ 38.  27.  25.]\n",
      "  [ 34.  23.  21.]\n",
      "  ...\n",
      "  [105.  65.  36.]\n",
      "  [126.  85.  48.]\n",
      "  [132.  96.  65.]]\n",
      "\n",
      " [[ 53.  42.  39.]\n",
      "  [ 45.  34.  31.]\n",
      "  [ 40.  30.  27.]\n",
      "  ...\n",
      "  [ 80.  46.  25.]\n",
      "  [107.  71.  41.]\n",
      "  [123.  89.  60.]]\n",
      "\n",
      " [[ 60.  48.  45.]\n",
      "  [ 55.  44.  40.]\n",
      "  [ 48.  37.  34.]\n",
      "  ...\n",
      "  [ 72.  35.  19.]\n",
      "  [ 88.  54.  33.]\n",
      "  [111.  79.  52.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[156. 132. 100.]\n",
      "  [155. 132.  99.]\n",
      "  [155. 132.  99.]\n",
      "  ...\n",
      "  [143. 116.  86.]\n",
      "  [141. 115.  84.]\n",
      "  [139. 114.  83.]]\n",
      "\n",
      " [[157. 134. 101.]\n",
      "  [156. 133.  99.]\n",
      "  [155. 132.  98.]\n",
      "  ...\n",
      "  [145. 119.  88.]\n",
      "  [144. 119.  88.]\n",
      "  [143. 118.  87.]]\n",
      "\n",
      " [[157. 133. 101.]\n",
      "  [155. 132.  99.]\n",
      "  [155. 132.  98.]\n",
      "  ...\n",
      "  [146. 121.  89.]\n",
      "  [145. 120.  89.]\n",
      "  [144. 119.  88.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f610>\n",
      "[[ 2.62653809e+01  1.17057648e+01  9.94340210e+01  1.06132401e+02]\n",
      " [ 2.53206367e+01  1.10903740e+01  9.94114456e+01  1.06028931e+02]\n",
      " [ 2.61537628e+01  8.80580521e+00  1.00157471e+02  1.06989288e+02]\n",
      " [ 2.63244877e+01  1.22275658e+01  9.91536865e+01  1.07986626e+02]\n",
      " [ 2.60109863e+01  1.05315857e+01  9.94224625e+01  1.06618652e+02]\n",
      " [ 2.56868534e+01  1.16211205e+01  9.93554001e+01  1.08207687e+02]\n",
      " [ 2.44646053e+01  8.99744225e+00  9.85389557e+01  1.08405220e+02]\n",
      " [ 2.43501625e+01  9.75145149e+00  9.85956268e+01  1.05818871e+02]\n",
      " [ 2.51357517e+01  9.96759415e+00  9.79136963e+01  1.05751526e+02]\n",
      " [ 2.50835457e+01  9.53674698e+00  9.89612427e+01  1.04829758e+02]\n",
      " [ 2.55260944e+01  7.98864746e+00  9.87457886e+01  1.06490181e+02]\n",
      " [ 2.58925991e+01  9.21549797e+00  9.80146637e+01  1.04923233e+02]\n",
      " [ 2.54648743e+01  8.92275429e+00  9.99702759e+01  1.05968475e+02]\n",
      " [ 2.53962059e+01  9.81086159e+00  9.98296051e+01  1.06964020e+02]\n",
      " [ 2.64543972e+01  1.01615810e+01  9.83422775e+01  1.04388687e+02]\n",
      " [ 2.56408405e+01  9.90150452e+00  9.81874542e+01  1.05514992e+02]\n",
      " [ 2.55443573e+01  1.01405325e+01  9.87180634e+01  1.06761421e+02]\n",
      " [ 2.52766342e+01  1.02172298e+01  9.90572662e+01  1.08428185e+02]\n",
      " [ 2.46510658e+01  1.23169975e+01  9.71852722e+01  1.06077873e+02]\n",
      " [ 2.65736217e+01  1.24793711e+01  9.86884766e+01  1.08102852e+02]\n",
      " [ 2.77125168e+01  1.29427862e+01  9.97984390e+01  1.07779427e+02]\n",
      " [ 2.50266342e+01  1.29328928e+01  9.70235596e+01  1.08175087e+02]\n",
      " [ 2.61712894e+01  6.93072605e+00  9.69331970e+01  1.06982452e+02]\n",
      " [ 2.61318798e+01  5.18004847e+00  9.72847137e+01  1.08675636e+02]\n",
      " [ 2.68865128e+01  1.10149918e+01  1.03004562e+02  1.10578285e+02]\n",
      " [ 2.57688408e+01  9.95596504e+00  1.00725311e+02  1.07339615e+02]\n",
      " [ 2.56708984e+01  8.56103706e+00  1.00948883e+02  1.07041306e+02]\n",
      " [ 2.40970173e+01  8.02237320e+00  9.65986328e+01  1.05684380e+02]\n",
      " [ 2.56151199e+01  8.01860809e+00  9.96093369e+01  1.06426399e+02]\n",
      " [ 2.31604729e+01  4.21989632e+00  9.94877014e+01  1.09982300e+02]\n",
      " [ 2.64940414e+01  3.52879906e+00  9.97220154e+01  1.10237038e+02]\n",
      " [ 2.40643597e+01  5.14567184e+00  9.62999573e+01  1.07637360e+02]\n",
      " [ 2.73514233e+01  1.51487112e+01  1.04583450e+02  1.07027863e+02]\n",
      " [ 2.25497513e+01  4.78551006e+00  9.96667786e+01  1.07812325e+02]\n",
      " [ 2.66398277e+01  5.85734701e+00  1.02587669e+02  1.12447723e+02]\n",
      " [ 2.38969383e+01  7.04205704e+00  9.50731201e+01  1.10893082e+02]\n",
      " [ 2.62438507e+01  1.46879902e+01  1.02009682e+02  1.06222847e+02]\n",
      " [ 2.43739262e+01  4.56585884e+00  1.01403709e+02  1.07920372e+02]\n",
      " [ 2.27121315e+01  5.75716782e+00  9.86549149e+01  1.09334869e+02]\n",
      " [ 2.52602119e+01 -7.08293915e-03  9.99004669e+01  1.08204269e+02]\n",
      " [ 2.39898777e+01 -8.30926895e-02  1.00222336e+02  1.11355110e+02]\n",
      " [ 2.93476105e+01  9.27666092e+00  1.04625229e+02  1.06539337e+02]] (42, 4)\n",
      "\n",
      "[0.99497163 0.9919247  0.9895084  0.98609424 0.9833988  0.97356343\n",
      " 0.9259362  0.92535573 0.918077   0.9105025  0.90831786 0.9077192\n",
      " 0.8957595  0.8830603  0.8798932  0.8589003  0.8445156  0.84304696\n",
      " 0.72224736 0.71560186 0.64781195 0.49453622 0.36646122 0.3645327\n",
      " 0.34513462 0.325423   0.30982372 0.2937556  0.2869473  0.25645077\n",
      " 0.16238503 0.15143771 0.12339541 0.11737509 0.11731499 0.10721048\n",
      " 0.10625529 0.09247959 0.08123967 0.06801117 0.04589477 0.02682472] (42,)\n",
      "Tensor in gpu\n",
      "test [[[238. 238. 240.]\n",
      "  [238. 238. 240.]\n",
      "  [238. 238. 240.]\n",
      "  ...\n",
      "  [239. 239. 241.]\n",
      "  [239. 239. 241.]\n",
      "  [239. 239. 241.]]\n",
      "\n",
      " [[238. 238. 240.]\n",
      "  [238. 238. 240.]\n",
      "  [238. 238. 240.]\n",
      "  ...\n",
      "  [239. 239. 241.]\n",
      "  [239. 239. 241.]\n",
      "  [239. 239. 241.]]\n",
      "\n",
      " [[238. 238. 240.]\n",
      "  [238. 238. 240.]\n",
      "  [238. 238. 240.]\n",
      "  ...\n",
      "  [239. 239. 241.]\n",
      "  [239. 239. 241.]\n",
      "  [239. 239. 241.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[243. 243. 245.]\n",
      "  [243. 243. 245.]\n",
      "  [243. 243. 245.]\n",
      "  ...\n",
      "  [236. 235. 240.]\n",
      "  [236. 235. 240.]\n",
      "  [236. 235. 240.]]\n",
      "\n",
      " [[243. 243. 245.]\n",
      "  [243. 243. 245.]\n",
      "  [243. 243. 245.]\n",
      "  ...\n",
      "  [236. 235. 240.]\n",
      "  [236. 235. 240.]\n",
      "  [236. 235. 240.]]\n",
      "\n",
      " [[243. 243. 245.]\n",
      "  [243. 243. 245.]\n",
      "  [243. 243. 245.]\n",
      "  ...\n",
      "  [236. 235. 240.]\n",
      "  [236. 235. 240.]\n",
      "  [236. 235. 240.]]] (534, 800, 3)\n",
      "torch.Size([1, 3, 534, 800])\n",
      "Forward time: 0.0041\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7fa90>\n",
      "[[268.4709  152.96556 463.1173  374.7465 ]\n",
      " [269.1633  151.15402 461.4503  369.95612]\n",
      " [269.5254  153.35114 460.93973 370.16867]\n",
      " [265.17084 153.71004 459.52454 371.07623]\n",
      " [267.35388 149.06525 463.44183 368.0342 ]\n",
      " [267.95978 147.15602 459.92255 371.17184]\n",
      " [264.02606 148.92426 463.00174 368.72885]\n",
      " [268.16367 152.21904 463.13086 368.9863 ]\n",
      " [266.14658 151.88242 465.20325 370.55475]\n",
      " [266.0091  153.62874 460.99738 371.19177]\n",
      " [268.38745 154.97269 462.1215  366.25485]\n",
      " [266.39563 151.48282 461.38693 368.3821 ]\n",
      " [269.89163 157.56111 463.49002 367.93848]\n",
      " [269.251   156.24677 463.83777 370.58887]\n",
      " [270.15958 156.31981 463.8198  366.29828]\n",
      " [270.3531  150.79767 460.3368  365.79697]\n",
      " [267.4413  149.98236 463.94354 367.76633]\n",
      " [263.07025 152.56396 459.41467 366.69882]\n",
      " [271.37653 151.0472  460.0169  369.88483]\n",
      " [261.00784 150.43631 459.68805 369.79877]\n",
      " [269.7726  151.926   459.93015 371.13263]\n",
      " [269.70395 150.16592 459.3994  370.91736]\n",
      " [270.19272 153.26128 459.4038  369.10934]\n",
      " [267.7746  151.99036 464.50537 366.80823]\n",
      " [272.43314 144.05722 458.43362 371.97278]\n",
      " [270.1559  152.1834  461.10916 371.5504 ]\n",
      " [271.58078 144.72003 458.88586 371.02545]\n",
      " [271.92224 147.63112 458.86868 371.15936]\n",
      " [270.03183 149.51308 460.80585 370.40784]\n",
      " [269.81674 147.87712 459.70544 371.9877 ]\n",
      " [272.23367 153.42776 461.17365 370.97055]\n",
      " [272.71198 144.61258 457.5252  370.1162 ]\n",
      " [270.65848 145.81056 458.15643 373.21744]\n",
      " [271.75543 146.49757 460.44653 368.0602 ]\n",
      " [269.6239  151.81131 460.29474 370.46893]\n",
      " [269.27966 146.45132 467.98392 368.8247 ]\n",
      " [270.82068 147.63036 458.3744  370.51483]\n",
      " [271.4029  151.09541 461.03738 375.69244]\n",
      " [271.94894 145.02493 460.1521  371.0295 ]\n",
      " [270.48044 142.31433 458.68732 372.3114 ]\n",
      " [273.33463 151.76227 458.96198 373.40326]\n",
      " [267.1171  156.13785 463.05948 367.97565]\n",
      " [269.3802  151.84927 460.50247 369.46487]\n",
      " [270.61514 139.74539 458.72568 372.26605]\n",
      " [269.62155 153.14497 461.54398 370.24854]\n",
      " [271.08524 143.7106  461.3716  368.51218]\n",
      " [269.37796 150.0522  462.15048 369.07047]\n",
      " [267.10574 155.07892 465.71823 367.68176]\n",
      " [272.2554  149.90349 460.95596 374.40457]\n",
      " [272.69263 151.20927 457.3349  372.58246]\n",
      " [266.63147 148.91597 464.72803 368.07886]\n",
      " [256.71994 151.25612 465.32373 372.21945]\n",
      " [272.69247 149.11035 459.57498 371.58594]\n",
      " [270.83643 147.46495 461.92755 372.593  ]\n",
      " [268.89413 154.19304 460.96524 371.85864]\n",
      " [272.55295 149.14946 460.1305  371.942  ]\n",
      " [266.78897 149.30048 466.3581  366.83466]\n",
      " [272.85324 143.55203 461.03564 373.67297]\n",
      " [268.23148 155.27992 465.1248  372.87955]\n",
      " [274.89017 155.56053 463.52676 367.42233]\n",
      " [262.8834  147.79178 467.49658 369.97403]\n",
      " [260.9916  145.88179 463.6462  371.5515 ]\n",
      " [275.56363 148.77267 461.74442 371.50668]\n",
      " [272.2992  150.86148 463.00827 370.78342]\n",
      " [271.6769  156.5126  464.70538 368.55405]\n",
      " [264.74777 137.45636 469.50818 369.0518 ]\n",
      " [272.17926 146.40097 465.3166  371.25616]\n",
      " [268.4886  144.4245  467.1774  373.84537]\n",
      " [252.80122 154.96953 463.8326  372.16937]\n",
      " [274.94498 148.30966 456.13257 372.51822]\n",
      " [275.5619  147.15077 458.0429  372.73636]\n",
      " [279.32086 153.44579 465.1268  368.34137]\n",
      " [267.0815  152.22595 456.3502  369.02625]\n",
      " [272.44403 148.49129 452.46616 369.27127]\n",
      " [264.12708 154.47849 462.98712 372.01602]\n",
      " [281.58722 146.20436 460.11926 370.232  ]\n",
      " [249.88051 154.13864 465.65704 373.1703 ]\n",
      " [262.9681  156.28563 453.30658 366.6647 ]\n",
      " [258.7809  154.21646 457.70697 367.3888 ]\n",
      " [274.95255 150.32338 465.65686 374.38742]\n",
      " [278.98306 155.07425 454.33908 373.66718]\n",
      " [271.53488 160.80508 464.65125 371.76852]\n",
      " [262.4715  155.02135 451.64505 363.88464]\n",
      " [253.25151 148.45726 468.9249  373.35245]\n",
      " [256.18542 156.00366 460.18    371.00653]\n",
      " [279.12436 155.22014 458.08725 373.22372]\n",
      " [261.76456 140.08716 458.15598 369.07782]\n",
      " [284.16672 162.65799 470.17874 365.96643]\n",
      " [274.30005 134.14699 478.55588 363.5658 ]\n",
      " [273.9223  160.57753 455.49963 375.74802]\n",
      " [253.6149  136.43347 459.38263 368.8116 ]\n",
      " [274.79382 124.77482 481.60678 365.2509 ]\n",
      " [287.7902  160.01888 471.49677 362.28586]\n",
      " [280.76303 155.78989 460.78137 373.6993 ]\n",
      " [266.48114 147.92467 450.52963 363.44678]\n",
      " [247.95126 148.94911 464.77982 378.68835]\n",
      " [255.72841 156.89185 461.13177 372.21738]\n",
      " [281.46466 160.13058 469.6986  367.0519 ]] (98, 4)\n",
      "\n",
      "[0.9996699  0.9995504  0.9993832  0.9992812  0.99921274 0.99915075\n",
      " 0.9989544  0.9986594  0.99763465 0.99740964 0.9968566  0.9946979\n",
      " 0.9945592  0.9943843  0.99418676 0.99260145 0.99040973 0.9737268\n",
      " 0.9728855  0.96690804 0.953113   0.9513223  0.9503985  0.9479361\n",
      " 0.9458907  0.94433594 0.93409175 0.92889196 0.9269068  0.91683364\n",
      " 0.91480386 0.91006106 0.90768754 0.8988201  0.8934252  0.89036137\n",
      " 0.88831234 0.8820487  0.8818208  0.8782511  0.8741114  0.85546976\n",
      " 0.84241104 0.82795835 0.81454855 0.80707526 0.77385926 0.714793\n",
      " 0.71203846 0.70436424 0.69279253 0.65083295 0.6187537  0.6132196\n",
      " 0.603078   0.5396896  0.52873063 0.51534176 0.46229976 0.421447\n",
      " 0.41163313 0.40034083 0.38684237 0.3352784  0.32809144 0.3175076\n",
      " 0.3106962  0.28839403 0.28823528 0.28451642 0.27015585 0.20572543\n",
      " 0.20291473 0.14617117 0.13053833 0.11491367 0.10545254 0.10341932\n",
      " 0.08342976 0.07791467 0.06161819 0.05859497 0.0585021  0.05465804\n",
      " 0.04568168 0.04433955 0.03809082 0.03528606 0.03352593 0.03133155\n",
      " 0.03022758 0.03020507 0.02945676 0.02846572 0.02694606 0.02384546\n",
      " 0.02287353 0.02153289] (98,)\n",
      "Tensor in gpu\n",
      "test [[[ 43.  46.  43.]\n",
      "  [ 45.  48.  46.]\n",
      "  [ 47.  49.  48.]\n",
      "  ...\n",
      "  [ 28.  26.  22.]\n",
      "  [ 28.  26.  22.]\n",
      "  [ 28.  25.  22.]]\n",
      "\n",
      " [[ 42.  45.  42.]\n",
      "  [ 44.  47.  45.]\n",
      "  [ 44.  47.  45.]\n",
      "  ...\n",
      "  [ 28.  26.  23.]\n",
      "  [ 28.  26.  23.]\n",
      "  [ 27.  25.  21.]]\n",
      "\n",
      " [[ 41.  44.  41.]\n",
      "  [ 43.  46.  43.]\n",
      "  [ 44.  47.  45.]\n",
      "  ...\n",
      "  [ 28.  27.  23.]\n",
      "  [ 29.  27.  24.]\n",
      "  [ 28.  26.  23.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[152. 138. 110.]\n",
      "  [152. 138. 110.]\n",
      "  [152. 138. 110.]\n",
      "  ...\n",
      "  [ 52.  48.  71.]\n",
      "  [ 58.  53.  74.]\n",
      "  [ 68.  61.  77.]]\n",
      "\n",
      " [[152. 138. 110.]\n",
      "  [152. 138. 109.]\n",
      "  [152. 138. 109.]\n",
      "  ...\n",
      "  [ 47.  44.  70.]\n",
      "  [ 46.  44.  69.]\n",
      "  [ 48.  44.  70.]]\n",
      "\n",
      " [[153. 139. 110.]\n",
      "  [152. 137. 109.]\n",
      "  [153. 139. 110.]\n",
      "  ...\n",
      "  [ 47.  44.  70.]\n",
      "  [ 45.  43.  68.]\n",
      "  [ 45.  42.  68.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0044\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f1f0>\n",
      "[[ 20.234669     9.356669    97.51987    107.312546  ]\n",
      " [ 19.933815     8.899946    97.6708     107.17849   ]\n",
      " [ 19.931877    10.612041    96.990265   109.24389   ]\n",
      " [ 19.157734     9.575769    97.30301    107.23243   ]\n",
      " [ 20.617384     9.870887    98.11748    106.803116  ]\n",
      " [ 20.032047     9.021191    95.976654   105.40572   ]\n",
      " [ 19.268112     9.102829    96.84267    105.89245   ]\n",
      " [ 19.534657     8.53648     96.26677    105.43526   ]\n",
      " [ 19.001976     9.762393    95.84925    105.18969   ]\n",
      " [ 19.172005    11.189028    96.927216   106.514725  ]\n",
      " [ 18.562738     8.60987     96.25637    106.49143   ]\n",
      " [ 18.959438     8.384484    96.323784   106.212395  ]\n",
      " [ 19.1982       8.841197    96.14052    107.44352   ]\n",
      " [ 19.383745     8.6960335   96.0516     107.368454  ]\n",
      " [ 20.650713     9.494654    97.55739    106.63799   ]\n",
      " [ 18.81977      8.331706    96.953186   106.81477   ]\n",
      " [ 19.620338     9.227154    96.690346   109.56856   ]\n",
      " [ 18.99868      7.5705705   94.764244   108.43534   ]\n",
      " [ 19.777418    11.217396    97.11633    106.96129   ]\n",
      " [ 19.16206      8.164239    97.24893    106.63927   ]\n",
      " [ 20.30481      7.8901305   95.73352    105.34055   ]\n",
      " [ 20.655226    12.9244175   96.2139     106.922035  ]\n",
      " [ 18.98355      7.077091    97.28       106.95259   ]\n",
      " [ 19.49054      7.5414977   96.25995    104.563194  ]\n",
      " [ 19.537289     6.945823    94.894165   106.443665  ]\n",
      " [ 20.703499    11.451457    97.603134   107.588066  ]\n",
      " [ 19.688791     9.544197    97.47975    106.118195  ]\n",
      " [ 20.131226     9.077253    97.410965   105.42368   ]\n",
      " [ 20.247318     5.2199593   95.1483     110.6205    ]\n",
      " [ 18.615126     4.9134436   97.49115    107.27365   ]\n",
      " [ 16.481613     5.599514    94.90403    108.83717   ]\n",
      " [ 21.660118    15.051796    98.3141     108.35285   ]\n",
      " [ 18.11694      4.1221704   97.348076   107.962     ]\n",
      " [ 20.77477      9.502541   100.78869    111.548904  ]\n",
      " [ 16.028948     0.72068405  97.22104    109.71786   ]\n",
      " [ 20.742397     0.33379936  98.72051    109.08016   ]\n",
      " [ 21.08188      1.6708593   97.78296    110.00094   ]\n",
      " [ 15.800796    -1.3292828   94.8586     109.49949   ]\n",
      " [ 17.755075    16.990597    93.370224   108.99506   ]] (39, 4)\n",
      "\n",
      "[0.9981236  0.99533963 0.99375993 0.9907348  0.98352504 0.98225284\n",
      " 0.9816992  0.9776594  0.9756575  0.9720063  0.9710513  0.9698989\n",
      " 0.9677941  0.96624905 0.9658214  0.9649607  0.95695245 0.94364506\n",
      " 0.942763   0.9398275  0.89702135 0.8634788  0.81866604 0.7263398\n",
      " 0.72091496 0.6651891  0.6025518  0.5996089  0.49106964 0.44704893\n",
      " 0.36353153 0.3292484  0.25534353 0.23732531 0.10362184 0.0632209\n",
      " 0.03565795 0.03046145 0.0270016 ] (39,)\n",
      "Tensor in gpu\n",
      "test [[[148. 119.  59.]\n",
      "  [158. 130.  66.]\n",
      "  [162. 134.  68.]\n",
      "  ...\n",
      "  [226. 209. 146.]\n",
      "  [224. 206. 141.]\n",
      "  [220. 201. 134.]]\n",
      "\n",
      " [[138. 110.  52.]\n",
      "  [152. 124.  61.]\n",
      "  [157. 128.  64.]\n",
      "  ...\n",
      "  [225. 209. 145.]\n",
      "  [225. 207. 143.]\n",
      "  [222. 204. 136.]]\n",
      "\n",
      " [[137. 109.  51.]\n",
      "  [144. 115.  56.]\n",
      "  [153. 125.  62.]\n",
      "  ...\n",
      "  [225. 207. 141.]\n",
      "  [225. 208. 142.]\n",
      "  [222. 204. 136.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[229. 214. 169.]\n",
      "  [229. 214. 169.]\n",
      "  [230. 215. 170.]\n",
      "  ...\n",
      "  [243. 232. 191.]\n",
      "  [241. 229. 185.]\n",
      "  [238. 224. 176.]]\n",
      "\n",
      " [[227. 211. 163.]\n",
      "  [227. 212. 163.]\n",
      "  [227. 211. 163.]\n",
      "  ...\n",
      "  [242. 231. 188.]\n",
      "  [240. 227. 180.]\n",
      "  [237. 222. 172.]]\n",
      "\n",
      " [[222. 204. 153.]\n",
      "  [223. 206. 155.]\n",
      "  [222. 204. 153.]\n",
      "  ...\n",
      "  [242. 230. 184.]\n",
      "  [239. 225. 175.]\n",
      "  [236. 221. 169.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f6d0>\n",
      "[[ 22.888979   22.287333  102.17115   105.267136 ]\n",
      " [ 24.189095   21.435862  102.45085   105.01306  ]\n",
      " [ 23.816076   20.50217   102.32366   105.92574  ]\n",
      " [ 22.861645   21.217958  101.9987    104.360664 ]\n",
      " [ 24.904959   20.77243   100.90645   106.28001  ]\n",
      " [ 22.272676   18.353785  101.44209   105.78439  ]\n",
      " [ 21.809008   19.34116   102.620026  104.88694  ]\n",
      " [ 23.54948    19.778576  101.64008   107.5407   ]\n",
      " [ 23.392939   23.767746  102.01223   105.52298  ]\n",
      " [ 22.795643   18.312346  100.95333   105.319016 ]\n",
      " [ 23.849724   22.898514  102.147415  105.99597  ]\n",
      " [ 23.679998   22.371407  101.62235   105.1759   ]\n",
      " [ 22.803135   18.488495  101.15676   104.06495  ]\n",
      " [ 22.015867   18.380318  100.75926   105.26381  ]\n",
      " [ 21.836824   18.840324  101.109634  104.02146  ]\n",
      " [ 23.161095   17.563469  103.30211   105.80972  ]\n",
      " [ 21.59069    16.907646  100.04512   107.82928  ]\n",
      " [ 22.034773   19.231766  101.14595   105.853714 ]\n",
      " [ 23.14394    20.96767   100.557846  104.56343  ]\n",
      " [ 22.686108   19.498253  101.93206   105.379196 ]\n",
      " [ 22.647478   18.307772  101.310555  105.36588  ]\n",
      " [ 23.161644   18.706734  102.4648    106.548584 ]\n",
      " [ 23.119003   20.819115  102.68584   105.02063  ]\n",
      " [ 22.553516   18.356045  103.01387   103.7502   ]\n",
      " [ 22.48427    17.647373  102.53999   104.702385 ]\n",
      " [ 23.193504   25.326498  105.51327   105.827095 ]\n",
      " [ 23.172262   20.019407  103.605225  107.628296 ]\n",
      " [ 24.007896   23.159622  102.909645  105.17279  ]\n",
      " [ 22.872076   12.885679  102.02598   104.0965   ]\n",
      " [ 21.153555   15.487731   98.32211   104.21432  ]\n",
      " [ 19.74509    12.202148  102.0895    108.72421  ]\n",
      " [ 22.928211   12.299845  103.87283   103.47247  ]\n",
      " [ 19.771147    8.787153   98.83361   105.79592  ]\n",
      " [ 19.97532    10.477236  103.28382   106.85907  ]\n",
      " [ 21.771406   14.700172  103.869064  109.8617   ]\n",
      " [ 18.86287    10.110719  102.79432   107.118576 ]\n",
      " [ 19.030533    7.127917  101.20752   106.2142   ]\n",
      " [ 21.084425   27.980003   97.04106   107.99007  ]\n",
      " [ 24.29478     9.7520485  96.38536   104.83304  ]] (39, 4)\n",
      "\n",
      "[0.9964863  0.99614525 0.99538404 0.9951102  0.94485414 0.9117892\n",
      " 0.91165054 0.9087592  0.9025449  0.8998818  0.8967486  0.889569\n",
      " 0.877045   0.86284834 0.8591258  0.8441403  0.8238781  0.8222225\n",
      " 0.8157962  0.7784134  0.7741051  0.75929433 0.6186154  0.599464\n",
      " 0.53962135 0.53675306 0.49905777 0.32045093 0.14897785 0.08484446\n",
      " 0.08290812 0.05167031 0.05112568 0.05092771 0.04563025 0.03863784\n",
      " 0.03339531 0.03038787 0.02743205] (39,)\n",
      "Tensor in gpu\n",
      "test [[[  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  ...\n",
      "  [ 92. 132. 160.]\n",
      "  [ 99. 142. 171.]\n",
      "  [103. 147. 177.]]\n",
      "\n",
      " [[  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  ...\n",
      "  [102. 146. 176.]\n",
      "  [102. 146. 176.]\n",
      "  [103. 147. 177.]]\n",
      "\n",
      " [[  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  ...\n",
      "  [103. 147. 177.]\n",
      "  [102. 146. 176.]\n",
      "  [102. 147. 176.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 18.  24.  17.]\n",
      "  [ 19.  25.  17.]\n",
      "  [ 20.  26.  17.]\n",
      "  ...\n",
      "  [ 21.  35.  32.]\n",
      "  [ 21.  35.  32.]\n",
      "  [ 22.  36.  33.]]\n",
      "\n",
      " [[ 14.  19.  14.]\n",
      "  [ 16.  22.  14.]\n",
      "  [ 15.  21.  14.]\n",
      "  ...\n",
      "  [ 22.  38.  35.]\n",
      "  [ 21.  38.  35.]\n",
      "  [ 21.  39.  36.]]\n",
      "\n",
      " [[ 12.  17.  13.]\n",
      "  [ 12.  18.  12.]\n",
      "  [ 13.  20.  13.]\n",
      "  ...\n",
      "  [ 21.  40.  37.]\n",
      "  [ 20.  39.  37.]\n",
      "  [ 20.  39.  37.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f370>\n",
      "[[  9.97403    20.233538   87.439705  109.719376 ]\n",
      " [ 10.243483   20.86928    87.72103   109.04089  ]\n",
      " [ 10.239304   21.025124   87.626465  110.01665  ]\n",
      " [  9.960272   20.46935    87.92087   109.13135  ]\n",
      " [  9.823639   19.47527    87.02227   109.36777  ]\n",
      " [  8.91918    18.684277   86.806564  109.45165  ]\n",
      " [ 10.6789665  18.152706   87.750656  107.66123  ]\n",
      " [ 10.362407   19.133091   87.19426   107.854935 ]\n",
      " [ 11.5066185  23.659039   87.65395   107.9217   ]\n",
      " [  9.56077    18.557201   86.12915   108.34346  ]\n",
      " [ 11.07497    18.365414   87.40367   110.25999  ]\n",
      " [ 10.625521   22.567833   87.06323   108.731064 ]\n",
      " [ 10.1007185  19.822643   87.740456  109.94101  ]\n",
      " [ 11.253822   18.820608   87.22393   109.640495 ]\n",
      " [  9.525151   19.575077   86.35034   108.29634  ]\n",
      " [ 10.05052    19.110247   88.49614   109.30242  ]\n",
      " [  9.672588   18.460138   86.97693   108.5622   ]\n",
      " [ 10.982381   22.385727   88.766174  108.06184  ]\n",
      " [ 11.753082   20.525204   87.53689   109.598015 ]\n",
      " [  8.409716   16.401413   87.80958   109.947845 ]\n",
      " [  9.657357   23.327152   86.714966  108.47095  ]\n",
      " [  9.977044   17.091179   86.24886   109.60765  ]\n",
      " [ 10.818739   19.054245   87.96282   107.80452  ]\n",
      " [  9.082468   19.843262   87.21228   107.67495  ]\n",
      " [ 10.806612   18.116253   88.0457    108.57494  ]\n",
      " [  9.913528   20.176651   88.012375  107.498474 ]\n",
      " [  9.89579    19.75634    86.68355   106.6861   ]\n",
      " [  9.197053   22.063532   85.20102   108.90069  ]\n",
      " [ 11.639322   14.056433   86.98471   111.0095   ]\n",
      " [  6.725254   12.276226   85.214386  110.80346  ]\n",
      " [ 10.64209    16.659834   87.8869    110.92551  ]\n",
      " [  6.4537024  14.604891   84.873184  110.746925 ]\n",
      " [ 13.92378    26.057108   91.56908   111.82614  ]\n",
      " [ 12.098294   10.385171   91.19544   112.21605  ]\n",
      " [ 15.901085   14.030365   90.47072   108.11839  ]\n",
      " [  8.14591     9.54093    90.21671   111.14772  ]\n",
      " [  6.965213   28.250006   81.794334  110.43492  ]\n",
      " [  7.6576486  10.003296   88.595215  110.02855  ]\n",
      " [ 16.205107    9.741634   87.11011   106.38217  ]\n",
      " [  6.719186   15.306395   80.4802    103.47667  ]\n",
      " [ 13.995977   20.026123   93.17794   115.35395  ]] (41, 4)\n",
      "\n",
      "[0.99789846 0.9970667  0.99699867 0.9966264  0.9479821  0.9465746\n",
      " 0.94585633 0.9393743  0.93697155 0.93494886 0.9308127  0.93072474\n",
      " 0.9215646  0.90859276 0.8951149  0.8632254  0.78483087 0.77731085\n",
      " 0.76183015 0.7561873  0.73541    0.73474544 0.71794486 0.7001527\n",
      " 0.6904898  0.6277124  0.5713105  0.4154447  0.29176405 0.19310336\n",
      " 0.15328552 0.11497314 0.05990843 0.04800428 0.04661424 0.0431564\n",
      " 0.02788633 0.02635805 0.02603174 0.02173193 0.02048055] (41,)\n",
      "Tensor in gpu\n",
      "test [[[ 79.  69.  55.]\n",
      "  [104.  89.  67.]\n",
      "  [124. 106.  80.]\n",
      "  ...\n",
      "  [ 19.  16.  12.]\n",
      "  [ 17.  14.  11.]\n",
      "  [ 17.  14.  11.]]\n",
      "\n",
      " [[ 95.  79.  59.]\n",
      "  [111.  93.  67.]\n",
      "  [128. 108.  77.]\n",
      "  ...\n",
      "  [ 19.  16.  12.]\n",
      "  [ 18.  15.  11.]\n",
      "  [ 17.  14.  11.]]\n",
      "\n",
      " [[115.  96.  66.]\n",
      "  [124. 104.  74.]\n",
      "  [126. 104.  74.]\n",
      "  ...\n",
      "  [ 19.  16.  12.]\n",
      "  [ 19.  16.  12.]\n",
      "  [ 20.  17.  13.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 60.  50.  34.]\n",
      "  [ 80.  73.  66.]\n",
      "  [108. 103. 105.]\n",
      "  ...\n",
      "  [ 11.  10.   8.]\n",
      "  [ 13.  10.   8.]\n",
      "  [ 14.  12.   8.]]\n",
      "\n",
      " [[ 79.  71.  63.]\n",
      "  [111. 107. 110.]\n",
      "  [120. 117. 121.]\n",
      "  ...\n",
      "  [ 11.   9.   7.]\n",
      "  [ 11.   9.   7.]\n",
      "  [ 16.  13.  10.]]\n",
      "\n",
      " [[109. 105. 107.]\n",
      "  [122. 119. 124.]\n",
      "  [116. 111. 116.]\n",
      "  ...\n",
      "  [ 11.   9.   7.]\n",
      "  [ 14.  12.   9.]\n",
      "  [ 20.  16.  11.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f400>\n",
      "[[  6.98788    10.139551   90.826416  109.12848  ]\n",
      " [  6.8857517   9.372822   91.62749   108.46767  ]\n",
      " [  7.715647    8.901172   91.00726   107.03854  ]\n",
      " [  7.333529   10.150953   89.46142   107.37038  ]\n",
      " [  7.7823544   9.584425   91.104004  107.32884  ]\n",
      " [  6.487902    9.647287   88.643684  106.77251  ]\n",
      " [  6.2919564  10.29595    90.87181   108.30396  ]\n",
      " [  6.2470555   9.772957   88.97337   107.11978  ]\n",
      " [  7.387105    9.825625   89.80388   106.73534  ]\n",
      " [  6.8925877  10.020663   91.053024  108.00686  ]\n",
      " [  6.4883995   9.1136     91.0481    107.237045 ]\n",
      " [  7.1811523   8.977926   90.263084  107.668335 ]\n",
      " [  8.110395    9.207264   90.40351   109.26779  ]\n",
      " [  6.168766    9.086893   89.64417   106.500946 ]\n",
      " [  7.63645     9.625541   89.60377   107.49046  ]\n",
      " [  8.010657    9.450931   90.67061   109.119286 ]\n",
      " [  8.012073   10.094624   89.083015  108.19075  ]\n",
      " [  7.2481866   9.890123   90.01577   108.593445 ]\n",
      " [  6.245063   10.502817   89.40976   106.7913   ]\n",
      " [  7.560213   10.718129   91.613556  107.31616  ]\n",
      " [  6.409112    9.956106   91.033455  108.219955 ]\n",
      " [  7.9482727   6.4925084  90.13073   108.24561  ]\n",
      " [  7.020301   10.369783   89.51551   106.70729  ]\n",
      " [  9.273914   12.526899   91.21071   107.70511  ]\n",
      " [  8.991858   15.0856495  91.19597   108.040695 ]\n",
      " [  6.2975206  12.974623   90.27333   108.752106 ]\n",
      " [  7.7535453   8.303835   91.279205  108.62672  ]\n",
      " [  8.051662    5.8166685  91.51245   108.96855  ]\n",
      " [  5.514088    7.7413154  88.420784  108.87109  ]\n",
      " [  6.737267    5.633537   90.38907   107.890945 ]\n",
      " [  9.712726    4.3801036  90.60526   110.77     ]\n",
      " [  8.846551   13.549406   93.024895  106.990685 ]\n",
      " [  9.066943    6.022628   88.48032   108.05615  ]\n",
      " [  3.568266    7.8685246  88.609375  107.38207  ]\n",
      " [  5.1030006  16.154291   89.458435  107.39454  ]\n",
      " [ 12.01191     8.605087   92.10267   107.96612  ]\n",
      " [  5.218881   13.819565   88.43903   107.39176  ]\n",
      " [ 11.701914    3.5814905  90.08188   108.62264  ]\n",
      " [  6.8814826   3.8711967  90.9017    109.10984  ]\n",
      " [  4.1083016   3.0488882  87.34093   108.460846 ]\n",
      " [  9.34227     2.9637194  89.11566   107.88276  ]\n",
      " [  4.246736    9.747068   85.563934  106.038086 ]] (42, 4)\n",
      "\n",
      "[0.9951267  0.9949911  0.9937162  0.99282444 0.9922854  0.99100435\n",
      " 0.99039537 0.9903042  0.98851556 0.9875623  0.984136   0.9829091\n",
      " 0.98283744 0.9819741  0.98180884 0.98146296 0.9767977  0.9749361\n",
      " 0.894224   0.8571215  0.8210809  0.81939656 0.6727817  0.6153736\n",
      " 0.60032207 0.5865436  0.5505504  0.5424609  0.54056484 0.5203753\n",
      " 0.46646374 0.46541384 0.34862372 0.34180564 0.31928894 0.28675857\n",
      " 0.26600793 0.24595739 0.22579421 0.17809707 0.09157839 0.06970223] (42,)\n",
      "Tensor in gpu\n",
      "test [[[230. 224. 207.]\n",
      "  [231. 225. 209.]\n",
      "  [231. 225. 209.]\n",
      "  ...\n",
      "  [211. 202. 171.]\n",
      "  [211. 202. 172.]\n",
      "  [211. 201. 172.]]\n",
      "\n",
      " [[230. 224. 208.]\n",
      "  [231. 226. 209.]\n",
      "  [231. 225. 209.]\n",
      "  ...\n",
      "  [213. 201. 166.]\n",
      "  [210. 201. 170.]\n",
      "  [210. 201. 170.]]\n",
      "\n",
      " [[231. 225. 208.]\n",
      "  [231. 226. 209.]\n",
      "  [231. 226. 209.]\n",
      "  ...\n",
      "  [217. 203. 160.]\n",
      "  [211. 201. 169.]\n",
      "  [210. 201. 171.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 73.  62.  50.]\n",
      "  [ 72.  61.  50.]\n",
      "  [ 74.  62.  50.]\n",
      "  ...\n",
      "  [201. 188. 159.]\n",
      "  [200. 188. 158.]\n",
      "  [201. 188. 159.]]\n",
      "\n",
      " [[ 65.  55.  45.]\n",
      "  [ 66.  55.  46.]\n",
      "  [ 69.  57.  47.]\n",
      "  ...\n",
      "  [200. 188. 159.]\n",
      "  [200. 188. 158.]\n",
      "  [200. 187. 158.]]\n",
      "\n",
      " [[ 55.  47.  40.]\n",
      "  [ 58.  48.  42.]\n",
      "  [ 63.  51.  44.]\n",
      "  ...\n",
      "  [200. 188. 158.]\n",
      "  [200. 188. 158.]\n",
      "  [200. 188. 158.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f3d0>\n",
      "[[ 16.078423    10.494993   100.06627    105.58282   ]\n",
      " [ 15.467493     9.700816    99.43672    106.275566  ]\n",
      " [ 14.336033     9.71073     99.39664    104.881195  ]\n",
      " [ 15.130203     9.336258    99.2487     105.025566  ]\n",
      " [ 16.998814    11.051855    98.61079    108.1203    ]\n",
      " [ 15.529027    10.2993145   98.403114   104.62837   ]\n",
      " [ 15.953589     9.3521595   98.013916   104.263504  ]\n",
      " [ 14.758184    10.986643    99.70453    105.65597   ]\n",
      " [ 15.4184475    9.302923    97.93535    106.722374  ]\n",
      " [ 16.000683    10.034132    98.29094    107.225815  ]\n",
      " [ 15.576678     9.705927    98.93724    104.70855   ]\n",
      " [ 15.371967    11.718496    99.245476   105.221565  ]\n",
      " [ 15.178701     9.058258    99.10733    106.003204  ]\n",
      " [ 15.536501     9.657587    99.15424    105.35591   ]\n",
      " [ 15.256391     9.475778    98.53558    105.76491   ]\n",
      " [ 16.309631    10.904024   100.215675   105.499435  ]\n",
      " [ 15.477688    12.443502    99.73788    105.75692   ]\n",
      " [ 15.895174     9.829985   100.06596    105.98793   ]\n",
      " [ 15.87779      8.947528    98.16453    108.27422   ]\n",
      " [ 16.528008     9.460373    99.453896   109.11905   ]\n",
      " [ 16.315624     9.637263    99.33281    104.87568   ]\n",
      " [ 14.697439     8.191222    98.1116     106.84714   ]\n",
      " [ 15.116852     8.663536    99.79301    104.46123   ]\n",
      " [ 14.403543     9.823612    98.65935    105.028305  ]\n",
      " [ 16.225506    11.750986   100.18266    106.16955   ]\n",
      " [ 15.799477     8.979591    98.48478    106.49643   ]\n",
      " [ 15.75798     10.960688    99.99483    104.665344  ]\n",
      " [ 14.925198     6.068006    99.72166    107.71849   ]\n",
      " [ 14.3263855    7.464857    97.38991    109.43157   ]\n",
      " [ 16.25959     15.164455    98.361      105.53439   ]\n",
      " [ 14.419205     6.1328506   98.82341    108.869316  ]\n",
      " [ 16.222961    10.240975   102.81863    111.33516   ]\n",
      " [ 17.9793       4.6657343   96.394485   108.495575  ]\n",
      " [ 17.835045    17.02856    100.634544   107.539444  ]\n",
      " [ 12.419466     2.5827994   99.92214    109.19275   ]\n",
      " [ 17.671692     1.0787296  100.61951    110.01261   ]\n",
      " [ 13.190175    17.677397    95.818565   108.59003   ]\n",
      " [ 12.801571    11.74605     97.33923    106.24907   ]\n",
      " [ 11.788277     0.11913157  96.69272    109.25457   ]\n",
      " [  9.513949     0.5230427   96.1466     108.91853   ]\n",
      " [ 16.311014     6.0362096  102.99858    112.90521   ]\n",
      " [ 19.776283     2.377234   100.54434    107.941696  ]\n",
      " [ 20.916224    16.069267   103.19152    104.72944   ]\n",
      " [ 20.585909    18.864      105.8483     106.451     ]\n",
      " [ 14.501794    -0.9561367  100.360115   110.22538   ]] (45, 4)\n",
      "\n",
      "[0.9925236  0.988499   0.98678803 0.9863229  0.98383176 0.9813405\n",
      " 0.9794749  0.97798014 0.9779661  0.9762397  0.9732414  0.9721959\n",
      " 0.9715837  0.9715067  0.9678101  0.9673824  0.9581827  0.9483517\n",
      " 0.94329506 0.92642534 0.92209923 0.861434   0.8562092  0.849217\n",
      " 0.84886056 0.8220143  0.81876975 0.5735688  0.56510466 0.5627602\n",
      " 0.47892925 0.3768912  0.27385238 0.1965093  0.16867241 0.1026539\n",
      " 0.06580949 0.06044319 0.04651901 0.04448587 0.03793433 0.03241183\n",
      " 0.03091972 0.02970385 0.02657008] (45,)\n",
      "Tensor in gpu\n",
      "test [[[146. 161. 164.]\n",
      "  [128. 143. 146.]\n",
      "  [115. 129. 132.]\n",
      "  ...\n",
      "  [143. 126. 118.]\n",
      "  [145. 128. 120.]\n",
      "  [147. 130. 122.]]\n",
      "\n",
      " [[154. 169. 172.]\n",
      "  [136. 151. 154.]\n",
      "  [119. 133. 136.]\n",
      "  ...\n",
      "  [143. 126. 118.]\n",
      "  [146. 129. 121.]\n",
      "  [149. 132. 124.]]\n",
      "\n",
      " [[163. 178. 181.]\n",
      "  [145. 160. 163.]\n",
      "  [125. 139. 142.]\n",
      "  ...\n",
      "  [144. 127. 119.]\n",
      "  [147. 130. 122.]\n",
      "  [150. 133. 125.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[227. 198. 168.]\n",
      "  [227. 198. 168.]\n",
      "  [226. 197. 167.]\n",
      "  ...\n",
      "  [ 38.  27.  33.]\n",
      "  [ 42.  31.  37.]\n",
      "  [ 45.  34.  40.]]\n",
      "\n",
      " [[227. 198. 168.]\n",
      "  [227. 198. 168.]\n",
      "  [226. 197. 167.]\n",
      "  ...\n",
      "  [ 42.  31.  37.]\n",
      "  [ 47.  36.  42.]\n",
      "  [ 50.  39.  45.]]\n",
      "\n",
      " [[227. 198. 168.]\n",
      "  [226. 197. 167.]\n",
      "  [226. 197. 167.]\n",
      "  ...\n",
      "  [ 46.  35.  41.]\n",
      "  [ 52.  41.  47.]\n",
      "  [ 56.  45.  51.]]] (2307, 3072, 3)\n",
      "torch.Size([1, 3, 2307, 3072])\n",
      "Forward time: 0.0042\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f130>\n",
      "[[ 702.8436   857.36957 1155.6316  1493.9916 ]\n",
      " [ 703.4254   859.1478  1158.9227  1493.3016 ]\n",
      " [ 702.9467   859.70416 1168.439   1493.9657 ]\n",
      " ...\n",
      " [  98.09476  802.1485   142.37779  858.8345 ]\n",
      " [ 241.31223  728.8584   263.27795  754.61676]\n",
      " [ 610.68604  838.62537  693.1527   916.97455]] (500, 4)\n",
      "\n",
      "[0.9999937  0.9999927  0.99999213 0.99999154 0.9999907  0.9999902\n",
      " 0.9999896  0.9999888  0.99998844 0.99998844 0.99998796 0.9999877\n",
      " 0.9999869  0.99998546 0.9999851  0.9999851  0.9999845  0.9999839\n",
      " 0.9999832  0.9999832  0.99998176 0.9999814  0.9999802  0.9999794\n",
      " 0.99997795 0.99997747 0.99997735 0.99997425 0.99997425 0.9999738\n",
      " 0.99997187 0.99996924 0.9999685  0.9999671  0.9999653  0.99996054\n",
      " 0.9999598  0.999959   0.9999553  0.9999553  0.99995494 0.99995255\n",
      " 0.99995255 0.99994445 0.99993765 0.9999366  0.99993277 0.99993086\n",
      " 0.99992883 0.9999248  0.9999244  0.9999198  0.9999192  0.99991333\n",
      " 0.9999118  0.9999095  0.9999007  0.9998759  0.9998721  0.9998685\n",
      " 0.99985373 0.99984646 0.99984145 0.9998097  0.9998053  0.9997942\n",
      " 0.9997706  0.9997665  0.9997533  0.9997098  0.99969614 0.9996655\n",
      " 0.99966013 0.99964356 0.9996275  0.9996203  0.99961734 0.99955505\n",
      " 0.9995511  0.9995504  0.9994773  0.9994438  0.99942976 0.99939597\n",
      " 0.99934417 0.9993081  0.9993081  0.99929154 0.9992848  0.99925727\n",
      " 0.9992404  0.99923956 0.99923086 0.9992137  0.9991916  0.99915254\n",
      " 0.9991497  0.99913377 0.99912447 0.9991086  0.99910575 0.9990972\n",
      " 0.9990885  0.99907506 0.9990501  0.9990312  0.99902284 0.99901235\n",
      " 0.99900657 0.99897885 0.99897754 0.99897695 0.99896336 0.9989422\n",
      " 0.9989213  0.9989145  0.9989042  0.998863   0.9988199  0.99877554\n",
      " 0.9987447  0.9987061  0.9987006  0.9986896  0.9986324  0.99862826\n",
      " 0.99857235 0.99857223 0.99856085 0.99851507 0.9984692  0.99841905\n",
      " 0.99836034 0.998273   0.9982445  0.99802434 0.9979395  0.99789387\n",
      " 0.9978613  0.99781454 0.9977658  0.9977635  0.9977469  0.9975091\n",
      " 0.99745566 0.9974402  0.9973902  0.9972036  0.99713933 0.997092\n",
      " 0.99697685 0.9969201  0.9968727  0.9968694  0.99678457 0.99671966\n",
      " 0.9963347  0.99610656 0.9960419  0.99590826 0.9957777  0.9957163\n",
      " 0.9956773  0.9956381  0.9956216  0.9955264  0.99534976 0.99530125\n",
      " 0.9952716  0.9951467  0.99504507 0.9948526  0.99482095 0.9946906\n",
      " 0.9945157  0.9944232  0.99442166 0.9937494  0.9933776  0.9933565\n",
      " 0.9932549  0.9931116  0.99293983 0.99289674 0.9923178  0.99215925\n",
      " 0.99211043 0.99192727 0.99161375 0.99150896 0.99138707 0.9911588\n",
      " 0.99101335 0.9909807  0.99054635 0.9905161  0.9905111  0.99026614\n",
      " 0.98998    0.98966646 0.98964196 0.98962665 0.98952544 0.9893991\n",
      " 0.9892285  0.9891472  0.9890422  0.98845273 0.98832846 0.98751765\n",
      " 0.98734784 0.98723257 0.9868413  0.98615974 0.9861557  0.98582524\n",
      " 0.9858014  0.9856227  0.98543185 0.9850386  0.9849422  0.98455703\n",
      " 0.9838499  0.9833197  0.9830168  0.98242396 0.9823926  0.98235923\n",
      " 0.98217726 0.98207974 0.9815781  0.9810688  0.9810373  0.98093754\n",
      " 0.98041403 0.98040086 0.9799601  0.9798288  0.9796458  0.97770476\n",
      " 0.97747654 0.9771353  0.9767036  0.97659904 0.9758228  0.97515225\n",
      " 0.9741964  0.9740657  0.97356254 0.9728212  0.9721653  0.9716816\n",
      " 0.97000915 0.9698592  0.9692281  0.96865195 0.96829885 0.9681018\n",
      " 0.96799445 0.9678774  0.9677865  0.9667262  0.96641827 0.96617234\n",
      " 0.9658726  0.9651967  0.9643578  0.9636343  0.9629241  0.9625124\n",
      " 0.9617386  0.9614231  0.96022826 0.95997775 0.9586202  0.9574969\n",
      " 0.9574582  0.95745796 0.9568914  0.95650727 0.95488596 0.95346975\n",
      " 0.9533221  0.95240813 0.95099974 0.94984937 0.94981605 0.9466519\n",
      " 0.9463272  0.9446279  0.94210625 0.94189304 0.93958867 0.93863237\n",
      " 0.9385207  0.9376958  0.9375973  0.93753105 0.93750185 0.9367606\n",
      " 0.9360421  0.9350125  0.934366   0.9340911  0.9339551  0.9323199\n",
      " 0.93167055 0.92973745 0.9297156  0.9284573  0.9269172  0.92427695\n",
      " 0.9237969  0.9223919  0.92104155 0.92028284 0.9183083  0.91767895\n",
      " 0.91661125 0.9143238  0.91099316 0.9109695  0.910396   0.9090329\n",
      " 0.9072177  0.90617305 0.9057058  0.9041784  0.90220475 0.90156376\n",
      " 0.90127605 0.90108    0.899372   0.8981581  0.89700866 0.8931986\n",
      " 0.89252055 0.89241916 0.8917805  0.89121    0.89104265 0.89051837\n",
      " 0.89034575 0.8894722  0.88945776 0.888104   0.8878543  0.88538045\n",
      " 0.884215   0.88312155 0.88275915 0.8826277  0.87997705 0.87938184\n",
      " 0.87327117 0.87305516 0.8712285  0.8629151  0.862501   0.8624916\n",
      " 0.862442   0.86190873 0.8575897  0.8570237  0.8546127  0.8522735\n",
      " 0.8521758  0.8483145  0.8471566  0.8464255  0.8460178  0.84574354\n",
      " 0.8447182  0.8443102  0.842965   0.841551   0.840672   0.84021175\n",
      " 0.8380621  0.83759344 0.8364698  0.8351859  0.83054227 0.8304715\n",
      " 0.8302834  0.8264889  0.8259009  0.82538384 0.82476515 0.82307893\n",
      " 0.8217309  0.8209154  0.8207378  0.8202943  0.8168936  0.81613964\n",
      " 0.81584626 0.815337   0.81276196 0.8081098  0.8078889  0.8078535\n",
      " 0.8056437  0.8042023  0.80267155 0.80080783 0.8003424  0.8002159\n",
      " 0.80018514 0.79793954 0.79607916 0.7936119  0.7898623  0.7856527\n",
      " 0.784449   0.78411233 0.7838758  0.7802331  0.780043   0.7723551\n",
      " 0.7700923  0.7679519  0.7591172  0.75650233 0.7547148  0.752808\n",
      " 0.74988884 0.7430006  0.7383807  0.73517907 0.73249    0.7312787\n",
      " 0.73030347 0.72883075 0.72794354 0.7271681  0.7261077  0.72588986\n",
      " 0.72583306 0.7246245  0.7240034  0.71615815 0.7117281  0.71150416\n",
      " 0.7094371  0.70437115 0.7028269  0.69420606 0.69300914 0.6928336\n",
      " 0.692175   0.68720454 0.6844098  0.6823738  0.68184876 0.6780693\n",
      " 0.67790806 0.6772228  0.67645353 0.67638093 0.67620015 0.67439926\n",
      " 0.6704868  0.66866505 0.6671956  0.6666939  0.666247   0.66361004\n",
      " 0.6624037  0.6621038  0.660303   0.65893376 0.6564099  0.6517877\n",
      " 0.649438   0.6477367  0.64667815 0.6387553  0.63570035 0.63476026\n",
      " 0.63332707 0.63236135 0.6317207  0.62732756 0.62730527 0.6250349\n",
      " 0.62431145 0.62288994 0.6215637  0.6211913  0.6207003  0.61916727\n",
      " 0.6179662  0.61362183 0.60672706 0.60548925 0.6040016  0.60379845\n",
      " 0.6036741  0.60328263] (500,)\n",
      "Tensor in gpu\n",
      "test [[[147. 153. 159.]\n",
      "  [152. 158. 165.]\n",
      "  [156. 162. 169.]\n",
      "  ...\n",
      "  [135. 140. 150.]\n",
      "  [137. 143. 154.]\n",
      "  [138. 144. 155.]]\n",
      "\n",
      " [[132. 139. 146.]\n",
      "  [142. 149. 155.]\n",
      "  [143. 150. 157.]\n",
      "  ...\n",
      "  [114. 119. 126.]\n",
      "  [123. 129. 139.]\n",
      "  [123. 130. 141.]]\n",
      "\n",
      " [[121. 128. 135.]\n",
      "  [123. 130. 137.]\n",
      "  [123. 131. 138.]\n",
      "  ...\n",
      "  [ 90.  94.  96.]\n",
      "  [101. 108. 117.]\n",
      "  [102. 110. 120.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 25.  30.  24.]\n",
      "  [ 26.  30.  26.]\n",
      "  [ 28.  32.  27.]\n",
      "  ...\n",
      "  [ 34.  37.  43.]\n",
      "  [ 34.  37.  43.]\n",
      "  [ 35.  38.  44.]]\n",
      "\n",
      " [[ 26.  30.  25.]\n",
      "  [ 27.  31.  26.]\n",
      "  [ 30.  33.  29.]\n",
      "  ...\n",
      "  [ 30.  32.  38.]\n",
      "  [ 30.  32.  37.]\n",
      "  [ 33.  35.  40.]]\n",
      "\n",
      " [[ 27.  31.  26.]\n",
      "  [ 29.  33.  29.]\n",
      "  [ 32.  36.  31.]\n",
      "  ...\n",
      "  [ 28.  30.  36.]\n",
      "  [ 30.  33.  38.]\n",
      "  [ 33.  36.  41.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0046\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f6d0>\n",
      "[[ 21.366425    7.828941   98.42557   107.597374 ]\n",
      " [ 21.308485    9.261006   97.58052   108.96642  ]\n",
      " [ 20.63856     6.7401576  98.64701   107.42944  ]\n",
      " [ 20.766333    7.8096113  97.730804  106.77543  ]\n",
      " [ 21.935526    8.086437   98.823654  106.583405 ]\n",
      " [ 21.429934    7.279716   96.94141   105.34961  ]\n",
      " [ 19.31157     7.5902905  96.1633    106.1377   ]\n",
      " [ 20.672806    7.3665805  97.141624  105.105194 ]\n",
      " [ 20.71256     8.327006   95.92152   105.10743  ]\n",
      " [ 20.227558    6.810473   96.56355   105.047134 ]\n",
      " [ 20.333893    6.0323644  96.69327   106.46747  ]\n",
      " [ 21.291431    8.1714325  97.136765  109.05579  ]\n",
      " [ 20.673405    7.267082   96.8915    107.108536 ]\n",
      " [ 20.680006    7.350512   96.98282   107.422844 ]\n",
      " [ 20.006292    7.0209284  95.554016  108.281204 ]\n",
      " [ 20.369207    7.5790386  97.01198   107.293976 ]\n",
      " [ 21.57552     7.941577   98.07866   106.11537  ]\n",
      " [ 20.091888    7.4674807  97.919876  106.416756 ]\n",
      " [ 20.479916    9.466862   96.95025   106.430664 ]\n",
      " [ 21.149635    6.949832   96.590164  105.463715 ]\n",
      " [ 20.337856    9.368853   97.27848   107.7079   ]\n",
      " [ 21.652761   11.115444   97.24862   106.75443  ]\n",
      " [ 20.295975    6.1633153  96.940125  107.19523  ]\n",
      " [ 19.314264    7.8276625  96.48299   108.559006 ]\n",
      " [ 22.220585    5.1500745  95.14186   109.8192   ]\n",
      " [ 20.455732    5.0712075  97.46899   104.851585 ]\n",
      " [ 21.016708    6.1841936  98.424706  106.39694  ]\n",
      " [ 21.345118    9.891188   98.840515  107.61672  ]\n",
      " [ 20.464615    6.97788    98.657135  106.11043  ]\n",
      " [ 22.910635   13.480185   99.3209    108.06291  ]\n",
      " [ 18.688496    4.619932   97.749954  108.77145  ]\n",
      " [ 18.561716    4.760793   95.84125   107.85147  ]\n",
      " [ 20.057299    3.417358   97.88806   107.66635  ]\n",
      " [ 21.063904    8.958385  101.269104  111.652275 ]\n",
      " [ 17.046839    1.1482873  96.97441   109.65834  ]\n",
      " [ 22.114063   -0.2980976  98.672356  108.55707  ]\n",
      " [ 23.044056    1.9456553  97.83659   109.861755 ]\n",
      " [ 20.985563    4.339485  100.51112   113.871735 ]\n",
      " [ 17.98869    -2.3750777  98.52941   111.12341  ]\n",
      " [ 18.059216    1.4490752  89.19868   100.90904  ]] (40, 4)\n",
      "\n",
      "[0.997142   0.9942472  0.99246526 0.989604   0.97880334 0.97799236\n",
      " 0.97637594 0.9756463  0.9737084  0.97356737 0.96920353 0.9637718\n",
      " 0.9605036  0.9594515  0.95916843 0.9588678  0.9578583  0.93767977\n",
      " 0.93544835 0.85125566 0.7757808  0.7647697  0.7607873  0.66642916\n",
      " 0.65498096 0.63892066 0.5855105  0.56848264 0.53066236 0.3951409\n",
      " 0.38359246 0.3192036  0.2813711  0.27420196 0.15083961 0.09350757\n",
      " 0.06477588 0.03549082 0.0278596  0.02699299] (40,)\n",
      "Tensor in gpu\n",
      "test [[[198. 199. 229.]\n",
      "  [198. 199. 229.]\n",
      "  [197. 199. 229.]\n",
      "  ...\n",
      "  [159.  88.  65.]\n",
      "  [157.  84.  59.]\n",
      "  [158.  86.  62.]]\n",
      "\n",
      " [[198. 199. 229.]\n",
      "  [198. 199. 229.]\n",
      "  [197. 198. 228.]\n",
      "  ...\n",
      "  [160.  90.  65.]\n",
      "  [159.  85.  60.]\n",
      "  [157.  86.  60.]]\n",
      "\n",
      " [[198. 199. 229.]\n",
      "  [198. 199. 229.]\n",
      "  [198. 199. 229.]\n",
      "  ...\n",
      "  [160.  91.  66.]\n",
      "  [160.  86.  60.]\n",
      "  [158.  86.  59.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[169. 119. 119.]\n",
      "  [170. 120. 119.]\n",
      "  [171. 122. 120.]\n",
      "  ...\n",
      "  [197. 131.  97.]\n",
      "  [199. 134. 100.]\n",
      "  [201. 136. 102.]]\n",
      "\n",
      " [[169. 119. 118.]\n",
      "  [170. 120. 119.]\n",
      "  [171. 121. 120.]\n",
      "  ...\n",
      "  [200. 133.  98.]\n",
      "  [201. 135. 100.]\n",
      "  [204. 138. 103.]]\n",
      "\n",
      " [[170. 119. 119.]\n",
      "  [170. 120. 119.]\n",
      "  [170. 121. 119.]\n",
      "  ...\n",
      "  [203. 136. 100.]\n",
      "  [205. 138. 103.]\n",
      "  [206. 141. 106.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f550>\n",
      "[[ 33.066338     3.8655257  104.575      105.90633   ]\n",
      " [ 33.215405     6.125364   104.06729    108.63465   ]\n",
      " [ 33.195885     3.7967792  105.13597    106.96852   ]\n",
      " [ 33.648438     6.690103   104.22853    105.545044  ]\n",
      " [ 33.527233     5.6986384  104.40396    108.091     ]\n",
      " [ 32.360832     3.82927    103.51428    105.1699    ]\n",
      " [ 32.78061      4.7218003  105.326515   105.664635  ]\n",
      " [ 33.248238     3.113062   103.686646   107.67792   ]\n",
      " [ 31.858957     4.2452474  103.97135    106.866394  ]\n",
      " [ 31.706863     3.526763   104.34215    104.5307    ]\n",
      " [ 33.701134     4.128656   103.20467    104.68652   ]\n",
      " [ 35.351177     5.9043274  105.6104     103.72834   ]\n",
      " [ 32.355423     6.4798045  104.217834   106.336426  ]\n",
      " [ 31.735085     3.3707614  103.549736   104.74454   ]\n",
      " [ 34.000706     1.2784204  102.32124    109.39359   ]\n",
      " [ 33.211662     6.1623006  103.17596    104.03809   ]\n",
      " [ 32.503666     5.955557   104.89013    106.850815  ]\n",
      " [ 34.239952     3.089757   104.45729    106.082184  ]\n",
      " [ 33.96827      3.8690405  105.431786   102.10785   ]\n",
      " [ 35.0691       6.922852   104.887344   105.841515  ]\n",
      " [ 33.858543     2.135476   103.66288    111.156395  ]\n",
      " [ 34.012512     5.9958014  106.3823     105.95954   ]\n",
      " [ 34.513676     5.8873577  107.6756     107.982056  ]\n",
      " [ 31.648785     0.81744194 101.048325   111.544395  ]\n",
      " [ 34.550213     4.2718334  106.594406   108.52458   ]\n",
      " [ 36.28861      1.8621354  106.16635    110.25119   ]\n",
      " [ 31.8721       0.9449949  101.318085   108.24236   ]\n",
      " [ 31.060137    -0.28008986 104.176735   108.12203   ]\n",
      " [ 32.373653     1.4313946  107.017426   107.51497   ]\n",
      " [ 31.883366     0.41979265 106.74237    107.94595   ]\n",
      " [ 33.283455     5.858225   107.777885   108.94798   ]\n",
      " [ 33.03085      3.7428093  108.58075    107.26585   ]\n",
      " [ 31.64327      4.0467715  106.7165     106.995895  ]\n",
      " [ 32.03401     10.656012   101.594666   107.81575   ]\n",
      " [ 28.71367      1.9495239  100.39156    109.49855   ]\n",
      " [ 27.267838     4.090601    96.87837    101.93469   ]\n",
      " [ 26.785624    -2.2502785   97.9953     105.51215   ]\n",
      " [ 28.994156     9.233887    98.16633    103.24363   ]\n",
      " [ 28.183939     5.7105513  104.374054   104.465935  ]\n",
      " [ 28.447762    10.835218    97.834625   105.306244  ]\n",
      " [ 36.956528    -1.6640768  107.4858     105.88005   ]\n",
      " [ 38.65697     14.03146    108.99794    109.86993   ]\n",
      " [ 25.454727    -1.7721701   98.64469    109.78539   ]\n",
      " [ 32.926815    -5.960497   107.3972     109.38433   ]] (44, 4)\n",
      "\n",
      "[0.9926864  0.99152267 0.982743   0.97048527 0.9422302  0.92787236\n",
      " 0.9250378  0.9038935  0.8984844  0.89016247 0.88035095 0.87994057\n",
      " 0.8768214  0.87574464 0.85312057 0.85257894 0.8329181  0.80839044\n",
      " 0.79983693 0.79602313 0.7627835  0.74543023 0.6786463  0.6435942\n",
      " 0.6094201  0.60743225 0.30853614 0.2976533  0.2900806  0.27166006\n",
      " 0.22078979 0.17151858 0.16630435 0.16389288 0.09552043 0.06849235\n",
      " 0.06639417 0.06347583 0.05421724 0.03527066 0.02213203 0.02211837\n",
      " 0.02146614 0.02107621] (44,)\n",
      "Tensor in gpu\n",
      "test [[[18.  9.  5.]\n",
      "  [19.  9.  5.]\n",
      "  [17.  8.  4.]\n",
      "  ...\n",
      "  [61. 43. 19.]\n",
      "  [61. 43. 19.]\n",
      "  [61. 43. 19.]]\n",
      "\n",
      " [[18.  9.  4.]\n",
      "  [18.  8.  4.]\n",
      "  [17.  8.  4.]\n",
      "  ...\n",
      "  [62. 44. 18.]\n",
      "  [61. 43. 17.]\n",
      "  [60. 42. 17.]]\n",
      "\n",
      " [[18.  8.  3.]\n",
      "  [17.  8.  3.]\n",
      "  [17.  8.  3.]\n",
      "  ...\n",
      "  [63. 45. 18.]\n",
      "  [62. 44. 17.]\n",
      "  [61. 43. 17.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[47. 20. 18.]\n",
      "  [51. 24. 11.]\n",
      "  [48. 22. 10.]\n",
      "  ...\n",
      "  [22.  9. 10.]\n",
      "  [23. 10. 11.]\n",
      "  [24. 11. 11.]]\n",
      "\n",
      " [[52. 24. 14.]\n",
      "  [50. 23. 11.]\n",
      "  [48. 22. 10.]\n",
      "  ...\n",
      "  [21.  9. 10.]\n",
      "  [22. 11. 11.]\n",
      "  [23. 12. 12.]]\n",
      "\n",
      " [[52. 25. 12.]\n",
      "  [50. 24. 11.]\n",
      "  [48. 22. 10.]\n",
      "  ...\n",
      "  [20.  9. 10.]\n",
      "  [23. 11. 12.]\n",
      "  [24. 12. 13.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7fa90>\n",
      "[[  5.4883432  13.170404   89.41446   107.688194 ]\n",
      " [  4.7539206  11.929545   89.666794  107.25959  ]\n",
      " [  4.6035233  13.689899   89.22237   107.092186 ]\n",
      " [  5.128729   12.9256935  89.54183   106.42492  ]\n",
      " [  5.656261   12.846125   88.29115   106.0462   ]\n",
      " [  5.608496   11.360897   88.829926  105.44601  ]\n",
      " [  4.079409   12.580311   87.57295   105.842705 ]\n",
      " [  5.245661   13.165264   88.938065  106.397644 ]\n",
      " [  5.2922673  12.086214   88.28051   105.268845 ]\n",
      " [  4.5435586  11.703756   86.74686   105.61766  ]\n",
      " [  5.751864   11.467449   87.78233   106.60399  ]\n",
      " [  5.4454017  11.798765   88.71632   106.48977  ]\n",
      " [  6.4748044  12.37331    88.85505   107.8634   ]\n",
      " [  4.4320908  12.553135   89.82114   105.841675 ]\n",
      " [  6.1025763  10.585216   88.72372   108.870605 ]\n",
      " [  4.6214175  11.423593   87.88931   105.82566  ]\n",
      " [  4.400411   12.658131   88.134796  107.04786  ]\n",
      " [  5.7654324  11.5855055  87.37545   107.66681  ]\n",
      " [  4.821115   13.423331   87.99429   104.996414 ]\n",
      " [  5.7521844  13.146532   89.58341   106.11155  ]\n",
      " [  4.7735305  13.079481   87.84531   104.22982  ]\n",
      " [  5.534212   11.620399   89.46545   107.43965  ]\n",
      " [  5.151079   16.223492   88.807076  106.54361  ]\n",
      " [  4.2465825  18.05405    88.90028   106.10711  ]\n",
      " [  6.9725094  17.308117   89.91186   107.25488  ]\n",
      " [  5.9639316   6.733699   89.30431   108.30836  ]\n",
      " [  4.4438133  15.799089   88.39847   106.71386  ]\n",
      " [  3.480627   10.597288   87.20793   107.55203  ]\n",
      " [  7.274489   14.065796   89.5221    106.67212  ]\n",
      " [  5.7164125   7.186326   90.36056   108.58793  ]\n",
      " [  2.1679869  10.208281   87.480286  107.01349  ]\n",
      " [  7.4106903  16.217718   91.94252   106.29342  ]\n",
      " [  4.5907025   6.7737465  88.01027   107.44563  ]\n",
      " [  6.640299    9.03725    89.6192    108.93865  ]\n",
      " [  2.4284234   4.751594   87.56123   106.421074 ]\n",
      " [  7.9886475   3.6977415  90.39793   110.20736  ]\n",
      " [  7.133838    4.9936056  88.08519   107.24285  ]\n",
      " [ 10.38425     4.279003   88.45004   107.97281  ]\n",
      " [ 11.333277    8.948278   91.5375    106.44936  ]\n",
      " [  4.8260617   6.2940526  89.41504   106.6287   ]\n",
      " [  3.2859464  11.949359   85.59772   105.8245   ]\n",
      " [  8.149923    4.849657   87.81762   107.27909  ]] (42, 4)\n",
      "\n",
      "[0.99540085 0.9936126  0.9922335  0.9894224  0.98797286 0.98722374\n",
      " 0.9845201  0.98405415 0.97996247 0.9776109  0.9748082  0.9703882\n",
      " 0.96908814 0.9673045  0.96651214 0.9614963  0.9515146  0.94941926\n",
      " 0.8214847  0.81022197 0.6946365  0.6728707  0.6482068  0.6136664\n",
      " 0.5880454  0.5812828  0.5668238  0.5575856  0.4843846  0.44180223\n",
      " 0.43817398 0.42955783 0.33487824 0.28436306 0.23601468 0.23070367\n",
      " 0.19050263 0.16606236 0.14282738 0.13999431 0.09365934 0.07845394] (42,)\n",
      "Tensor in gpu\n",
      "test [[[172. 153. 129.]\n",
      "  [175. 155. 132.]\n",
      "  [173. 153. 129.]\n",
      "  ...\n",
      "  [ 54.  49.  30.]\n",
      "  [ 42.  39.  28.]\n",
      "  [ 37.  34.  26.]]\n",
      "\n",
      " [[171. 152. 129.]\n",
      "  [173. 154. 130.]\n",
      "  [172. 152. 127.]\n",
      "  ...\n",
      "  [ 57.  51.  32.]\n",
      "  [ 39.  35.  25.]\n",
      "  [ 32.  29.  24.]]\n",
      "\n",
      " [[172. 152. 130.]\n",
      "  [172. 152. 129.]\n",
      "  [171. 150. 127.]\n",
      "  ...\n",
      "  [ 58.  53.  36.]\n",
      "  [ 37.  34.  24.]\n",
      "  [ 31.  28.  23.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[103. 100.  71.]\n",
      "  [102. 100.  68.]\n",
      "  [105. 102.  71.]\n",
      "  ...\n",
      "  [ 67.  58.  55.]\n",
      "  [ 64.  56.  53.]\n",
      "  [ 65.  56.  51.]]\n",
      "\n",
      " [[101.  99.  66.]\n",
      "  [100.  98.  65.]\n",
      "  [102. 100.  66.]\n",
      "  ...\n",
      "  [ 68.  58.  55.]\n",
      "  [ 64.  55.  52.]\n",
      "  [ 63.  54.  49.]]\n",
      "\n",
      " [[ 99.  98.  62.]\n",
      "  [100.  98.  63.]\n",
      "  [102. 100.  65.]\n",
      "  ...\n",
      "  [ 68.  58.  54.]\n",
      "  [ 63.  54.  51.]\n",
      "  [ 61.  52.  47.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f2b0>\n",
      "[[  3.5515633   10.3837185   88.122574   108.84272   ]\n",
      " [  4.196388     9.868403    89.47571    108.44927   ]\n",
      " [  4.184438    10.216665    88.20456    109.16257   ]\n",
      " [  3.1070404    9.926636    89.81037    110.89073   ]\n",
      " [  2.7246985   10.312279    87.71377    108.972855  ]\n",
      " [  2.7814422   10.308013    86.92215    108.48619   ]\n",
      " [  3.62776     10.447382    88.386505   108.10979   ]\n",
      " [  3.1267304   10.188978    90.12527    109.97544   ]\n",
      " [  2.8388433   10.172379    89.17168    110.2359    ]\n",
      " [  3.1190166    9.693115    89.39871    108.41933   ]\n",
      " [  2.696971    10.109755    88.08642    108.30403   ]\n",
      " [  3.252788    10.62245     88.06585    109.46098   ]\n",
      " [  4.268639    10.877011    87.49527    108.61405   ]\n",
      " [  3.187129    10.586991    89.77426    109.090996  ]\n",
      " [  3.1651893   11.0680065   87.93894    109.549194  ]\n",
      " [  3.7446985   10.477219    87.83163    110.106735  ]\n",
      " [  4.3407803   10.38484     88.76951    110.28521   ]\n",
      " [  4.4550953    9.25569     88.735245   110.85724   ]\n",
      " [  3.2716436   11.867077    87.87359    107.3561    ]\n",
      " [  3.5240192   12.0052185   89.628296   108.22624   ]\n",
      " [  3.5768676   11.7221775   87.5703     106.90911   ]\n",
      " [  2.4577632   10.571323    89.53818    108.353165  ]\n",
      " [  3.4047308    9.954584    85.89486    109.24088   ]\n",
      " [  1.9936504    9.975866    86.4569     109.33288   ]\n",
      " [  3.2856994   13.492155    89.047806   109.32298   ]\n",
      " [  3.0826607   14.874239    89.14345    108.66876   ]\n",
      " [  3.9789095    7.2097945   89.62378    110.317116  ]\n",
      " [  2.9058208    7.067929    87.73574    109.50141   ]\n",
      " [  4.527737     6.6239934   88.68143    109.75282   ]\n",
      " [  2.8854966   12.767448    88.34015    109.734566  ]\n",
      " [  4.9128127   16.21795     89.71797    108.613785  ]\n",
      " [  2.4212103    5.9894996   87.10099    109.43034   ]\n",
      " [  4.5962367    8.6310215   89.390335   110.080635  ]\n",
      " [  3.1950264    6.9248514   88.52311    109.76109   ]\n",
      " [  6.876409    14.121431    90.23507    108.75556   ]\n",
      " [  6.3688974    6.2892694   88.07339    108.70085   ]\n",
      " [  6.6956472   15.511766    92.15265    108.20082   ]\n",
      " [  6.6823893    3.1927032   89.40047    111.76795   ]\n",
      " [  1.4623499   10.08737     86.010414   108.18405   ]\n",
      " [  5.6835146    3.9628878   87.3668     108.97313   ]\n",
      " [  8.38802      3.166678    88.42018    108.85205   ]\n",
      " [ 10.974314     9.337851    91.72372    107.696655  ]\n",
      " [ -2.1374054   15.055468    85.05805    111.3934    ]\n",
      " [ -0.18327188  11.38968     92.96122    107.69969   ]\n",
      " [ -3.1489239   13.791524    89.03314    109.93972   ]] (45, 4)\n",
      "\n",
      "[0.9954204  0.99500567 0.99468577 0.99376464 0.9937611  0.99300486\n",
      " 0.9922552  0.99074554 0.99002177 0.9887306  0.9863783  0.98537725\n",
      " 0.98451114 0.983318   0.98128235 0.97729445 0.97336066 0.9632903\n",
      " 0.942313   0.9294468  0.9017541  0.83712786 0.82512957 0.7843559\n",
      " 0.6888589  0.66313833 0.65462685 0.6516723  0.64954585 0.62449294\n",
      " 0.5296235  0.4575876  0.39127034 0.31813812 0.30067062 0.2893833\n",
      " 0.22214735 0.21609445 0.16978689 0.1062148  0.096567   0.08351633\n",
      " 0.03605657 0.02339672 0.02083687] (45,)\n",
      "Tensor in gpu\n",
      "test [[[162. 170. 181.]\n",
      "  [163. 171. 181.]\n",
      "  [164. 171. 181.]\n",
      "  ...\n",
      "  [157. 169. 186.]\n",
      "  [158. 170. 187.]\n",
      "  [159. 170. 187.]]\n",
      "\n",
      " [[161. 170. 181.]\n",
      "  [162. 170. 180.]\n",
      "  [163. 171. 181.]\n",
      "  ...\n",
      "  [160. 172. 187.]\n",
      "  [162. 173. 187.]\n",
      "  [162. 173. 188.]]\n",
      "\n",
      " [[160. 169. 180.]\n",
      "  [161. 170. 181.]\n",
      "  [162. 170. 181.]\n",
      "  ...\n",
      "  [163. 174. 188.]\n",
      "  [164. 175. 188.]\n",
      "  [165. 175. 189.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[136. 141. 141.]\n",
      "  [133. 138. 137.]\n",
      "  [130. 135. 134.]\n",
      "  ...\n",
      "  [131. 138. 141.]\n",
      "  [130. 137. 140.]\n",
      "  [131. 139. 141.]]\n",
      "\n",
      " [[126. 132. 132.]\n",
      "  [125. 131. 130.]\n",
      "  [122. 127. 126.]\n",
      "  ...\n",
      "  [129. 136. 139.]\n",
      "  [128. 135. 138.]\n",
      "  [131. 138. 141.]]\n",
      "\n",
      " [[116. 122. 123.]\n",
      "  [118. 124. 124.]\n",
      "  [116. 121. 123.]\n",
      "  ...\n",
      "  [131. 138. 141.]\n",
      "  [131. 138. 141.]\n",
      "  [131. 137. 141.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f370>\n",
      "[[ 18.354866    11.806328    97.3286     106.43987   ]\n",
      " [ 17.227303    10.8643675   97.644875   107.073555  ]\n",
      " [ 19.153145    12.044931    96.883514   108.7252    ]\n",
      " [ 18.212263    11.350941    97.09556    106.43492   ]\n",
      " [ 17.011053    10.224083    96.13498    105.98056   ]\n",
      " [ 17.26307      9.703433    96.472755   105.85972   ]\n",
      " [ 17.57565     12.487041    96.3188     106.74649   ]\n",
      " [ 17.375013    11.159755    95.54369    105.82187   ]\n",
      " [ 16.756641    10.285812    95.6301     105.158966  ]\n",
      " [ 16.97369      9.951603    96.11844    106.05612   ]\n",
      " [ 17.315079    10.219186    95.916214   108.29324   ]\n",
      " [ 17.342497    10.3268385   96.07871    107.639465  ]\n",
      " [ 17.049519     8.53896     96.95862    106.96407   ]\n",
      " [ 18.25177     11.278175    98.02295    106.56187   ]\n",
      " [ 17.545885    10.720028    96.35742    106.4319    ]\n",
      " [ 17.074547    11.121142    96.60336    108.4019    ]\n",
      " [ 17.484348    12.875626    97.177795   107.218506  ]\n",
      " [ 17.878794    10.249407    96.991875   107.082115  ]\n",
      " [ 18.768534     9.4132395   96.88278    109.306274  ]\n",
      " [ 17.995827    12.30673     95.54881    107.97176   ]\n",
      " [ 18.63519      8.207891    96.21451    109.784805  ]\n",
      " [ 17.513329     8.544268    97.1979     107.25296   ]\n",
      " [ 16.119133    10.870222    97.184235   107.34693   ]\n",
      " [ 18.53908     15.283123    96.67303    106.748535  ]\n",
      " [ 18.779428    12.396662    97.79686    107.27216   ]\n",
      " [ 16.956766    10.4629135   97.49474    105.80062   ]\n",
      " [ 16.94955     11.635353    98.35337    111.16695   ]\n",
      " [ 17.309118    11.304054    97.96021    105.40378   ]\n",
      " [ 15.245336     6.52568     95.810905   109.59957   ]\n",
      " [ 19.540321     4.955247    95.266396   109.21906   ]\n",
      " [ 15.644461     6.6965218   97.062515   110.27925   ]\n",
      " [ 15.980957     8.190434    98.056114   109.90398   ]\n",
      " [ 18.553518    11.104119   100.84154    111.3364    ]\n",
      " [ 19.906433    16.724571    98.261314   108.69095   ]\n",
      " [ 15.55821      2.1503797   97.57614    109.869606  ]\n",
      " [ 15.319963    18.689177    93.906204   109.07064   ]\n",
      " [ 21.548962     0.47007084  99.34322    111.19056   ]\n",
      " [ 22.037657     1.5473619   98.58346    106.909775  ]\n",
      " [ 13.599737    13.497879    95.57857    108.12912   ]\n",
      " [ 14.750197     2.4213905   87.03931     96.13805   ]\n",
      " [ 10.010883     5.0044103   94.74378    111.2465    ]\n",
      " [ 18.447414     6.582574   101.30333    114.85152   ]\n",
      " [ 23.543098    18.570942   103.74495    107.241     ]\n",
      " [ 23.919739    15.800158   101.90911    105.16792   ]] (44, 4)\n",
      "\n",
      "[0.99424464 0.98777556 0.9872824  0.9765753  0.97286856 0.9699766\n",
      " 0.9678514  0.962667   0.9603552  0.95896155 0.9557858  0.9553739\n",
      " 0.9507901  0.94993615 0.94412947 0.93978864 0.9322766  0.90574735\n",
      " 0.90368086 0.8880595  0.88155144 0.82789296 0.7556169  0.71450573\n",
      " 0.670312   0.6544271  0.6521431  0.6152364  0.3524997  0.3238685\n",
      " 0.30172437 0.27983037 0.26483983 0.23439723 0.10808603 0.06802647\n",
      " 0.05586777 0.0507695  0.05067017 0.04807609 0.02976008 0.02860805\n",
      " 0.02191133 0.02045833] (44,)\n",
      "Tensor in gpu\n",
      "test [[[ 36.  29.  25.]\n",
      "  [ 36.  28.  24.]\n",
      "  [ 36.  29.  25.]\n",
      "  ...\n",
      "  [151. 120.  76.]\n",
      "  [150. 120.  76.]\n",
      "  [150. 119.  76.]]\n",
      "\n",
      " [[ 36.  29.  25.]\n",
      "  [ 36.  29.  25.]\n",
      "  [ 36.  29.  25.]\n",
      "  ...\n",
      "  [150. 120.  75.]\n",
      "  [151. 121.  76.]\n",
      "  [150. 120.  76.]]\n",
      "\n",
      " [[ 36.  30.  26.]\n",
      "  [ 36.  29.  25.]\n",
      "  [ 35.  29.  24.]\n",
      "  ...\n",
      "  [153. 122.  78.]\n",
      "  [152. 121.  77.]\n",
      "  [150. 120.  76.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 38.  30.  28.]\n",
      "  [ 28.  22.  20.]\n",
      "  [ 21.  17.  16.]\n",
      "  ...\n",
      "  [ 49.  32.  19.]\n",
      "  [ 53.  36.  21.]\n",
      "  [ 56.  38.  23.]]\n",
      "\n",
      " [[ 43.  35.  32.]\n",
      "  [ 27.  21.  20.]\n",
      "  [ 20.  16.  15.]\n",
      "  ...\n",
      "  [ 62.  37.  27.]\n",
      "  [ 59.  38.  25.]\n",
      "  [ 58.  40.  24.]]\n",
      "\n",
      " [[ 38.  30.  27.]\n",
      "  [ 29.  22.  21.]\n",
      "  [ 20.  16.  15.]\n",
      "  ...\n",
      "  [ 87.  43.  40.]\n",
      "  [ 82.  44.  39.]\n",
      "  [ 78.  45.  36.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f490>\n",
      "[[ 13.325949   13.022948   94.49313   104.71916  ]\n",
      " [ 12.790653   13.784448   94.372314  104.2172   ]\n",
      " [ 12.648197   14.867643   93.71424   105.31798  ]\n",
      " [ 12.455165   14.489246   94.10792   104.125626 ]\n",
      " [ 12.024227   13.6028385  93.55904   106.31264  ]\n",
      " [ 12.2790165  12.129499   93.996956  104.53051  ]\n",
      " [ 12.50337    13.897147   92.64006   103.84867  ]\n",
      " [ 10.798612   13.414272   92.24105   103.69683  ]\n",
      " [ 11.203574   13.373644   93.00226   103.96517  ]\n",
      " [ 12.070563   12.723222   93.26853   104.08829  ]\n",
      " [ 12.0007515  14.981762   94.41762   104.46844  ]\n",
      " [ 11.247073   12.594821   93.11334   104.8821   ]\n",
      " [ 13.1215515  15.572766   95.38011   103.147896 ]\n",
      " [ 11.592939   13.347284   91.702034  105.00815  ]\n",
      " [ 11.676538   13.659585   92.0836    104.79744  ]\n",
      " [ 10.767663   12.82761    94.26403   105.11224  ]\n",
      " [ 12.918377   13.352211   93.44944   103.234055 ]\n",
      " [ 11.940807   12.488106   94.25342   106.205315 ]\n",
      " [ 10.022339   12.816268   92.475784  105.413925 ]\n",
      " [ 11.188898   11.543288   93.53429   104.20279  ]\n",
      " [ 13.206854   11.357807   95.16226   103.72104  ]\n",
      " [ 13.993231   18.115328   93.77373   103.34939  ]\n",
      " [ 12.981361   15.156121   94.918205  103.445015 ]\n",
      " [ 13.489908   11.061918   94.682014  106.13822  ]\n",
      " [ 12.043457   12.974453   93.31754   103.01505  ]\n",
      " [ 12.837067   14.491119   94.78862   102.88559  ]\n",
      " [ 12.177355   12.1083145  95.27283   102.91084  ]\n",
      " [ 13.175675    8.845953   94.27189   106.49372  ]\n",
      " [ 10.9189415   7.2730803  95.531006  106.69603  ]\n",
      " [ 11.984967   18.527727   91.464165  105.363556 ]\n",
      " [  8.936586    7.1591825  94.39352   106.865685 ]\n",
      " [ 10.251356    7.4664426  92.71924   106.98719  ]\n",
      " [ 10.8759     12.717558   90.87423   104.344406 ]\n",
      " [  9.910707   19.485497   90.27427   104.87233  ]\n",
      " [ 14.591211    5.786838   92.07898   105.54108  ]\n",
      " [  9.422668   16.872246   89.5271    104.850464 ]\n",
      " [  7.3199606   4.551446   90.7301    107.36651  ]\n",
      " [  6.14728     2.289505   94.5739    105.27475  ]\n",
      " [ 16.102684   22.925308   97.20278   106.059906 ]\n",
      " [ 14.90238    15.180107  100.19809   109.77553  ]\n",
      " [  5.2969203   7.361931   88.5898    108.7783   ]\n",
      " [ 11.766687    5.15176    88.8685    102.72104  ]] (42, 4)\n",
      "\n",
      "[0.997764   0.9966363  0.9963845  0.9951018  0.9853613  0.97995764\n",
      " 0.9771548  0.9734591  0.9728698  0.97199064 0.9705467  0.9679349\n",
      " 0.9657287  0.95419633 0.95351183 0.95152926 0.94456905 0.94447494\n",
      " 0.9221553  0.91526264 0.7661527  0.7656912  0.68769675 0.68556505\n",
      " 0.6847026  0.6707422  0.63850605 0.6335387  0.43507314 0.36855456\n",
      " 0.34053636 0.31016088 0.20314017 0.15065667 0.12657432 0.10695598\n",
      " 0.09299552 0.06092428 0.05676785 0.03704504 0.02324733 0.02012454] (42,)\n",
      "Tensor in gpu\n",
      "test [[[ 44.  38.  27.]\n",
      "  [ 43.  36.  23.]\n",
      "  [ 41.  32.  21.]\n",
      "  ...\n",
      "  [225. 225. 225.]\n",
      "  [224. 225. 224.]\n",
      "  [224. 225. 224.]]\n",
      "\n",
      " [[ 45.  37.  26.]\n",
      "  [ 42.  35.  23.]\n",
      "  [ 39.  31.  21.]\n",
      "  ...\n",
      "  [224. 225. 224.]\n",
      "  [224. 225. 224.]\n",
      "  [224. 225. 224.]]\n",
      "\n",
      " [[ 43.  35.  24.]\n",
      "  [ 40.  32.  22.]\n",
      "  [ 39.  32.  22.]\n",
      "  ...\n",
      "  [224. 225. 224.]\n",
      "  [224. 225. 224.]\n",
      "  [224. 225. 224.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  2.   2.   2.]\n",
      "  [  3.   2.   2.]\n",
      "  [  5.   4.   4.]\n",
      "  ...\n",
      "  [ 94.  86.  70.]\n",
      "  [ 96.  87.  71.]\n",
      "  [ 97.  88.  72.]]\n",
      "\n",
      " [[  2.   2.   2.]\n",
      "  [  2.   2.   2.]\n",
      "  [  2.   2.   2.]\n",
      "  ...\n",
      "  [ 95.  87.  70.]\n",
      "  [ 95.  86.  70.]\n",
      "  [ 94.  85.  69.]]\n",
      "\n",
      " [[  2.   2.   2.]\n",
      "  [  2.   2.   2.]\n",
      "  [  2.   2.   2.]\n",
      "  ...\n",
      "  [ 92.  84.  67.]\n",
      "  [ 92.  84.  67.]\n",
      "  [ 93.  84.  67.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f2e0>\n",
      "[[ 1.25499535e+00  6.70431232e+00  7.98608627e+01  1.07238106e+02]\n",
      " [ 7.98442841e-01  6.55999994e+00  7.99389420e+01  1.08323639e+02]\n",
      " [ 2.27984858e+00  7.05790520e+00  7.90980301e+01  1.09214005e+02]\n",
      " [ 1.40022898e+00  5.33328629e+00  7.99959412e+01  1.04534073e+02]\n",
      " [ 2.17891836e+00  5.83281040e+00  7.94364090e+01  1.05583061e+02]\n",
      " [ 2.18515682e+00  5.70584154e+00  7.81927643e+01  1.07330917e+02]\n",
      " [ 1.57808352e+00  6.29039097e+00  7.81663666e+01  1.06400253e+02]\n",
      " [ 1.15743303e+00  4.98490047e+00  7.88602829e+01  1.07507423e+02]\n",
      " [ 9.25889015e-01  5.39280701e+00  7.88543549e+01  1.07159019e+02]\n",
      " [ 2.22628593e-01  5.65568686e+00  7.91759186e+01  1.05008263e+02]\n",
      " [ 6.71477318e-01  6.95861053e+00  7.91612625e+01  1.06060173e+02]\n",
      " [ 3.07119179e+00  6.62748146e+00  7.89481049e+01  1.06237000e+02]\n",
      " [ 1.45298052e+00  6.80401754e+00  8.19030228e+01  1.07398697e+02]\n",
      " [ 7.50808239e-01  4.54275417e+00  7.76214828e+01  1.09601044e+02]\n",
      " [ 1.34479046e+00  6.56063080e+00  7.53079453e+01  1.09173111e+02]\n",
      " [ 5.00578880e-01  5.19052601e+00  7.75834198e+01  1.09692146e+02]\n",
      " [ 1.44972944e+00  8.23614979e+00  8.16215515e+01  1.06929901e+02]\n",
      " [ 1.63375568e+00  7.50395346e+00  7.89041595e+01  1.09008408e+02]\n",
      " [ 3.88355684e+00  4.95812750e+00  8.12066650e+01  1.10103615e+02]\n",
      " [ 2.81558180e+00  5.81194544e+00  8.04426270e+01  1.07075203e+02]\n",
      " [ 8.30112457e-01  8.90856171e+00  7.96949310e+01  1.08719421e+02]\n",
      " [ 1.06406307e+00  4.80615139e+00  7.72162170e+01  1.10230339e+02]\n",
      " [ 5.13529778e-01  6.07018900e+00  7.97432785e+01  1.05640030e+02]\n",
      " [ 2.59802008e+00  1.10843124e+01  7.94611664e+01  1.06833603e+02]\n",
      " [ 1.37233782e+00  5.74240446e+00  7.77557831e+01  1.11347733e+02]\n",
      " [ 8.38911057e-01  7.93125629e+00  7.90673447e+01  1.06588104e+02]\n",
      " [ 1.05898952e+00  7.54077005e+00  8.09681244e+01  1.06265594e+02]\n",
      " [ 9.58406448e-01  6.60171652e+00  7.96335983e+01  1.06168976e+02]\n",
      " [ 4.67026711e+00  3.24122572e+00  7.98720245e+01  1.13119560e+02]\n",
      " [ 1.60926580e+00  2.13345671e+00  7.89606628e+01  1.08916176e+02]\n",
      " [ 4.61552620e-01  1.94533491e+00  8.01635742e+01  1.09780869e+02]\n",
      " [-7.02619553e-03  3.58220148e+00  8.00732117e+01  1.12244560e+02]\n",
      " [ 4.61372709e+00  1.52212162e+01  8.28341217e+01  1.09266266e+02]\n",
      " [ 4.69568825e+00 -2.84188747e-01  8.47812881e+01  1.11471710e+02]\n",
      " [ 1.94200373e+00  5.83339453e+00  8.35503769e+01  1.10457443e+02]\n",
      " [-2.78486681e+00  9.46553993e+00  7.62769623e+01  1.10168365e+02]\n",
      " [ 9.39867973e+00  5.13720036e-01  8.25621338e+01  1.09677849e+02]\n",
      " [-1.74489975e-01  1.50340328e+01  7.72716751e+01  1.10323685e+02]\n",
      " [ 4.38814116e+00  4.08023357e-01  8.18873062e+01  1.07767944e+02]\n",
      " [ 7.42981291e+00 -2.68303204e+00  8.68721466e+01  1.12291969e+02]\n",
      " [ 9.44682121e+00  1.25431538e+01  8.48333740e+01  1.04881371e+02]\n",
      " [-2.89902163e+00 -2.83695412e+00  7.91263275e+01  1.11515900e+02]\n",
      " [ 5.69169235e+00  3.51627207e+00  8.64550476e+01  1.12621414e+02]] (43, 4)\n",
      "\n",
      "[0.99416214 0.9887782  0.9823172  0.98101956 0.9768859  0.9734427\n",
      " 0.96807486 0.9622297  0.96206343 0.95986754 0.95446754 0.95119774\n",
      " 0.9504162  0.944674   0.93896794 0.9090792  0.9066609  0.89510626\n",
      " 0.8843864  0.86787707 0.8653535  0.85891265 0.8413366  0.7429619\n",
      " 0.7224354  0.6081397  0.568363   0.5109716  0.5022395  0.42872223\n",
      " 0.37156364 0.34611    0.16153666 0.13199705 0.12327153 0.11303064\n",
      " 0.10418595 0.09132934 0.06981768 0.04324916 0.0362454  0.03581384\n",
      " 0.0309073 ] (43,)\n",
      "Tensor in gpu\n",
      "test [[[167. 155. 155.]\n",
      "  [158. 146. 146.]\n",
      "  [152. 140. 140.]\n",
      "  ...\n",
      "  [168. 154. 151.]\n",
      "  [166. 152. 149.]\n",
      "  [166. 152. 149.]]\n",
      "\n",
      " [[164. 152. 152.]\n",
      "  [161. 149. 149.]\n",
      "  [159. 147. 147.]\n",
      "  ...\n",
      "  [173. 159. 156.]\n",
      "  [171. 157. 154.]\n",
      "  [169. 155. 152.]]\n",
      "\n",
      " [[160. 148. 148.]\n",
      "  [163. 151. 151.]\n",
      "  [165. 153. 153.]\n",
      "  ...\n",
      "  [176. 162. 159.]\n",
      "  [172. 158. 155.]\n",
      "  [169. 155. 152.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 87.  80.  51.]\n",
      "  [ 85.  78.  49.]\n",
      "  [ 84.  77.  48.]\n",
      "  ...\n",
      "  [124. 128. 103.]\n",
      "  [124. 128. 103.]\n",
      "  [124. 128. 103.]]\n",
      "\n",
      " [[ 84.  77.  48.]\n",
      "  [ 82.  75.  46.]\n",
      "  [ 81.  74.  45.]\n",
      "  ...\n",
      "  [125. 129. 104.]\n",
      "  [126. 130. 105.]\n",
      "  [126. 130. 105.]]\n",
      "\n",
      " [[ 81.  74.  45.]\n",
      "  [ 79.  72.  43.]\n",
      "  [ 78.  71.  42.]\n",
      "  ...\n",
      "  [126. 130. 105.]\n",
      "  [127. 131. 106.]\n",
      "  [128. 132. 107.]]] (3072, 1728, 3)\n",
      "torch.Size([1, 3, 3072, 1728])\n",
      "Forward time: 0.0042\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f400>\n",
      "[[ 516.94775  941.1658  1103.6642  1788.1687 ]\n",
      " [ 538.0271   864.20325 1181.0363  1667.5653 ]\n",
      " [ 538.59717  861.44946 1172.6309  1668.4373 ]\n",
      " ...\n",
      " [ 492.38507  901.1151  1000.1136  1644.6229 ]\n",
      " [ 573.6499  1081.6265  1168.9725  1793.2427 ]\n",
      " [ 585.5637   709.18274 1116.0994  1421.1677 ]] (312, 4)\n",
      "\n",
      "[0.96537024 0.95933706 0.951934   0.9507905  0.9416848  0.9290151\n",
      " 0.9287955  0.92520666 0.91100633 0.9104119  0.90990275 0.90843844\n",
      " 0.90786105 0.8962211  0.89210176 0.89074606 0.88746643 0.88743967\n",
      " 0.87442887 0.87206405 0.8694384  0.86942273 0.8614199  0.85965633\n",
      " 0.8571277  0.84449023 0.84361845 0.8426671  0.8411358  0.84046525\n",
      " 0.83649576 0.8362496  0.8285261  0.8270425  0.82516116 0.8248967\n",
      " 0.8240435  0.82067466 0.81936973 0.8157593  0.8154991  0.8040008\n",
      " 0.7990263  0.7907707  0.78943104 0.77981335 0.77978337 0.77807814\n",
      " 0.77660245 0.77220416 0.7517329  0.74921936 0.743445   0.7419487\n",
      " 0.7408505  0.7399238  0.7348336  0.7316435  0.72508025 0.7238555\n",
      " 0.72375745 0.72260445 0.7196206  0.7188865  0.7133903  0.7072437\n",
      " 0.704604   0.7044524  0.70251864 0.70215654 0.6958035  0.6903825\n",
      " 0.68554795 0.6848714  0.67932004 0.6746397  0.66442776 0.6590153\n",
      " 0.6557265  0.64348274 0.6401137  0.62394345 0.6207502  0.61885846\n",
      " 0.6092993  0.60784715 0.6077     0.5983262  0.59674215 0.59480315\n",
      " 0.59389645 0.57652307 0.57066417 0.55858165 0.5499631  0.540168\n",
      " 0.5394449  0.5321538  0.5315376  0.53035897 0.5293037  0.520176\n",
      " 0.51034206 0.50792146 0.5075704  0.49420157 0.49418032 0.4837661\n",
      " 0.47206652 0.47140512 0.46453315 0.45285863 0.45159662 0.45136958\n",
      " 0.4467938  0.43243054 0.4233087  0.42135268 0.41588834 0.41145077\n",
      " 0.4097367  0.3913448  0.38926423 0.38813293 0.38720274 0.37903956\n",
      " 0.36971757 0.36902708 0.36612293 0.36550176 0.3562729  0.35208252\n",
      " 0.33859262 0.33856925 0.33118266 0.3225816  0.32241574 0.31624246\n",
      " 0.31215233 0.31042093 0.29952747 0.29849124 0.29757273 0.2955189\n",
      " 0.29455075 0.29313284 0.27461576 0.2739238  0.25385553 0.25284\n",
      " 0.24107102 0.24003465 0.23999894 0.23593259 0.22814652 0.22814374\n",
      " 0.22214623 0.22061083 0.21808672 0.20596287 0.202808   0.20077163\n",
      " 0.19577456 0.19509952 0.19146146 0.18857104 0.18650982 0.18466325\n",
      " 0.18386288 0.1812806  0.17510632 0.16675036 0.16576272 0.16567221\n",
      " 0.16465978 0.16418345 0.16404039 0.1635062  0.16038947 0.15623796\n",
      " 0.15521072 0.15379044 0.15297057 0.15253836 0.15250237 0.14787462\n",
      " 0.14614218 0.14531375 0.1446623  0.13925165 0.13861224 0.13855226\n",
      " 0.13729094 0.13365456 0.13000262 0.12840427 0.12445039 0.12145709\n",
      " 0.11760458 0.11542998 0.11496754 0.1139591  0.11249996 0.11194824\n",
      " 0.11134857 0.10961261 0.10951467 0.10927107 0.10493688 0.10479228\n",
      " 0.10382589 0.10371272 0.10104473 0.10085007 0.10070075 0.09837448\n",
      " 0.09825196 0.09725685 0.09503757 0.09416427 0.09410805 0.09333587\n",
      " 0.09247554 0.08836758 0.0882081  0.08808515 0.086871   0.08637527\n",
      " 0.08603217 0.08375486 0.0800138  0.0798856  0.07985566 0.07858256\n",
      " 0.07486673 0.07465772 0.07213742 0.07186962 0.06910706 0.06884127\n",
      " 0.06850602 0.06806193 0.06638977 0.06594178 0.06562448 0.06528293\n",
      " 0.05962573 0.05915656 0.05780683 0.05633051 0.05271029 0.0510986\n",
      " 0.04899306 0.04752248 0.04739596 0.04536547 0.04529524 0.04480004\n",
      " 0.04440025 0.04426552 0.04351488 0.0432763  0.04236201 0.04203892\n",
      " 0.04105521 0.0403965  0.04023087 0.04013376 0.03980199 0.03961318\n",
      " 0.03761694 0.03724422 0.03721439 0.03713215 0.03656089 0.03569948\n",
      " 0.03523233 0.03480549 0.03456989 0.03434119 0.034257   0.03407865\n",
      " 0.03367633 0.03245592 0.03220967 0.03179786 0.0308526  0.0308066\n",
      " 0.0305114  0.02996166 0.02957316 0.02935847 0.02879652 0.02857428\n",
      " 0.02694979 0.02673867 0.02546239 0.02542418 0.02503947 0.02297788\n",
      " 0.02266817 0.02256132 0.0221907  0.02168223 0.02109412 0.02099883\n",
      " 0.02093823 0.02089074 0.02069572 0.02048958 0.02024122 0.02000658] (312,)\n",
      "Tensor in gpu\n",
      "test [[[2. 2. 2.]\n",
      "  [2. 2. 2.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 2. 2.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [2. 2. 2.]\n",
      "  ...\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 2. 2.]]\n",
      "\n",
      " [[2. 2. 2.]\n",
      "  [2. 1. 1.]\n",
      "  [2. 2. 2.]\n",
      "  ...\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[3. 2. 2.]\n",
      "  [2. 2. 2.]\n",
      "  [3. 2. 2.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [0. 0. 0.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[3. 2. 2.]\n",
      "  [3. 2. 2.]\n",
      "  [4. 3. 3.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[3. 2. 2.]\n",
      "  [3. 2. 2.]\n",
      "  [4. 3. 3.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0046\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f2b0>\n",
      "[[ 21.385216  24.861336 100.0563   106.73774 ]\n",
      " [ 20.590227  24.247728  98.930984 106.457565]\n",
      " [ 20.878586  25.284437  99.08912  107.14395 ]\n",
      " [ 20.35177   24.775204 100.41581  105.7811  ]\n",
      " [ 20.49229   25.464005  99.97479  106.83315 ]\n",
      " [ 20.418207  24.399067  99.2858   106.080185]\n",
      " [ 19.749989  22.316658  99.70991  107.45194 ]\n",
      " [ 21.040207  26.615412  98.69973  106.08806 ]\n",
      " [ 22.458263  22.401787  98.89379  107.11285 ]\n",
      " [ 20.284834  21.394596 100.16751  106.90065 ]\n",
      " [ 21.035725  27.573215  99.862015 106.474846]\n",
      " [ 20.254091  21.379402  99.35181  105.66532 ]\n",
      " [ 18.86406   21.813965  99.52659  105.51416 ]\n",
      " [ 19.385994  20.800432 100.67045  107.28984 ]\n",
      " [ 18.271519  21.232756  97.79317  106.30524 ]\n",
      " [ 21.308716  19.092997 100.105    107.75935 ]\n",
      " [ 19.437325  21.290318  99.02514  107.60209 ]\n",
      " [ 19.849342  20.659111  98.677574 106.81469 ]\n",
      " [ 19.274633  21.387833  99.12231  107.1346  ]\n",
      " [ 19.27515   20.192509  99.80036  108.6777  ]\n",
      " [ 19.737972  21.530266 100.148544 106.29625 ]\n",
      " [ 21.314957  17.382835  99.75983  108.421165]\n",
      " [ 19.696053  23.243322 100.29631  106.081924]\n",
      " [ 19.575401  21.541124 100.288956 105.08644 ]\n",
      " [ 20.440098  21.302107  99.88931  105.824936]\n",
      " [ 20.924755  23.51684  101.28572  108.4049  ]\n",
      " [ 22.663727  29.001095 102.91162  105.37199 ]\n",
      " [ 18.74573   17.41943   98.75179  106.78316 ]\n",
      " [ 18.947313  29.056362  95.881714 108.32403 ]\n",
      " [ 24.306087  24.719698 101.39048  104.89529 ]\n",
      " [ 18.086662  18.18855   98.59875  106.51578 ]\n",
      " [ 18.183052  17.28749   96.12736  106.52028 ]\n",
      " [ 16.001314  12.066448  97.188126 107.27725 ]\n",
      " [ 19.206795  10.714498 102.68964  107.48224 ]\n",
      " [ 18.132648  10.047316 101.1828   109.297295]\n",
      " [ 18.497179  10.94223  102.72232  107.246284]] (36, 4)\n",
      "\n",
      "[0.9958983  0.99359375 0.9925661  0.9920515  0.97256356 0.94075596\n",
      " 0.8965979  0.89229006 0.88249147 0.8787832  0.8760315  0.8587279\n",
      " 0.8250497  0.8101187  0.808711   0.751225   0.74288714 0.7389891\n",
      " 0.66318357 0.63439626 0.59519476 0.53058887 0.50901544 0.47517988\n",
      " 0.46505266 0.35112926 0.3273094  0.21094236 0.18631418 0.12075887\n",
      " 0.11124165 0.09819234 0.03087861 0.03084451 0.02613655 0.0203396 ] (36,)\n",
      "Tensor in gpu\n",
      "test [[[131. 101.  64.]\n",
      "  [135. 106.  69.]\n",
      "  [139. 111.  74.]\n",
      "  ...\n",
      "  [ 43.  43.  44.]\n",
      "  [ 64.  65.  68.]\n",
      "  [ 93.  96. 100.]]\n",
      "\n",
      " [[130.  99.  62.]\n",
      "  [133. 103.  68.]\n",
      "  [139. 110.  73.]\n",
      "  ...\n",
      "  [ 63.  63.  64.]\n",
      "  [ 79.  79.  82.]\n",
      "  [100. 102. 106.]]\n",
      "\n",
      " [[129.  97.  61.]\n",
      "  [133. 102.  67.]\n",
      "  [139. 110.  73.]\n",
      "  ...\n",
      "  [ 89.  91.  94.]\n",
      "  [ 95.  97. 101.]\n",
      "  [103. 106. 111.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 11.  10.   9.]\n",
      "  [ 10.   9.   8.]\n",
      "  [  9.   9.   8.]\n",
      "  ...\n",
      "  [ 95.  91.  80.]\n",
      "  [ 96.  91.  80.]\n",
      "  [ 97.  92.  81.]]\n",
      "\n",
      " [[ 10.  10.   9.]\n",
      "  [  9.   8.   8.]\n",
      "  [ 10.   9.   8.]\n",
      "  ...\n",
      "  [ 95.  90.  80.]\n",
      "  [ 95.  90.  79.]\n",
      "  [ 95.  90.  80.]]\n",
      "\n",
      " [[ 10.  10.   9.]\n",
      "  [ 12.  11.  10.]\n",
      "  [ 12.  11.  10.]\n",
      "  ...\n",
      "  [ 93.  88.  78.]\n",
      "  [ 93.  88.  77.]\n",
      "  [ 93.  88.  78.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f2e0>\n",
      "[[ 2.31173182e+00  1.19247789e+01  7.77545013e+01  1.04111839e+02]\n",
      " [ 1.82510185e+00  1.15833426e+01  7.78752441e+01  1.03462471e+02]\n",
      " [ 2.51364565e+00  1.19314919e+01  7.77795258e+01  1.05059921e+02]\n",
      " [ 2.18696260e+00  1.21295738e+01  7.95966949e+01  1.03186180e+02]\n",
      " [ 2.83155346e+00  1.19094486e+01  7.60329895e+01  1.05198280e+02]\n",
      " [ 2.19056082e+00  1.26474552e+01  7.62013702e+01  1.05334457e+02]\n",
      " [ 2.12784243e+00  1.31162510e+01  7.92474518e+01  1.03102829e+02]\n",
      " [ 3.07840157e+00  1.13509541e+01  7.72822189e+01  1.02797173e+02]\n",
      " [ 2.99763870e+00  9.09059906e+00  7.60806351e+01  1.03143295e+02]\n",
      " [ 2.56051588e+00  1.01161728e+01  7.75102005e+01  1.00366905e+02]\n",
      " [ 1.47394562e+00  9.73940849e+00  7.78187256e+01  1.02597458e+02]\n",
      " [ 2.26428747e+00  1.64237328e+01  7.67758179e+01  1.03778351e+02]\n",
      " [ 2.31907511e+00  1.18387260e+01  7.66603088e+01  1.02945145e+02]\n",
      " [ 2.40052223e+00  1.05077906e+01  7.82683487e+01  1.01905891e+02]\n",
      " [ 3.90651131e+00  9.75383472e+00  8.00537033e+01  1.04735275e+02]\n",
      " [ 1.18730021e+00  1.04202881e+01  7.76199493e+01  1.01956299e+02]\n",
      " [ 2.48569775e+00  9.47976303e+00  7.58504868e+01  1.03790535e+02]\n",
      " [ 4.53064442e-01  9.25539589e+00  7.60528641e+01  1.06222069e+02]\n",
      " [-6.94141388e-02  9.43530273e+00  7.28032990e+01  1.06735703e+02]\n",
      " [ 5.75547218e-01  1.01308126e+01  7.85422287e+01  1.01646729e+02]\n",
      " [ 1.16679573e+00  1.10815821e+01  7.48942490e+01  1.07140709e+02]\n",
      " [-3.96003723e-02  8.21438408e+00  7.42944031e+01  1.06989120e+02]\n",
      " [ 1.42451525e+00  6.24263954e+00  7.68290329e+01  1.05977272e+02]\n",
      " [ 1.94683027e+00  9.28606415e+00  7.97280197e+01  1.01502098e+02]\n",
      " [ 8.46057415e-01  1.19134941e+01  7.89679337e+01  1.01749542e+02]\n",
      " [ 1.61463642e+00  1.23599796e+01  7.91401596e+01  1.04048950e+02]\n",
      " [ 4.12801170e+00  7.68718529e+00  7.81282883e+01  1.08775841e+02]\n",
      " [ 1.01811075e+00  1.29255695e+01  7.80309067e+01  1.03783218e+02]\n",
      " [ 1.82889032e+00  1.28674774e+01  7.73655396e+01  1.04403473e+02]\n",
      " [ 9.29340363e-01  6.14086485e+00  7.87421875e+01  1.01877831e+02]\n",
      " [ 1.41357374e+00  1.82968102e+01  7.42417755e+01  1.06302284e+02]\n",
      " [-2.46447563e-01  6.13949299e+00  7.80893860e+01  1.03956001e+02]\n",
      " [-1.04362202e+00  6.53059673e+00  7.81836166e+01  1.08060974e+02]\n",
      " [ 8.07135582e+00  3.75421476e+00  8.32774506e+01  1.04240372e+02]\n",
      " [ 4.46518564e+00  1.84437160e+01  8.05533295e+01  1.06811165e+02]\n",
      " [ 2.01643467e+00  1.27647610e+01  8.30261688e+01  1.07747086e+02]\n",
      " [ 4.07985640e+00  2.41333294e+00  8.63774261e+01  1.06413811e+02]\n",
      " [-2.54596949e+00  1.29795227e+01  7.37787781e+01  1.08447487e+02]\n",
      " [ 7.53030920e+00  1.49658566e+01  8.44731445e+01  1.00878944e+02]\n",
      " [ 3.43760538e+00  2.32253647e+00  8.35234833e+01  1.00665192e+02]\n",
      " [-5.05876398e+00 -3.24008751e+00  7.74534302e+01  1.05547394e+02]\n",
      " [ 6.95445156e+00 -1.04130554e+00  8.90349274e+01  1.06067970e+02]\n",
      " [ 8.49136257e+00  2.00713844e+01  8.61709747e+01  1.03385208e+02]\n",
      " [ 1.29760246e+01  7.56605434e+00  8.89457474e+01  9.90309830e+01]\n",
      " [-1.81583595e+00  2.13385620e+01  6.78319397e+01  1.04056534e+02]\n",
      " [-2.69702101e+00  1.87531471e+01  6.90921402e+01  1.03447075e+02]] (46, 4)\n",
      "\n",
      "[0.9960975  0.9940201  0.97780085 0.96303636 0.9587491  0.943459\n",
      " 0.93357104 0.9190608  0.9052469  0.9052217  0.88574666 0.8835228\n",
      " 0.88152254 0.8530502  0.85262865 0.8412487  0.8411223  0.821289\n",
      " 0.7917667  0.78312194 0.751418   0.7155073  0.6510623  0.62357175\n",
      " 0.5830389  0.46216515 0.4524382  0.2973372  0.28959063 0.27376154\n",
      " 0.19927093 0.1887335  0.14893843 0.1177114  0.10368379 0.09523379\n",
      " 0.0852776  0.07447597 0.06833129 0.0596917  0.03473042 0.03175067\n",
      " 0.03130919 0.02919429 0.02844593 0.02282913] (46,)\n",
      "Tensor in gpu\n",
      "test [[[169. 171. 176.]\n",
      "  [170. 172. 177.]\n",
      "  [170. 171. 176.]\n",
      "  ...\n",
      "  [190. 191. 194.]\n",
      "  [191. 191. 195.]\n",
      "  [190. 191. 194.]]\n",
      "\n",
      " [[169. 170. 175.]\n",
      "  [170. 171. 176.]\n",
      "  [170. 171. 176.]\n",
      "  ...\n",
      "  [188. 189. 192.]\n",
      "  [189. 189. 193.]\n",
      "  [188. 189. 192.]]\n",
      "\n",
      " [[169. 171. 176.]\n",
      "  [169. 170. 175.]\n",
      "  [169. 171. 176.]\n",
      "  ...\n",
      "  [186. 187. 190.]\n",
      "  [186. 187. 191.]\n",
      "  [186. 187. 191.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 80.  77.  37.]\n",
      "  [ 78.  75.  35.]\n",
      "  [ 78.  73.  35.]\n",
      "  ...\n",
      "  [ 73.  66.  50.]\n",
      "  [ 76.  68.  52.]\n",
      "  [ 76.  69.  52.]]\n",
      "\n",
      " [[ 81.  77.  36.]\n",
      "  [ 80.  75.  35.]\n",
      "  [ 81.  74.  36.]\n",
      "  ...\n",
      "  [ 76.  69.  51.]\n",
      "  [ 75.  68.  50.]\n",
      "  [ 76.  69.  51.]]\n",
      "\n",
      " [[ 82.  77.  36.]\n",
      "  [ 84.  76.  36.]\n",
      "  [ 85.  76.  37.]\n",
      "  ...\n",
      "  [ 77.  70.  49.]\n",
      "  [ 76.  70.  48.]\n",
      "  [ 75.  70.  47.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f1f0>\n",
      "[[ 14.940826   12.093798   92.9288    107.71294  ]\n",
      " [ 14.634077   12.052352   92.622894  107.77298  ]\n",
      " [ 15.507662   12.690193   92.09169   108.28265  ]\n",
      " [ 14.901009   12.858288   92.48905   108.3508   ]\n",
      " [ 14.677412   12.463654   93.04173   108.58987  ]\n",
      " [ 14.744089   10.577421   92.09525   106.16405  ]\n",
      " [ 14.468262   12.500029   90.86102   106.73743  ]\n",
      " [ 14.284653   11.364515   91.24592   107.268074 ]\n",
      " [ 14.61993    11.564704   91.30344   106.01908  ]\n",
      " [ 14.0342     10.758381   90.90359   105.90953  ]\n",
      " [ 15.114345   12.625639   92.19667   107.40228  ]\n",
      " [ 15.47006    10.463858   93.31774   107.02874  ]\n",
      " [ 13.780399   10.635477   91.612274  107.45059  ]\n",
      " [ 15.928235   11.99167    92.57195   106.842896 ]\n",
      " [ 14.867666   11.665834   91.70684   106.35497  ]\n",
      " [ 14.266264   10.596484   92.95693   107.2174   ]\n",
      " [ 13.734364   10.555075   90.279594  107.67942  ]\n",
      " [ 15.227231   12.988882   93.53213   107.02287  ]\n",
      " [ 16.286238   15.74727    92.555885  107.038414 ]\n",
      " [ 14.52082     9.152523   91.13506   108.7441   ]\n",
      " [ 15.366222   11.442835   93.418884  107.30578  ]\n",
      " [ 14.588114   10.5549345  91.777855  107.974304 ]\n",
      " [ 14.836798   11.133159   91.95738   107.8167   ]\n",
      " [ 16.22377     9.371276   91.8981    108.907776 ]\n",
      " [ 15.640852   13.197102   93.06186   107.67688  ]\n",
      " [ 16.062931    7.249515   90.8345    110.37697  ]\n",
      " [ 15.342718   12.292974   92.72764   106.25155  ]\n",
      " [ 15.078213   12.570852   93.30702   105.98252  ]\n",
      " [ 17.42615     6.2169614  91.429985  110.67335  ]\n",
      " [ 14.014589   16.411093   91.178406  108.837326 ]\n",
      " [ 13.110701    6.104202   93.08495   108.97519  ]\n",
      " [ 12.630963    6.545644   89.52524   108.14283  ]\n",
      " [ 13.24573     6.1341724  92.009735  108.449905 ]\n",
      " [ 14.073072   13.894159   91.58761   105.99922  ]\n",
      " [ 17.454609   18.891853   95.353455  110.549934 ]\n",
      " [ 14.963303    3.7558136  87.95032   102.82364  ]\n",
      " [ 16.141535   13.619488   96.844284  113.593666 ]\n",
      " [  9.82871     4.3130693  88.480865  109.19937  ]\n",
      " [ 11.846596   20.190102   86.8984    106.52242  ]\n",
      " [ 11.556706   16.286137   86.127304  104.2832   ]\n",
      " [ 13.471416    1.2072573  96.0985    110.80406  ]] (41, 4)\n",
      "\n",
      "[0.9979235  0.99621564 0.9939873  0.9928585  0.98453104 0.97921616\n",
      " 0.97777766 0.97469395 0.9726442  0.9722106  0.9646462  0.96240765\n",
      " 0.9577647  0.95663446 0.9484007  0.9409041  0.9341571  0.92777866\n",
      " 0.9012788  0.8985475  0.895901   0.83616066 0.75586236 0.74146\n",
      " 0.7135204  0.6077271  0.5981333  0.5752256  0.4738533  0.3877108\n",
      " 0.32406202 0.20550115 0.19141749 0.15516128 0.11959243 0.07155134\n",
      " 0.06937252 0.05611198 0.04178548 0.03329066 0.02572507] (41,)\n",
      "Tensor in gpu\n",
      "test [[[  1.   1.   1.]\n",
      "  [  1.   1.   1.]\n",
      "  [  1.   1.   1.]\n",
      "  ...\n",
      "  [186. 166. 132.]\n",
      "  [185. 166. 133.]\n",
      "  [183. 165. 132.]]\n",
      "\n",
      " [[  1.   1.   1.]\n",
      "  [  1.   1.   1.]\n",
      "  [  2.   2.   2.]\n",
      "  ...\n",
      "  [185. 165. 131.]\n",
      "  [185. 165. 134.]\n",
      "  [186. 166. 135.]]\n",
      "\n",
      " [[  1.   1.   1.]\n",
      "  [  2.   2.   2.]\n",
      "  [  3.   3.   4.]\n",
      "  ...\n",
      "  [185. 164. 130.]\n",
      "  [185. 165. 133.]\n",
      "  [186. 166. 133.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 37.  47.  59.]\n",
      "  [ 31.  40.  53.]\n",
      "  [ 26.  34.  46.]\n",
      "  ...\n",
      "  [  1.   0.   1.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[ 34.  43.  55.]\n",
      "  [ 27.  36.  46.]\n",
      "  [ 22.  29.  39.]\n",
      "  ...\n",
      "  [  1.   1.   1.]\n",
      "  [  1.   1.   1.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[ 30.  39.  49.]\n",
      "  [ 23.  29.  38.]\n",
      "  [ 17.  23.  30.]\n",
      "  ...\n",
      "  [  3.   2.   3.]\n",
      "  [  1.   0.   1.]\n",
      "  [  1.   0.   0.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f730>\n",
      "[[ 27.79531    11.894682  102.66537   108.16158  ]\n",
      " [ 26.960407   11.022228  102.3444    108.347336 ]\n",
      " [ 27.24649    10.4819355 102.03611   108.598946 ]\n",
      " [ 27.239298    9.216816  103.78142   108.260315 ]\n",
      " [ 27.022495   10.95505   102.43847   110.75648  ]\n",
      " [ 27.85738    11.315025  101.91933   111.1597   ]\n",
      " [ 25.190262    9.0481205 101.60155   111.55239  ]\n",
      " [ 25.853146    9.8121    101.26754   108.62526  ]\n",
      " [ 26.892498    9.507177  102.24345   106.99146  ]\n",
      " [ 27.141937    9.0957155 102.04883   106.50639  ]\n",
      " [ 27.67654    11.263315  101.95914   108.53421  ]\n",
      " [ 27.411892    7.6415434 103.940926  108.02984  ]\n",
      " [ 27.308079    9.287231  102.74191   109.83208  ]\n",
      " [ 25.846329    8.595924  102.70083   110.08993  ]\n",
      " [ 27.980827   10.684484  101.60509   106.76995  ]\n",
      " [ 26.520573    9.7586975 100.7382    107.03321  ]\n",
      " [ 27.176016   10.726517  102.22308   109.99712  ]\n",
      " [ 26.954435    9.684267  103.2573    111.470856 ]\n",
      " [ 28.560617   13.167705  101.81755   110.223305 ]\n",
      " [ 27.273495    9.7309265 103.79629   110.521225 ]\n",
      " [ 26.881817   13.463619  101.40327   110.707954 ]\n",
      " [ 25.199345    8.047531  103.60098   109.65449  ]\n",
      " [ 27.890669   10.427655  104.54956   113.01941  ]\n",
      " [ 24.822727    5.2687654 101.47412   112.94667  ]\n",
      " [ 25.28139     7.748345  103.152306  108.29866  ]\n",
      " [ 27.317327    6.5278196 105.68176   114.00528  ]\n",
      " [ 25.843922   13.230333   98.943565  107.42709  ]\n",
      " [ 28.878426   14.598215  106.83427   109.94974  ]\n",
      " [ 28.223396    4.3378763 103.32393   112.75369  ]\n",
      " [ 26.881569    4.1235156  99.06741   111.44086  ]\n",
      " [ 27.859203   14.008892  104.55384   108.117294 ]\n",
      " [ 28.4279      5.8712826 102.47049   111.99738  ]\n",
      " [ 24.331367    6.462351  103.95022   111.77315  ]\n",
      " [ 25.702868    6.3173943 104.29875   113.12016  ]\n",
      " [ 25.184765    7.974802   96.89421   105.00159  ]\n",
      " [ 24.430729    1.8826532 101.59939   112.667114 ]\n",
      " [ 25.74358    14.381714  100.18613   109.20932  ]\n",
      " [ 24.37629     2.233399  101.676315  113.43811  ]\n",
      " [ 26.54942     2.6110077 104.96602   110.04627  ]\n",
      " [ 26.403511    5.051571  102.67906   116.303955 ]\n",
      " [ 29.240139    8.800829  106.41971   108.82393  ]\n",
      " [ 25.343473    4.403432  100.66577   118.010284 ]] (42, 4)\n",
      "\n",
      "[0.98753566 0.9874894  0.98048383 0.9756394  0.96729803 0.96718895\n",
      " 0.94538265 0.93955064 0.938288   0.93770003 0.9354906  0.9347481\n",
      " 0.9173644  0.914265   0.912305   0.9102462  0.89121205 0.86579823\n",
      " 0.8091565  0.6250536  0.622784   0.6137995  0.592409   0.5183042\n",
      " 0.47047618 0.3519133  0.25183034 0.25000957 0.23873016 0.23091622\n",
      " 0.21262692 0.20578146 0.18094034 0.1690284  0.14593805 0.14104453\n",
      " 0.13973422 0.10433603 0.0873448  0.06122154 0.05615104 0.04879643] (42,)\n",
      "Tensor in gpu\n",
      "test [[[ 25.  30.  26.]\n",
      "  [ 13.  18.  14.]\n",
      "  [  5.  10.   6.]\n",
      "  ...\n",
      "  [126. 159. 213.]\n",
      "  [145. 182. 237.]\n",
      "  [165. 202. 255.]]\n",
      "\n",
      " [[ 18.  23.  19.]\n",
      "  [ 17.  22.  18.]\n",
      "  [ 10.  15.  11.]\n",
      "  ...\n",
      "  [129. 162. 216.]\n",
      "  [148. 185. 240.]\n",
      "  [167. 204. 255.]]\n",
      "\n",
      " [[  9.  11.   8.]\n",
      "  [ 18.  20.  17.]\n",
      "  [ 16.  18.  15.]\n",
      "  ...\n",
      "  [133. 166. 219.]\n",
      "  [153. 188. 242.]\n",
      "  [171. 206. 255.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[108.  56.  60.]\n",
      "  [109.  57.  61.]\n",
      "  [109.  57.  61.]\n",
      "  ...\n",
      "  [101.  51.  54.]\n",
      "  [ 98.  49.  55.]\n",
      "  [ 95.  45.  54.]]\n",
      "\n",
      " [[108.  56.  60.]\n",
      "  [108.  56.  60.]\n",
      "  [108.  56.  60.]\n",
      "  ...\n",
      "  [ 99.  48.  53.]\n",
      "  [ 96.  46.  55.]\n",
      "  [ 92.  42.  53.]]\n",
      "\n",
      " [[111.  59.  63.]\n",
      "  [110.  58.  62.]\n",
      "  [107.  55.  59.]\n",
      "  ...\n",
      "  [ 98.  47.  54.]\n",
      "  [ 94.  44.  55.]\n",
      "  [ 91.  41.  52.]]] (3072, 2307, 3)\n",
      "torch.Size([1, 3, 3072, 2307])\n",
      "Forward time: 0.0042\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f6d0>\n",
      "[[ 286.32098  909.6737   376.1327  1050.9374 ]\n",
      " [ 285.6608   911.37915  376.8425  1053.0884 ]\n",
      " [ 285.41373  909.58923  375.57852 1053.2407 ]\n",
      " ...\n",
      " [1186.6554   953.3898  1260.2297  1070.3325 ]\n",
      " [1629.6262  1284.7346  1941.7627  1788.6193 ]\n",
      " [1276.2314   876.661   1314.1847   939.37854]] (500, 4)\n",
      "\n",
      "[0.9906955  0.98813117 0.98121613 0.9756606  0.9738471  0.9722271\n",
      " 0.97122914 0.9686987  0.9608428  0.9486597  0.9398764  0.93735915\n",
      " 0.9359215  0.93568844 0.92786354 0.9186553  0.9079714  0.9060136\n",
      " 0.90139264 0.88437015 0.88337386 0.8787692  0.8620518  0.8598901\n",
      " 0.825073   0.82226443 0.8072159  0.8010558  0.7761517  0.76747096\n",
      " 0.7644583  0.76297724 0.76255167 0.7529591  0.74125713 0.7368543\n",
      " 0.73387295 0.7260299  0.7127254  0.70630205 0.7031523  0.6929551\n",
      " 0.6924426  0.6895621  0.6869762  0.6725132  0.6708562  0.6632686\n",
      " 0.66073465 0.66057587 0.6572226  0.6527742  0.64816624 0.6425578\n",
      " 0.62346876 0.61941206 0.6093699  0.60401    0.5992821  0.59823066\n",
      " 0.5963853  0.59484434 0.5869005  0.5773778  0.57716125 0.57092804\n",
      " 0.57051486 0.56785303 0.5660111  0.56015134 0.5578249  0.55679715\n",
      " 0.5555252  0.5533741  0.55189323 0.55122846 0.54126835 0.53864974\n",
      " 0.5381402  0.5356787  0.53009397 0.52976733 0.5273134  0.5261789\n",
      " 0.52440494 0.52176774 0.51935035 0.5154722  0.5144751  0.50851154\n",
      " 0.50621676 0.505496   0.5022507  0.49714997 0.4942162  0.49377424\n",
      " 0.4905048  0.48986328 0.48493624 0.4812056  0.47581986 0.47557625\n",
      " 0.4674856  0.4583245  0.45688015 0.45583963 0.45514625 0.45296666\n",
      " 0.45187843 0.4447887  0.4363438  0.43265426 0.42917743 0.4277317\n",
      " 0.4236037  0.4228826  0.42241138 0.41690066 0.41642833 0.41107613\n",
      " 0.40957603 0.4095497  0.40825838 0.40758362 0.39788547 0.39672613\n",
      " 0.3941466  0.39256126 0.3801074  0.37744406 0.37505114 0.374388\n",
      " 0.37195593 0.36907208 0.36668262 0.35954568 0.356252   0.35109413\n",
      " 0.34926283 0.34527248 0.34023735 0.33812785 0.3345976  0.3341367\n",
      " 0.3283406  0.32252073 0.32232597 0.31742203 0.31654254 0.31240937\n",
      " 0.3064551  0.2917575  0.2870428  0.28555188 0.26774338 0.26360202\n",
      " 0.26176822 0.25723112 0.25628138 0.2558498  0.25100708 0.25006706\n",
      " 0.24713473 0.24609593 0.24327262 0.24247912 0.24206764 0.24191724\n",
      " 0.23798813 0.23675014 0.23605107 0.23423444 0.22937354 0.2273565\n",
      " 0.22671267 0.22644931 0.22588971 0.2252914  0.22525221 0.22439794\n",
      " 0.22411925 0.2201155  0.21686076 0.21490291 0.21241961 0.21185659\n",
      " 0.21163906 0.20984451 0.20980214 0.20730819 0.2062689  0.20278047\n",
      " 0.20216328 0.20093988 0.19759294 0.1973675  0.1970357  0.1944712\n",
      " 0.19282272 0.18372926 0.18042363 0.17806008 0.17748356 0.17524204\n",
      " 0.17379372 0.17344244 0.17261295 0.17239949 0.16931051 0.16749816\n",
      " 0.16408284 0.16345528 0.16293252 0.15925826 0.1589274  0.15787722\n",
      " 0.15774512 0.15701002 0.1565457  0.15556511 0.15429765 0.15409145\n",
      " 0.15230395 0.1509848  0.15073578 0.15066496 0.149346   0.1476714\n",
      " 0.14527753 0.1452076  0.14500313 0.14481387 0.14399754 0.14396225\n",
      " 0.14368632 0.14350028 0.14185365 0.14136133 0.1410812  0.14096428\n",
      " 0.14059053 0.13940582 0.13930425 0.13929507 0.13864405 0.13702214\n",
      " 0.13499959 0.13341473 0.13247868 0.13140462 0.13069895 0.12774496\n",
      " 0.12604402 0.12581864 0.12512305 0.12475273 0.12367325 0.12331785\n",
      " 0.12295125 0.1228476  0.12278771 0.12182277 0.12144817 0.12095343\n",
      " 0.1206597  0.1199257  0.11936589 0.11895245 0.11843392 0.1178785\n",
      " 0.11779813 0.11693083 0.11683019 0.11619364 0.1149976  0.11489873\n",
      " 0.11452528 0.11365772 0.11333323 0.11332566 0.112883   0.11175656\n",
      " 0.10880996 0.1083082  0.10785833 0.10720173 0.10717305 0.10678152\n",
      " 0.10647321 0.10588416 0.10446621 0.10418866 0.10262268 0.1020129\n",
      " 0.101613   0.10037294 0.10016306 0.09940788 0.0985302  0.09699191\n",
      " 0.09679171 0.09591565 0.09461461 0.09425642 0.09374652 0.09351692\n",
      " 0.09259523 0.09247869 0.09219333 0.09173002 0.09130018 0.09127115\n",
      " 0.09031147 0.08971303 0.08824213 0.08821925 0.08795436 0.0879108\n",
      " 0.08770818 0.08699057 0.08688401 0.08608545 0.08499037 0.08485834\n",
      " 0.08426791 0.08304486 0.08301657 0.08266754 0.0813817  0.0813046\n",
      " 0.08126296 0.08112799 0.07982368 0.07926171 0.07919841 0.07889112\n",
      " 0.07870498 0.07848386 0.07820158 0.07818388 0.07814299 0.07738384\n",
      " 0.07714089 0.07676797 0.07675882 0.07542036 0.07533897 0.07454436\n",
      " 0.07403951 0.07354558 0.07258296 0.07239717 0.0723673  0.07211415\n",
      " 0.07187461 0.07121163 0.07055055 0.07051817 0.07019532 0.06878901\n",
      " 0.06842416 0.06812518 0.06782962 0.06776693 0.06720431 0.06711604\n",
      " 0.06583743 0.06563206 0.06509712 0.06451516 0.06450797 0.06376126\n",
      " 0.06364326 0.06355327 0.06316327 0.06295635 0.06284206 0.06276187\n",
      " 0.06250686 0.06245434 0.06213043 0.06189219 0.06186924 0.0617105\n",
      " 0.06150602 0.06136845 0.06088205 0.0605165  0.06035309 0.06017725\n",
      " 0.05989975 0.05944496 0.05922303 0.05894048 0.05893356 0.05861821\n",
      " 0.05856403 0.0579068  0.05772153 0.05735642 0.05732113 0.05704277\n",
      " 0.05670528 0.05631725 0.05621241 0.05611876 0.05610769 0.05591365\n",
      " 0.05587307 0.05580909 0.05559155 0.0553927  0.05532578 0.05513599\n",
      " 0.05499367 0.05437119 0.05391372 0.05383493 0.05373082 0.0536654\n",
      " 0.05343556 0.05316522 0.0531335  0.05312661 0.05302732 0.05302321\n",
      " 0.05278293 0.05278242 0.05268943 0.05261283 0.05250418 0.0522771\n",
      " 0.05214192 0.05200952 0.0518264  0.05172603 0.05154715 0.05142412\n",
      " 0.05104658 0.05103517 0.0507582  0.05074511 0.0507399  0.05054582\n",
      " 0.0504956  0.05048331 0.0502193  0.0501989  0.05008981 0.05002245\n",
      " 0.04966103 0.04937937 0.04895069 0.04888251 0.04884968 0.04871693\n",
      " 0.04832035 0.04812421 0.04765983 0.04765442 0.04741014 0.04715692\n",
      " 0.04652623 0.04624429 0.04615958 0.04609456 0.04607196 0.04601171\n",
      " 0.04576147 0.04561772 0.04555086 0.0451718  0.04512498 0.04507042\n",
      " 0.04497855 0.04497545 0.04472353 0.04472158 0.04462422 0.04449552\n",
      " 0.04427502 0.04419001 0.04417996 0.0441784  0.04390397 0.04370081\n",
      " 0.04346077 0.04303778 0.04300936 0.04299595 0.04284963 0.04230501\n",
      " 0.04177802 0.04156943 0.04154891 0.04095361 0.04093688 0.04082799\n",
      " 0.04071222 0.04052478] (500,)\n",
      "Tensor in gpu\n",
      "test [[[ 47.  28.  13.]\n",
      "  [ 50.  30.  16.]\n",
      "  [ 53.  33.  18.]\n",
      "  ...\n",
      "  [ 67.  60.  52.]\n",
      "  [ 67.  59.  52.]\n",
      "  [ 66.  58.  51.]]\n",
      "\n",
      " [[ 47.  27.  13.]\n",
      "  [ 53.  32.  17.]\n",
      "  [ 54.  34.  18.]\n",
      "  ...\n",
      "  [ 66.  59.  51.]\n",
      "  [ 66.  58.  51.]\n",
      "  [ 65.  57.  50.]]\n",
      "\n",
      " [[ 49.  29.  15.]\n",
      "  [ 53.  33.  17.]\n",
      "  [ 53.  33.  17.]\n",
      "  ...\n",
      "  [ 66.  58.  50.]\n",
      "  [ 65.  57.  50.]\n",
      "  [ 66.  58.  50.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  3.   3.   3.]\n",
      "  [  3.   3.   2.]\n",
      "  [  3.   3.   2.]\n",
      "  ...\n",
      "  [136. 127. 114.]\n",
      "  [138. 130. 116.]\n",
      "  [139. 130. 117.]]\n",
      "\n",
      " [[  3.   3.   3.]\n",
      "  [  3.   3.   2.]\n",
      "  [  3.   3.   2.]\n",
      "  ...\n",
      "  [135. 127. 114.]\n",
      "  [136. 128. 115.]\n",
      "  [138. 129. 116.]]\n",
      "\n",
      " [[  3.   3.   2.]\n",
      "  [  3.   3.   2.]\n",
      "  [  4.   3.   3.]\n",
      "  ...\n",
      "  [136. 128. 115.]\n",
      "  [135. 127. 114.]\n",
      "  [137. 128. 115.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0046\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f2b0>\n",
      "[[  5.2866964  12.887324   87.36364   106.245    ]\n",
      " [  4.509082   12.014217   87.08714   107.90502  ]\n",
      " [  4.189048   12.480637   87.83856   106.54491  ]\n",
      " [  5.4601617  11.261129   86.67616   106.17482  ]\n",
      " [  4.2789464  12.328102   88.108826  105.70178  ]\n",
      " [  4.529773   12.590858   86.49049   105.907524 ]\n",
      " [  5.5225663  12.070643   87.15149   106.50585  ]\n",
      " [  4.011477   11.707244   87.324005  106.336685 ]\n",
      " [  3.2235684  12.16901    85.890816  106.28298  ]\n",
      " [  4.6868896  12.421626   86.24617   107.10564  ]\n",
      " [  4.3288674  12.183296   86.11886   106.6988   ]\n",
      " [  5.6722994  12.281813   86.66498   106.84254  ]\n",
      " [  4.357987   12.119089   86.791374  105.980064 ]\n",
      " [  5.059505   10.523846   87.157295  108.003716 ]\n",
      " [  4.032716   11.187635   85.92262   105.75421  ]\n",
      " [  3.93501    11.296714   86.35075   104.510185 ]\n",
      " [  2.964871   11.55755    86.41408   106.76056  ]\n",
      " [  5.05568    12.878796   86.39601   107.40137  ]\n",
      " [  4.7935076  15.834114   86.78856   106.65337  ]\n",
      " [  3.8184085  14.225105   87.31331   105.5964   ]\n",
      " [  5.1553383  14.416815   87.60544   107.29584  ]\n",
      " [  3.9869337  13.492008   86.60481   104.36004  ]\n",
      " [  4.539236   13.335535   86.19332   104.872025 ]\n",
      " [  4.021624   16.295452   86.73631   105.67102  ]\n",
      " [  2.8516173  10.369026   85.019485  108.36403  ]\n",
      " [  1.509851    9.910647   86.02735   107.60948  ]\n",
      " [  5.268515   18.23962    87.39114   105.89584  ]\n",
      " [  4.021664   13.036346   88.523544  105.50141  ]\n",
      " [  6.7260385  14.939611   88.42328   106.19148  ]\n",
      " [  3.6287112   7.2795324  86.80889   107.64888  ]\n",
      " [  3.9155602   7.8243113  88.43604   108.24637  ]\n",
      " [  1.8316607   6.863802   87.26195   107.44415  ]\n",
      " [  5.0202885   6.2182565  89.05247   105.45055  ]\n",
      " [  6.6282425  16.836496   90.56495   104.93627  ]\n",
      " [  3.052977    7.6247706  87.885086  108.54869  ]\n",
      " [  4.577872    5.381248   87.28572   106.13343  ]\n",
      " [  2.533012   10.661559   85.515495  106.42281  ]\n",
      " [  6.765482    3.7809577  89.99763   109.06158  ]\n",
      " [  7.6465936   6.285608   85.37668   105.881805 ]\n",
      " [  9.673336    4.296627   86.686455  106.16702  ]\n",
      " [  5.442007   10.069399   90.50387   106.03104  ]\n",
      " [ 10.39644     9.54893    90.65117   105.14502  ]] (42, 4)\n",
      "\n",
      "[0.9962341  0.9926158  0.99118453 0.98660743 0.98571336 0.98375124\n",
      " 0.98037386 0.9776829  0.9763922  0.97535056 0.9750165  0.9736395\n",
      " 0.9689829  0.9551326  0.9524397  0.95094335 0.9466384  0.9286122\n",
      " 0.83440125 0.8130677  0.80373746 0.8004483  0.7221922  0.69451916\n",
      " 0.6823939  0.583852   0.53319544 0.52015954 0.43026546 0.38996738\n",
      " 0.37210938 0.35430062 0.33480415 0.2668877  0.19825098 0.15113746\n",
      " 0.1494736  0.13249572 0.12817308 0.12100094 0.09488361 0.08378135] (42,)\n",
      "Tensor in gpu\n",
      "test [[[193. 202. 218.]\n",
      "  [194. 202. 218.]\n",
      "  [193. 201. 217.]\n",
      "  ...\n",
      "  [ 91.  74.  62.]\n",
      "  [ 85.  67.  55.]\n",
      "  [ 78.  57.  45.]]\n",
      "\n",
      " [[195. 203. 218.]\n",
      "  [194. 202. 218.]\n",
      "  [194. 202. 218.]\n",
      "  ...\n",
      "  [ 90.  74.  62.]\n",
      "  [ 83.  65.  54.]\n",
      "  [ 76.  56.  45.]]\n",
      "\n",
      " [[195. 203. 218.]\n",
      "  [194. 202. 218.]\n",
      "  [194. 202. 218.]\n",
      "  ...\n",
      "  [ 89.  73.  61.]\n",
      "  [ 81.  63.  51.]\n",
      "  [ 75.  55.  44.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 42.  47.  56.]\n",
      "  [ 43.  48.  59.]\n",
      "  [ 43.  49.  60.]\n",
      "  ...\n",
      "  [ 93.  68.  56.]\n",
      "  [ 94.  69.  58.]\n",
      "  [ 97.  71.  59.]]\n",
      "\n",
      " [[ 43.  48.  57.]\n",
      "  [ 45.  49.  60.]\n",
      "  [ 44.  49.  61.]\n",
      "  ...\n",
      "  [ 91.  67.  56.]\n",
      "  [ 93.  68.  57.]\n",
      "  [ 96.  71.  58.]]\n",
      "\n",
      " [[ 45.  48.  59.]\n",
      "  [ 46.  50.  61.]\n",
      "  [ 44.  48.  59.]\n",
      "  ...\n",
      "  [ 92.  68.  53.]\n",
      "  [ 93.  70.  57.]\n",
      "  [ 93.  70.  57.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f490>\n",
      "[[ 3.74186668e+01  3.10129595e+00  1.06394516e+02  1.05509529e+02]\n",
      " [ 3.79930458e+01  5.24985981e+00  1.05623596e+02  1.07697784e+02]\n",
      " [ 3.74732666e+01  2.02933216e+00  1.07542244e+02  1.07534668e+02]\n",
      " [ 3.72612877e+01  5.50507259e+00  1.05193192e+02  1.05935822e+02]\n",
      " [ 3.67277679e+01  2.26936769e+00  1.05676834e+02  1.04479370e+02]\n",
      " [ 3.78127670e+01  3.99358273e+00  1.07055618e+02  1.06187813e+02]\n",
      " [ 3.58878059e+01  9.22651291e-01  1.06275047e+02  1.05453613e+02]\n",
      " [ 3.69078331e+01  4.65407848e+00  1.05077820e+02  1.06972084e+02]\n",
      " [ 3.72418671e+01  5.53927898e-01  1.03112350e+02  1.08226471e+02]\n",
      " [ 3.84785080e+01  3.79527378e+00  1.07282043e+02  1.08761505e+02]\n",
      " [ 3.69017639e+01  3.71810579e+00  1.06173996e+02  1.06475998e+02]\n",
      " [ 3.62256622e+01  2.96219730e+00  1.05663567e+02  1.05600433e+02]\n",
      " [ 3.75373840e+01  1.90897894e+00  1.05569107e+02  1.07190567e+02]\n",
      " [ 3.76257629e+01  2.53382301e+00  1.04513954e+02  1.04192184e+02]\n",
      " [ 3.58139305e+01  1.97247171e+00  1.06293991e+02  1.05099602e+02]\n",
      " [ 3.80691643e+01  5.38030005e+00  1.05947433e+02  1.06596687e+02]\n",
      " [ 3.79002609e+01  2.20912600e+00  1.04298004e+02  1.12423134e+02]\n",
      " [ 3.86645966e+01  3.95952320e+00  1.08530228e+02  1.08171104e+02]\n",
      " [ 3.58582687e+01  4.92283297e+00  1.06109360e+02  1.05762383e+02]\n",
      " [ 3.72395134e+01  5.34590006e+00  1.03985474e+02  1.03954514e+02]\n",
      " [ 3.93953781e+01  4.08434248e+00  1.07906502e+02  1.04882454e+02]\n",
      " [ 3.76178398e+01  1.03645897e+00  1.05708923e+02  1.05803879e+02]\n",
      " [ 3.55493393e+01  3.13344955e-01  1.01592491e+02  1.11835884e+02]\n",
      " [ 3.63043289e+01  3.18301010e+00  1.07254181e+02  1.07659302e+02]\n",
      " [ 3.70589867e+01  1.10287905e+00  1.07144821e+02  1.03715485e+02]\n",
      " [ 3.89221077e+01  2.68998146e-02  1.06242607e+02  1.10462860e+02]\n",
      " [ 3.58589287e+01  1.88739300e-01  1.08244331e+02  1.06423706e+02]\n",
      " [ 3.46440697e+01 -1.69208479e+00  1.05747864e+02  1.07822746e+02]\n",
      " [ 3.60255623e+01 -1.87765312e+00  1.08870499e+02  1.07118042e+02]\n",
      " [ 3.40483894e+01  4.11067486e-01  1.01240356e+02  1.08593071e+02]\n",
      " [ 3.65493011e+01  4.62259912e+00  1.09964600e+02  1.09857452e+02]\n",
      " [ 3.64581223e+01  1.00684547e+00  1.10621490e+02  1.07380981e+02]\n",
      " [ 3.47473412e+01  3.10971403e+00  1.07726830e+02  1.06650696e+02]\n",
      " [ 3.21995201e+01  5.75437069e-01  1.03951035e+02  1.09313766e+02]\n",
      " [ 4.10527840e+01  1.09858255e+01  1.09886871e+02  1.09425873e+02]\n",
      " [ 3.87800751e+01 -1.39284229e+00  1.07181320e+02  1.10630707e+02]\n",
      " [ 3.48570709e+01  1.13931675e+01  1.01611847e+02  1.08738335e+02]\n",
      " [ 2.91605206e+01  3.00847006e+00  9.49453506e+01  1.00663528e+02]\n",
      " [ 3.64598503e+01 -4.94125462e+00  1.07188599e+02  1.10148552e+02]\n",
      " [ 2.86062222e+01 -4.43586922e+00  1.00704536e+02  1.07323273e+02]\n",
      " [ 2.88971176e+01  5.49900436e+00  1.03551071e+02  1.07869278e+02]] (41, 4)\n",
      "\n",
      "[0.9942199  0.99263954 0.9854285  0.9341475  0.9127862  0.8999463\n",
      " 0.88073474 0.8798596  0.87781197 0.8732045  0.85593396 0.8504344\n",
      " 0.84590816 0.84386253 0.84048957 0.83400005 0.8081813  0.80383945\n",
      " 0.80274826 0.8006638  0.778821   0.74886703 0.7481787  0.7068914\n",
      " 0.6339779  0.6273269  0.21959226 0.20895624 0.20674151 0.17938589\n",
      " 0.12606774 0.11670402 0.07548124 0.07271245 0.0590682  0.054297\n",
      " 0.0478617  0.02991891 0.02882537 0.02488712 0.021027  ] (41,)\n",
      "Tensor in gpu\n",
      "test [[[ 77.  43.  49.]\n",
      "  [ 77.  43.  48.]\n",
      "  [ 77.  43.  48.]\n",
      "  ...\n",
      "  [212. 189. 159.]\n",
      "  [213. 190. 163.]\n",
      "  [212. 188. 159.]]\n",
      "\n",
      " [[ 76.  43.  48.]\n",
      "  [ 76.  43.  48.]\n",
      "  [ 76.  42.  48.]\n",
      "  ...\n",
      "  [212. 187. 157.]\n",
      "  [213. 191. 163.]\n",
      "  [212. 188. 159.]]\n",
      "\n",
      " [[ 76.  43.  48.]\n",
      "  [ 76.  43.  48.]\n",
      "  [ 76.  42.  48.]\n",
      "  ...\n",
      "  [210. 185. 154.]\n",
      "  [213. 190. 161.]\n",
      "  [211. 187. 157.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 55.  38.  23.]\n",
      "  [ 55.  39.  22.]\n",
      "  [ 55.  39.  22.]\n",
      "  ...\n",
      "  [ 65.  46.  28.]\n",
      "  [ 64.  46.  27.]\n",
      "  [ 65.  46.  28.]]\n",
      "\n",
      " [[ 55.  39.  24.]\n",
      "  [ 55.  39.  23.]\n",
      "  [ 55.  39.  22.]\n",
      "  ...\n",
      "  [ 64.  46.  27.]\n",
      "  [ 64.  46.  27.]\n",
      "  [ 65.  46.  27.]]\n",
      "\n",
      " [[ 55.  40.  24.]\n",
      "  [ 56.  40.  24.]\n",
      "  [ 56.  40.  23.]\n",
      "  ...\n",
      "  [ 64.  45.  26.]\n",
      "  [ 65.  46.  27.]\n",
      "  [ 64.  45.  26.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f130>\n",
      "[[  8.21973    20.070583   90.46692   106.43768  ]\n",
      " [  7.9986577  19.675724   91.17275   105.70175  ]\n",
      " [  7.683824   19.57124    90.79353   105.97113  ]\n",
      " [  7.8432837  18.8312     91.0564    105.10786  ]\n",
      " [  8.165932   18.464615   90.332855  104.49725  ]\n",
      " [  8.03285    18.560883   89.3903    104.2685   ]\n",
      " [  6.826144   18.35808    88.99657   104.83775  ]\n",
      " [  8.0812     17.83023    89.79283   104.06004  ]\n",
      " [  8.386997   18.832878   90.417694  107.20849  ]\n",
      " [  6.949131   18.226702   89.618324  105.33696  ]\n",
      " [  8.188972   19.630535   90.29696   106.59841  ]\n",
      " [  7.0966444  18.997284   88.873405  104.69026  ]\n",
      " [  8.83419    20.961689   92.56313   104.593605 ]\n",
      " [  8.792544   21.05608    90.339005  105.63959  ]\n",
      " [  8.455164   19.060417   89.18829   104.4129   ]\n",
      " [  7.516544   17.86835    90.150665  105.201416 ]\n",
      " [  9.208332   22.366907   91.06209   105.02857  ]\n",
      " [  7.9570847  18.775646   89.3013    104.53987  ]\n",
      " [  7.0894747  19.24289    89.33185   105.03672  ]\n",
      " [  6.7620974  18.876595   90.23063   105.35469  ]\n",
      " [  7.9740744  18.634289   88.24873   105.555725 ]\n",
      " [  7.5186067  21.272148   89.96012   106.089645 ]\n",
      " [  7.3418937  22.734612   89.032104  104.95345  ]\n",
      " [  7.817195   19.440773   89.25541   104.43077  ]\n",
      " [  8.458721   20.10605    90.76727   104.66336  ]\n",
      " [  7.801814   18.619465   91.37173   104.75907  ]\n",
      " [  6.6083355  21.5391     87.902725  105.565    ]\n",
      " [  7.6579857  18.118382   87.75784   104.04854  ]\n",
      " [  8.299189   15.396033   89.8936    106.44327  ]\n",
      " [  4.7739377  12.374039   86.8127    107.20232  ]\n",
      " [  7.870237   17.108633   90.284164  105.90496  ]\n",
      " [  8.652565   11.553963   91.72548   109.080025 ]\n",
      " [  5.6092505  11.09491    91.52322   106.797455 ]\n",
      " [  4.2473035  14.739196   86.7755    107.14609  ]\n",
      " [ 12.502309   15.87565    92.29241   105.877365 ]\n",
      " [ 11.876196   26.126192   95.02665   108.46692  ]\n",
      " [  4.277895   10.618277   90.49635   105.58116  ]\n",
      " [  4.2101064   5.8894205  92.12752   108.23508  ]\n",
      " [  7.5550594   9.109327   91.358925  104.7423   ]\n",
      " [  2.1009426   6.354945   85.98483   105.85892  ]\n",
      " [  3.9419327  16.852442   84.72748   102.46623  ]\n",
      " [  4.0697126  26.835007   83.177345  108.84032  ]] (42, 4)\n",
      "\n",
      "[0.9985656  0.9982874  0.99826556 0.9973948  0.9705734  0.96840614\n",
      " 0.96073085 0.9604134  0.95328707 0.95204407 0.94629455 0.93919677\n",
      " 0.92754996 0.9118514  0.90402764 0.90057826 0.89449364 0.890323\n",
      " 0.885772   0.8827167  0.8726826  0.87251574 0.79346615 0.75408506\n",
      " 0.7482942  0.67933905 0.5922173  0.5800291  0.3047971  0.18069774\n",
      " 0.16802135 0.15080808 0.11143152 0.10559822 0.09703872 0.07157799\n",
      " 0.05328536 0.03552309 0.03168678 0.02900703 0.0264344  0.02185928] (42,)\n",
      "Tensor in gpu\n",
      "test [[[160. 112.  57.]\n",
      "  [150. 100.  51.]\n",
      "  [135.  86.  39.]\n",
      "  ...\n",
      "  [ 59.  58.  70.]\n",
      "  [ 52.  51.  64.]\n",
      "  [ 47.  46.  60.]]\n",
      "\n",
      " [[158. 108.  54.]\n",
      "  [147.  96.  46.]\n",
      "  [129.  79.  34.]\n",
      "  ...\n",
      "  [ 60.  58.  71.]\n",
      "  [ 54.  52.  66.]\n",
      "  [ 48.  46.  61.]]\n",
      "\n",
      " [[157. 106.  51.]\n",
      "  [141.  89.  40.]\n",
      "  [122.  73.  29.]\n",
      "  ...\n",
      "  [ 63.  60.  73.]\n",
      "  [ 55.  53.  67.]\n",
      "  [ 49.  48.  62.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[181. 165. 175.]\n",
      "  [183. 167. 176.]\n",
      "  [182. 166. 176.]\n",
      "  ...\n",
      "  [150. 122. 123.]\n",
      "  [150. 121. 121.]\n",
      "  [149. 120. 121.]]\n",
      "\n",
      " [[182. 167. 176.]\n",
      "  [183. 167. 177.]\n",
      "  [184. 169. 178.]\n",
      "  ...\n",
      "  [149. 121. 121.]\n",
      "  [149. 120. 120.]\n",
      "  [150. 121. 121.]]\n",
      "\n",
      " [[180. 165. 174.]\n",
      "  [183. 168. 177.]\n",
      "  [183. 168. 177.]\n",
      "  ...\n",
      "  [151. 122. 122.]\n",
      "  [150. 121. 121.]\n",
      "  [150. 121. 121.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f400>\n",
      "[[  7.160591    7.481523   86.883705  107.274    ]\n",
      " [  6.9166636   6.806671   88.05079   106.81593  ]\n",
      " [  6.204538    7.944638   86.78123   107.5493   ]\n",
      " [  7.4665327   6.5794597  86.70069   104.92641  ]\n",
      " [  7.660469    8.512231   87.02082   108.220375 ]\n",
      " [  6.480075    7.715821   87.05786   105.79059  ]\n",
      " [  7.344978    7.2959914  85.928856  105.87611  ]\n",
      " [  5.8524137   7.7644434  85.26974   106.00532  ]\n",
      " [  7.5087934   8.55546    86.80309   105.90224  ]\n",
      " [  7.688564    7.5432835  87.251205  108.83396  ]\n",
      " [  5.424353    7.15728    84.466965  105.20209  ]\n",
      " [  7.2802067   7.616189   86.037766  106.25822  ]\n",
      " [  6.3901596   8.234327   85.85962   105.10742  ]\n",
      " [  6.937572    7.1611953  86.43803   105.85699  ]\n",
      " [  5.688715    7.7071023  86.30242   105.15724  ]\n",
      " [  6.4956727   7.297547   87.49559   105.55609  ]\n",
      " [  6.090423    8.234959   86.48557   107.26283  ]\n",
      " [  7.2791686   8.372622   85.470116  107.46283  ]\n",
      " [  5.874387    8.849275   85.81364   105.42808  ]\n",
      " [  6.90662     9.118891   87.68723   105.75035  ]\n",
      " [  5.5095987   6.659755   83.96064   107.94401  ]\n",
      " [  6.4312153   9.092255   85.98209   104.63046  ]\n",
      " [  7.0954194   2.9108977  87.29556   108.06264  ]\n",
      " [  6.343169   11.080327   86.05163   106.30644  ]\n",
      " [  3.9068885   6.2505836  84.056854  106.95964  ]\n",
      " [  6.3567576   8.147243   88.63425   108.08738  ]\n",
      " [  6.229298   11.84477    85.5734    106.21883  ]\n",
      " [  8.2806635  13.517579   87.72989   106.60517  ]\n",
      " [  5.841482   12.761711   86.44543   105.70341  ]\n",
      " [  4.415485    3.9604912  84.48596   108.1488   ]\n",
      " [  6.8883386   4.5585356  87.79021   109.22747  ]\n",
      " [  6.34384     4.131767   86.58356   107.76097  ]\n",
      " [ 11.094549    2.6019788  87.29823   111.139435 ]\n",
      " [  9.139404   10.596281   88.077034  105.428154 ]\n",
      " [  8.738113    4.8577046  85.74762   107.94734  ]\n",
      " [  6.2193847   4.8880625  87.24866   109.84432  ]\n",
      " [  8.448294    2.5771785  88.60393   110.11869  ]\n",
      " [  8.311352    5.292144   89.42673   108.57207  ]\n",
      " [  8.910173    3.3833385  86.73317   110.65469  ]\n",
      " [  8.994745   12.4177475  90.72518   105.432785 ]\n",
      " [ 12.039377    7.12292    89.913956  106.88279  ]\n",
      " [  4.6856112   8.332865   83.855415  106.5197   ]] (42, 4)\n",
      "\n",
      "[0.99629563 0.99516296 0.9930902  0.9906983  0.9904987  0.99041826\n",
      " 0.990137   0.98921424 0.98916143 0.9891611  0.98837554 0.98396975\n",
      " 0.9827253  0.9823183  0.97858757 0.97815543 0.97732204 0.97089237\n",
      " 0.7601806  0.75177974 0.7209609  0.7200782  0.6567847  0.6393952\n",
      " 0.583348   0.57496357 0.54686296 0.5430847  0.52867955 0.46987012\n",
      " 0.45164767 0.4379357  0.4241507  0.34885883 0.3453508  0.31420937\n",
      " 0.30575153 0.3016903  0.25396562 0.2492205  0.20256428 0.1913058 ] (42,)\n",
      "Tensor in gpu\n",
      "test [[[164. 175. 123.]\n",
      "  [165. 176. 124.]\n",
      "  [164. 175. 124.]\n",
      "  ...\n",
      "  [155. 180. 164.]\n",
      "  [151. 177. 161.]\n",
      "  [147. 173. 159.]]\n",
      "\n",
      " [[153. 168. 111.]\n",
      "  [154. 168. 112.]\n",
      "  [154. 166. 110.]\n",
      "  ...\n",
      "  [151. 175. 158.]\n",
      "  [147. 171. 156.]\n",
      "  [142. 167. 152.]]\n",
      "\n",
      " [[147. 163. 105.]\n",
      "  [147. 162. 103.]\n",
      "  [152. 161.  99.]\n",
      "  ...\n",
      "  [146. 170. 153.]\n",
      "  [142. 166. 149.]\n",
      "  [137. 161. 145.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[101. 117.  90.]\n",
      "  [104. 120.  93.]\n",
      "  [104. 121.  95.]\n",
      "  ...\n",
      "  [167. 186. 158.]\n",
      "  [165. 184. 155.]\n",
      "  [159. 180. 149.]]\n",
      "\n",
      " [[ 98. 115.  88.]\n",
      "  [101. 117.  90.]\n",
      "  [102. 119.  92.]\n",
      "  ...\n",
      "  [166. 185. 157.]\n",
      "  [164. 184. 155.]\n",
      "  [158. 180. 149.]]\n",
      "\n",
      " [[ 98. 115.  88.]\n",
      "  [100. 117.  90.]\n",
      "  [101. 118.  92.]\n",
      "  ...\n",
      "  [166. 186. 157.]\n",
      "  [164. 184. 155.]\n",
      "  [159. 179. 148.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f640>\n",
      "[[ 10.518208     6.9898562   94.58266    108.00227   ]\n",
      " [ 10.360531     6.2963524   93.88004    106.68153   ]\n",
      " [  9.801216     7.7894807   92.13685    107.39243   ]\n",
      " [  8.30985      6.8590155   91.54378    106.2336    ]\n",
      " [  8.980132     7.79875     92.30119    107.16701   ]\n",
      " [ 10.5246105    7.571465    92.65093    105.69326   ]\n",
      " [ 11.516038     8.371389    93.96699    106.2958    ]\n",
      " [  9.606379     7.196196    93.74157    107.78123   ]\n",
      " [ 10.085872     8.199129    93.53913    108.85191   ]\n",
      " [ 11.129026     8.197885    92.42291    108.59416   ]\n",
      " [  9.101223     5.8807154   93.19315    106.80963   ]\n",
      " [  9.613898     6.4317927   91.94008    106.773834  ]\n",
      " [  9.435005     6.7365394   92.60499    106.45479   ]\n",
      " [  9.5171       8.787722    93.77029    108.268524  ]\n",
      " [ 10.189926     7.1174793   94.14664    106.15802   ]\n",
      " [  9.842528     7.4193354   90.73075    107.15413   ]\n",
      " [ 10.650237     7.750578    93.55651    106.65583   ]\n",
      " [ 10.670715     6.9039564   93.587456   107.778534  ]\n",
      " [  9.417963     4.6058164   92.853745   107.49481   ]\n",
      " [  8.783926     8.314603    93.32795    106.35789   ]\n",
      " [ 10.309355     8.29509     94.30792    105.45308   ]\n",
      " [  9.495571     7.8691354   94.02058    107.75668   ]\n",
      " [ 10.721948     9.360374    93.779      107.04184   ]\n",
      " [  9.125946     5.7628255   93.447464   107.80507   ]\n",
      " [ 10.860516     4.7739043   92.644295   109.94936   ]\n",
      " [  9.750753     4.7179217   93.579605   108.60475   ]\n",
      " [ 10.80451      9.589699    95.423225   107.03468   ]\n",
      " [ 12.73362      8.050071    93.07603    108.44169   ]\n",
      " [  9.03243      3.7281427   92.45773    108.476685  ]\n",
      " [ 11.11667     12.457895    94.09307    107.28801   ]\n",
      " [  9.385712     8.872776    92.774796   105.8676    ]\n",
      " [ 10.455503     5.3343744   90.237755   109.34466   ]\n",
      " [  8.335705     3.9944973   91.342674   108.347084  ]\n",
      " [ 13.168826     2.805882    91.90343    110.9227    ]\n",
      " [  8.387959    12.189394    92.86687    108.54997   ]\n",
      " [  8.955034     2.7809048   92.627625   108.436165  ]\n",
      " [  6.6576457    4.4103446   90.59376    107.68938   ]\n",
      " [  6.1222663   -0.65941095  90.63059    106.97224   ]\n",
      " [  7.813857    15.443578    90.78203    106.18987   ]\n",
      " [  7.98544     13.033854    89.66354    105.32948   ]\n",
      " [ 10.426801     1.574976    90.77022    108.47882   ]\n",
      " [  9.294802     8.212438    98.63749    114.60967   ]\n",
      " [ 11.416967    -1.0874414   96.13854    110.54568   ]\n",
      " [  6.0765576    7.5083995   87.04555    104.19606   ]\n",
      " [ 14.224295    16.518309    97.25118    110.54601   ]\n",
      " [ 15.692816    -2.4969196   98.33269    109.039795  ]] (46, 4)\n",
      "\n",
      "[0.9942498  0.9940942  0.9933466  0.9922058  0.9920736  0.99123585\n",
      " 0.98988146 0.98954344 0.9892236  0.9889129  0.9881456  0.9872492\n",
      " 0.9870187  0.9844611  0.9817415  0.98117644 0.97454333 0.9725998\n",
      " 0.94270295 0.9131727  0.8803893  0.8757449  0.8445906  0.8209764\n",
      " 0.75683624 0.73321366 0.7229478  0.59897107 0.5977894  0.57649034\n",
      " 0.5419855  0.53911084 0.39810476 0.3900935  0.32100928 0.2894164\n",
      " 0.1820843  0.14374824 0.10575914 0.09348934 0.08311351 0.04380418\n",
      " 0.04119287 0.04021343 0.03279921 0.03179864] (46,)\n",
      "Tensor in gpu\n",
      "test [[[ 82.  90.  51.]\n",
      "  [ 80.  88.  50.]\n",
      "  [ 81.  90.  50.]\n",
      "  ...\n",
      "  [ 73.  80.  63.]\n",
      "  [ 74.  80.  65.]\n",
      "  [ 73.  80.  64.]]\n",
      "\n",
      " [[ 84.  91.  52.]\n",
      "  [ 83.  91.  50.]\n",
      "  [ 85.  93.  52.]\n",
      "  ...\n",
      "  [ 76.  83.  63.]\n",
      "  [ 76.  82.  63.]\n",
      "  [ 76.  84.  62.]]\n",
      "\n",
      " [[ 91.  95.  52.]\n",
      "  [ 89.  94.  51.]\n",
      "  [ 88.  95.  49.]\n",
      "  ...\n",
      "  [ 79.  85.  63.]\n",
      "  [ 79.  86.  62.]\n",
      "  [ 79.  86.  61.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 32.  40.  17.]\n",
      "  [ 29.  36.  16.]\n",
      "  [ 24.  30.  14.]\n",
      "  ...\n",
      "  [ 45.  53.  29.]\n",
      "  [ 49.  56.  32.]\n",
      "  [ 53.  57.  35.]]\n",
      "\n",
      " [[ 31.  39.  17.]\n",
      "  [ 31.  38.  17.]\n",
      "  [ 24.  28.  14.]\n",
      "  ...\n",
      "  [ 55.  58.  37.]\n",
      "  [ 49.  53.  33.]\n",
      "  [ 50.  51.  32.]]\n",
      "\n",
      " [[ 32.  38.  17.]\n",
      "  [ 30.  35.  17.]\n",
      "  [ 28.  30.  18.]\n",
      "  ...\n",
      "  [124. 106.  87.]\n",
      "  [ 98.  85.  67.]\n",
      "  [ 64.  59.  40.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f2e0>\n",
      "[[ 20.048082     9.704368    91.852005   107.81529   ]\n",
      " [ 19.680191     9.425352    92.171616   107.21507   ]\n",
      " [ 19.797867    11.134264    92.35298    109.11713   ]\n",
      " [ 19.241241    10.969009    91.269554   108.289185  ]\n",
      " [ 20.0896      10.25967     91.82068    107.69156   ]\n",
      " [ 19.885382     9.95908     91.5442     108.56091   ]\n",
      " [ 20.93344     10.145072    92.422905   107.0445    ]\n",
      " [ 19.986809     8.326185    91.234055   105.96515   ]\n",
      " [ 19.346203     9.03737     90.63319    106.66126   ]\n",
      " [ 19.112328    10.316605    89.97722    106.86159   ]\n",
      " [ 19.205927     9.218682    90.567184   107.800575  ]\n",
      " [ 18.835024     8.77203     90.60828    106.09079   ]\n",
      " [ 18.447105     8.916466    91.6275     108.14756   ]\n",
      " [ 20.021973     9.731255    91.57584    108.532166  ]\n",
      " [ 20.657928    12.887735    91.219315   107.19804   ]\n",
      " [ 18.853786     9.06677     90.56282    107.88043   ]\n",
      " [ 18.401165     8.409111    92.732124   107.763504  ]\n",
      " [ 20.357693     9.677351    90.82785    107.09543   ]\n",
      " [ 19.040396     8.078072    92.917564   108.53156   ]\n",
      " [ 18.622375     7.2039733   90.766525   108.34443   ]\n",
      " [ 20.315662     8.673623    91.685036   109.29594   ]\n",
      " [ 19.446045     8.125998    92.20746    108.46242   ]\n",
      " [ 19.431477     8.176716    91.83386    107.47489   ]\n",
      " [ 19.188683     8.205885    91.07161    109.045715  ]\n",
      " [ 19.981228     5.861456    91.11799    110.212685  ]\n",
      " [ 20.338081     5.786918    91.67342    111.992096  ]\n",
      " [ 20.323175    11.968745    92.36094    108.934074  ]\n",
      " [ 20.355492     9.615133    92.03968    106.27633   ]\n",
      " [ 19.269075    10.355387    92.5848     106.99933   ]\n",
      " [ 17.216806     3.840829    92.97717    110.2175    ]\n",
      " [ 18.429611    14.943876    88.35834    108.694824  ]\n",
      " [ 16.696022     3.5795078   90.89657    109.02724   ]\n",
      " [ 22.756292    16.217175    93.68715    110.24132   ]\n",
      " [ 16.780668     3.0298057   92.94255    108.96539   ]\n",
      " [ 21.596306    13.099679    96.76231    113.8499    ]\n",
      " [ 16.414696    10.32741     89.77525    107.70503   ]\n",
      " [ 10.703899     1.0349436   87.67909    112.11135   ]\n",
      " [ 23.324398    -0.25946188  94.4868     107.51182   ]\n",
      " [ 17.38127      1.0100532   89.17751    107.98716   ]\n",
      " [ 16.886528    -1.2523317   94.55264    112.81182   ]\n",
      " [ 23.04553     -3.1841083   97.89479    108.339584  ]\n",
      " [ 18.852287    -2.1035028   93.26633    112.6443    ]] (42, 4)\n",
      "\n",
      "[0.998095   0.99576426 0.9956722  0.98574847 0.9780487  0.9728368\n",
      " 0.95928097 0.9571891  0.95514286 0.95449173 0.94940174 0.9475485\n",
      " 0.9217639  0.9184544  0.91809183 0.91107845 0.90880746 0.908749\n",
      " 0.9023428  0.90201825 0.90079546 0.83087486 0.80863607 0.7607108\n",
      " 0.67074573 0.5305519  0.4371203  0.31716704 0.30192888 0.22101736\n",
      " 0.19181043 0.15893368 0.1453437  0.11189634 0.06112021 0.04756078\n",
      " 0.03180862 0.02899981 0.02472124 0.02464818 0.02331404 0.02297461] (42,)\n",
      "Tensor in gpu\n",
      "test [[[148. 121.  69.]\n",
      "  [147. 120.  70.]\n",
      "  [148. 119.  70.]\n",
      "  ...\n",
      "  [104.  79.  45.]\n",
      "  [105.  80.  47.]\n",
      "  [106.  82.  48.]]\n",
      "\n",
      " [[145. 119.  68.]\n",
      "  [145. 118.  68.]\n",
      "  [145. 117.  68.]\n",
      "  ...\n",
      "  [101.  77.  44.]\n",
      "  [106.  80.  47.]\n",
      "  [108.  84.  50.]]\n",
      "\n",
      " [[146. 120.  69.]\n",
      "  [146. 120.  69.]\n",
      "  [145. 119.  69.]\n",
      "  ...\n",
      "  [100.  76.  43.]\n",
      "  [103.  78.  43.]\n",
      "  [107.  83.  48.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 17.  16.  14.]\n",
      "  [ 17.  16.  14.]\n",
      "  [ 17.  16.  14.]\n",
      "  ...\n",
      "  [  5.   6.   6.]\n",
      "  [  5.   6.   6.]\n",
      "  [  5.   6.   6.]]\n",
      "\n",
      " [[ 17.  17.  14.]\n",
      "  [ 17.  16.  14.]\n",
      "  [ 17.  16.  14.]\n",
      "  ...\n",
      "  [  5.   6.   6.]\n",
      "  [  5.   6.   6.]\n",
      "  [  6.   7.   7.]]\n",
      "\n",
      " [[ 18.  16.  13.]\n",
      "  [ 18.  17.  14.]\n",
      "  [ 18.  17.  14.]\n",
      "  ...\n",
      "  [  6.   6.   6.]\n",
      "  [  7.   7.   7.]\n",
      "  [  6.   7.   7.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7fa90>\n",
      "[[ 21.300514    6.9474087 100.45492   106.80664  ]\n",
      " [ 20.623209    6.4580216 100.30453   106.321915 ]\n",
      " [ 20.701208    7.8226223  99.47875   109.28161  ]\n",
      " [ 19.680464    7.6866913  99.915344  105.87473  ]\n",
      " [ 21.201246    6.984716   98.922195  105.054955 ]\n",
      " [ 21.315582    7.340525  100.91573   105.87268  ]\n",
      " [ 19.29459     6.8490586  99.275276  106.05077  ]\n",
      " [ 20.11492     6.826962  100.09509   104.37896  ]\n",
      " [ 20.169527    6.2382836  99.06422   104.7408   ]\n",
      " [ 20.086994    7.800125   98.31622   104.07499  ]\n",
      " [ 20.221024    7.750291   99.5436    108.59005  ]\n",
      " [ 20.268124    6.308926   99.26686   107.28897  ]\n",
      " [ 20.119009    6.4643435  98.57208   107.19307  ]\n",
      " [ 19.572847    6.342692   98.46833   106.77118  ]\n",
      " [ 20.081585    6.608913   99.03475   105.1595   ]\n",
      " [ 21.057552    7.1940866 100.49527   105.54465  ]\n",
      " [ 19.811996    5.974656   97.97973   107.5285   ]\n",
      " [ 19.346807    5.815417  100.76482   105.85499  ]\n",
      " [ 20.15726     9.962431   99.30887   105.39301  ]\n",
      " [ 20.37106     6.191557   98.06823   104.25615  ]\n",
      " [ 20.339918   10.105394   99.596016  105.89131  ]\n",
      " [ 20.358828    9.5561    100.72061   106.56175  ]\n",
      " [ 19.5299      3.9730616  97.20108   106.389305 ]\n",
      " [ 19.939669    7.5122814 100.59878   104.71152  ]\n",
      " [ 20.079975    6.9601693  99.91478   105.09883  ]\n",
      " [ 19.219212    5.6837783  98.82663   107.190544 ]\n",
      " [ 20.781904   11.622736   99.26965   105.613754 ]\n",
      " [ 19.54168     5.279907   98.84794   102.90898  ]\n",
      " [ 19.161453    3.4159293  99.783394  107.20384  ]\n",
      " [ 21.158438    3.800888   97.39733   109.781044 ]\n",
      " [ 18.284817    4.6936054  97.89553   107.82491  ]\n",
      " [ 19.536552    3.3986092  99.173294  107.54261  ]\n",
      " [ 21.905468   13.285328  101.277565  106.54909  ]\n",
      " [ 20.590332    8.742603  102.639565  109.97926  ]\n",
      " [ 16.343384    1.0837498  98.65105   108.95569  ]\n",
      " [ 20.150581   -0.1408577  98.46208   107.55532  ]\n",
      " [ 21.43472     1.1931114  99.85245   110.11823  ]\n",
      " [ 16.75808    -2.3185444  99.385     110.00216  ]\n",
      " [ 20.371567    3.9605913 101.810745  111.28816  ]\n",
      " [ 16.594566   -5.3303223  96.88149   109.06505  ]\n",
      " [ 21.43694    13.311887  103.083145  105.71506  ]\n",
      " [ 22.29488    15.18239   106.10828   106.55989  ]] (42, 4)\n",
      "\n",
      "[0.9973195  0.99363434 0.993476   0.9931625  0.9888466  0.9884334\n",
      " 0.9884089  0.9872248  0.9848381  0.9841689  0.9827915  0.98172975\n",
      " 0.98144525 0.9808772  0.9804734  0.97948176 0.9783917  0.97472906\n",
      " 0.92609966 0.86168694 0.8089113  0.7693966  0.74027455 0.72368604\n",
      " 0.7010786  0.6907146  0.6857584  0.6134549  0.6082259  0.5805374\n",
      " 0.56252617 0.4792831  0.4004062  0.34272614 0.23785079 0.19643188\n",
      " 0.13853732 0.06012479 0.05414862 0.03516665 0.03358844 0.0283219 ] (42,)\n",
      "Tensor in gpu\n",
      "test [[[106.  79.  37.]\n",
      "  [107.  80.  38.]\n",
      "  [108.  80.  38.]\n",
      "  ...\n",
      "  [120.  94.  50.]\n",
      "  [121.  94.  51.]\n",
      "  [122.  94.  51.]]\n",
      "\n",
      " [[108.  81.  39.]\n",
      "  [109.  83.  41.]\n",
      "  [110.  82.  40.]\n",
      "  ...\n",
      "  [117.  91.  49.]\n",
      "  [118.  91.  49.]\n",
      "  [120.  92.  49.]]\n",
      "\n",
      " [[109.  82.  41.]\n",
      "  [110.  84.  43.]\n",
      "  [110.  84.  42.]\n",
      "  ...\n",
      "  [115.  88.  48.]\n",
      "  [115.  88.  47.]\n",
      "  [117.  90.  48.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[146. 128.  89.]\n",
      "  [138. 117.  72.]\n",
      "  [137. 115.  69.]\n",
      "  ...\n",
      "  [166. 143.  95.]\n",
      "  [165. 142.  94.]\n",
      "  [164. 140.  92.]]\n",
      "\n",
      " [[145. 126.  86.]\n",
      "  [138. 116.  72.]\n",
      "  [137. 114.  68.]\n",
      "  ...\n",
      "  [166. 143.  95.]\n",
      "  [165. 142.  94.]\n",
      "  [164. 141.  92.]]\n",
      "\n",
      " [[145. 126.  86.]\n",
      "  [138. 116.  71.]\n",
      "  [136. 113.  67.]\n",
      "  ...\n",
      "  [166. 143.  94.]\n",
      "  [165. 141.  93.]\n",
      "  [164. 141.  93.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f1f0>\n",
      "[[ 11.698212   12.738623   92.74592   108.10282  ]\n",
      " [ 11.365801   13.107096   92.21229   109.399    ]\n",
      " [ 11.387637   11.91851    92.31174   108.241165 ]\n",
      " [ 10.998253   12.630253   92.35581   109.09198  ]\n",
      " [ 12.399807   13.322187   90.75894   108.79039  ]\n",
      " [ 11.491244   12.871009   90.8778    107.75764  ]\n",
      " [ 11.511879   11.647259   92.05341   107.16384  ]\n",
      " [ 10.54459    12.22603    90.26857   107.82438  ]\n",
      " [ 11.772299   11.725569   90.62039   106.59943  ]\n",
      " [ 10.229597   12.181414   90.01098   106.078125 ]\n",
      " [ 12.0977335  13.9438505  91.818474  108.156715 ]\n",
      " [ 11.890633   12.837601   91.21363   108.83608  ]\n",
      " [ 11.26125    12.246282   91.685265  107.62028  ]\n",
      " [ 11.091369   11.884658   90.34354   106.08747  ]\n",
      " [ 11.231005   12.609521   90.177956  107.550934 ]\n",
      " [ 10.525452   12.535227   90.63218   107.97221  ]\n",
      " [ 11.312859   13.504081   89.403114  107.324615 ]\n",
      " [ 11.659606   13.94359    92.135216  106.84859  ]\n",
      " [ 11.1377945  12.94281    91.01374   108.89285  ]\n",
      " [ 11.010475   12.6894455  91.58132   107.38966  ]\n",
      " [ 12.113068   13.921113   93.522705  106.82958  ]\n",
      " [ 12.782856   15.814371   92.152176  107.70244  ]\n",
      " [ 11.218087   12.4741745  92.9146    106.89211  ]\n",
      " [ 11.523819   12.504709   92.75967   106.83394  ]\n",
      " [ 11.413092    9.381821   90.76488   107.46514  ]\n",
      " [ 10.592529   15.106634   91.18359   109.20435  ]\n",
      " [ 11.171304   11.377904   92.31669   107.69445  ]\n",
      " [ 10.743086   12.770846   90.77771   107.12835  ]\n",
      " [ 14.957892   11.160439   92.280426  107.5916   ]\n",
      " [ 13.109215    8.155694   91.54109   110.89237  ]\n",
      " [ 11.422861    7.564232   93.013275  108.71739  ]\n",
      " [  8.422686    7.777271   89.877594  110.60604  ]\n",
      " [ 14.694057    5.824863   90.04817   109.646904 ]\n",
      " [  9.059603   18.183697   90.15911   108.03776  ]\n",
      " [  9.61271     6.615228   91.820526  108.644875 ]\n",
      " [  9.346533   16.532541   88.91458   107.57433  ]\n",
      " [ 11.324285    6.23073    89.92083   107.73297  ]\n",
      " [  7.096017    8.62682    89.70237   110.37972  ]\n",
      " [  8.229875    3.8888073  91.666405  109.00578  ]\n",
      " [ 14.79191    19.67049    95.72888   110.42983  ]\n",
      " [ 13.295568   14.198927   97.54271   113.99947  ]\n",
      " [ 11.874575    4.7468343  88.2321    107.35844  ]\n",
      " [  4.9124055   2.555419   86.91035   109.6778   ]] (43, 4)\n",
      "\n",
      "[0.99630654 0.99437654 0.9930276  0.98986804 0.98557925 0.984999\n",
      " 0.9831697  0.9795609  0.97798663 0.9746609  0.9746527  0.9622178\n",
      " 0.9616884  0.96073693 0.9557958  0.9507112  0.93879676 0.908851\n",
      " 0.8978685  0.8392748  0.8322056  0.7996287  0.79767996 0.78928703\n",
      " 0.7828977  0.65960413 0.6033547  0.5639835  0.4678165  0.39841995\n",
      " 0.24654964 0.23789501 0.18981566 0.17766349 0.17170604 0.13426511\n",
      " 0.13375953 0.12902233 0.05416897 0.04881685 0.0417243  0.03262842\n",
      " 0.02933959] (43,)\n",
      "Tensor in gpu\n",
      "test [[[121. 151. 141.]\n",
      "  [122. 151. 141.]\n",
      "  [122. 151. 141.]\n",
      "  ...\n",
      "  [161. 134.  74.]\n",
      "  [162. 136.  75.]\n",
      "  [163. 137.  76.]]\n",
      "\n",
      " [[122. 151. 141.]\n",
      "  [122. 151. 141.]\n",
      "  [123. 151. 141.]\n",
      "  ...\n",
      "  [163. 137.  75.]\n",
      "  [162. 136.  75.]\n",
      "  [161. 135.  74.]]\n",
      "\n",
      " [[123. 152. 142.]\n",
      "  [123. 152. 142.]\n",
      "  [123. 152. 142.]\n",
      "  ...\n",
      "  [160. 135.  73.]\n",
      "  [158. 132.  72.]\n",
      "  [156. 131.  71.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[106. 129. 105.]\n",
      "  [104. 127. 103.]\n",
      "  [103. 126. 102.]\n",
      "  ...\n",
      "  [100.  43.  33.]\n",
      "  [105.  48.  36.]\n",
      "  [113.  54.  40.]]\n",
      "\n",
      " [[106. 129. 104.]\n",
      "  [106. 129. 104.]\n",
      "  [104. 127. 103.]\n",
      "  ...\n",
      "  [100.  44.  33.]\n",
      "  [103.  46.  35.]\n",
      "  [107.  50.  37.]]\n",
      "\n",
      " [[107. 130. 103.]\n",
      "  [106. 129. 103.]\n",
      "  [105. 129. 102.]\n",
      "  ...\n",
      "  [102.  45.  34.]\n",
      "  [103.  45.  35.]\n",
      "  [104.  47.  36.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f2b0>\n",
      "[[ 26.593737   15.805308  103.50166   104.9973   ]\n",
      " [ 27.299833   15.874952  104.058     104.62931  ]\n",
      " [ 26.562307   14.885321  103.83182   104.970184 ]\n",
      " [ 26.556225   14.091581  104.51462   105.121216 ]\n",
      " [ 26.994587   15.443678  103.51388   107.0976   ]\n",
      " [ 28.215723   15.6105    103.69751   106.67854  ]\n",
      " [ 25.899933   13.881643  103.19114   104.24089  ]\n",
      " [ 25.194532   12.609278  101.75226   106.27362  ]\n",
      " [ 26.33334    14.162868  102.49876   104.619705 ]\n",
      " [ 25.612072   13.627141  102.45448   104.788704 ]\n",
      " [ 26.393301   13.404161  102.31027   103.21351  ]\n",
      " [ 27.568499   17.752075  103.29673   105.591385 ]\n",
      " [ 26.040443   12.267681  104.94728   104.501656 ]\n",
      " [ 25.495903   13.801544  102.30613   104.37127  ]\n",
      " [ 26.511751   13.8679905 103.34438   104.99416  ]\n",
      " [ 26.829353   13.59243   102.07747   102.24433  ]\n",
      " [ 26.13919    13.5977545 102.87725   105.02993  ]\n",
      " [ 26.923777   13.88451   103.16192   104.22955  ]\n",
      " [ 27.131071   14.144392  103.91793   105.6907   ]\n",
      " [ 26.010876   17.00406   102.96763   106.063805 ]\n",
      " [ 26.445889   18.012365  106.186745  105.2046   ]\n",
      " [ 26.1482     15.130957  104.08591   105.70063  ]\n",
      " [ 26.179184   17.438597  104.90288   105.025246 ]\n",
      " [ 25.069298   12.591563  104.33593   104.34436  ]\n",
      " [ 25.365236   19.158262  102.02738   106.075836 ]\n",
      " [ 26.617044   15.749045  104.3544    108.10092  ]\n",
      " [ 24.564648   13.944545  103.60937   105.181015 ]\n",
      " [ 25.673428   17.640102  101.00124   104.39767  ]\n",
      " [ 25.237354    9.197487  101.06455   108.76913  ]\n",
      " [ 27.196102    9.9183445 104.50202   108.610214 ]\n",
      " [ 28.70834     7.117189  103.15951   107.980255 ]\n",
      " [ 24.739868    7.8617554 103.21777   104.29442  ]\n",
      " [ 25.033398    7.6390133 106.3346    106.18805  ]\n",
      " [ 23.888067    5.0738177 101.73671   108.206406 ]\n",
      " [ 24.496845    3.186635  102.56187   106.61828  ]\n",
      " [ 27.48094     6.4233246  99.64044   105.46025  ]\n",
      " [ 24.306534    8.098436  104.952324  106.79634  ]\n",
      " [ 28.603241   11.688485  107.237274  106.30962  ]\n",
      " [ 24.410545   11.432434   99.24342   103.60689  ]\n",
      " [ 23.151157    5.1606355 102.7655    107.15017  ]\n",
      " [ 21.225069    5.371518   99.395386  107.72633  ]\n",
      " [ 26.152046    6.9148746 104.50506   103.56043  ]] (42, 4)\n",
      "\n",
      "[0.99725276 0.99445134 0.9942327  0.9922936  0.9822875  0.9646085\n",
      " 0.92594266 0.9250071  0.92025685 0.9178186  0.91313285 0.90770054\n",
      " 0.90407753 0.9025458  0.894338   0.88108534 0.8780156  0.84863967\n",
      " 0.8419701  0.69331235 0.5920878  0.5872073  0.57385653 0.5458152\n",
      " 0.4856397  0.43932766 0.43622994 0.41378912 0.39715305 0.2164462\n",
      " 0.13474305 0.12151791 0.09139089 0.09101252 0.08651593 0.08267071\n",
      " 0.07969519 0.06504973 0.06442853 0.04808148 0.03115368 0.02956782] (42,)\n",
      "Tensor in gpu\n",
      "test [[[165. 163. 161.]\n",
      "  [165. 163. 161.]\n",
      "  [166. 164. 161.]\n",
      "  ...\n",
      "  [143. 143. 144.]\n",
      "  [141. 141. 142.]\n",
      "  [141. 141. 140.]]\n",
      "\n",
      " [[166. 163. 161.]\n",
      "  [165. 163. 161.]\n",
      "  [165. 163. 161.]\n",
      "  ...\n",
      "  [148. 147. 146.]\n",
      "  [147. 146. 146.]\n",
      "  [146. 145. 144.]]\n",
      "\n",
      " [[168. 165. 162.]\n",
      "  [168. 165. 162.]\n",
      "  [165. 163. 160.]\n",
      "  ...\n",
      "  [148. 148. 145.]\n",
      "  [147. 146. 145.]\n",
      "  [148. 147. 147.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  7.   7.   8.]\n",
      "  [  6.   7.   8.]\n",
      "  [  6.   7.   8.]\n",
      "  ...\n",
      "  [  6.   7.   9.]\n",
      "  [  6.   6.   8.]\n",
      "  [  6.   6.   8.]]\n",
      "\n",
      " [[  6.   6.   8.]\n",
      "  [  7.   7.   8.]\n",
      "  [  6.   7.   8.]\n",
      "  ...\n",
      "  [  6.   6.   8.]\n",
      "  [  6.   6.   8.]\n",
      "  [  6.   6.   8.]]\n",
      "\n",
      " [[  6.   6.   8.]\n",
      "  [  6.   6.   7.]\n",
      "  [  6.   7.   8.]\n",
      "  ...\n",
      "  [  6.   6.   8.]\n",
      "  [  5.   6.   7.]\n",
      "  [  6.   6.   8.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f490>\n",
      "[[ 20.803413   16.102167   96.07283   107.60281  ]\n",
      " [ 20.25465    15.253013   96.176414  107.18139  ]\n",
      " [ 20.063446   16.37178    96.83942   106.554245 ]\n",
      " [ 20.78433    16.554838   97.42409   106.47005  ]\n",
      " [ 20.358566   16.694174   96.25833   108.488235 ]\n",
      " [ 20.504065   17.52       96.239174  107.57556  ]\n",
      " [ 20.933853   17.106716   96.05499   107.68382  ]\n",
      " [ 19.123652   15.226443   96.733925  107.20924  ]\n",
      " [ 19.541658   14.7129     95.572136  107.411446 ]\n",
      " [ 18.905369   13.828748   95.49805   107.23344  ]\n",
      " [ 20.096478   15.154105   95.68689   106.376724 ]\n",
      " [ 20.716879   18.831522   95.69299   106.22089  ]\n",
      " [ 19.544466   15.109064   95.29596   107.52141  ]\n",
      " [ 19.831104   15.257269   97.14504   107.66039  ]\n",
      " [ 19.3556     14.855914   95.13111   107.56008  ]\n",
      " [ 18.941788   14.41325    96.02599   107.666565 ]\n",
      " [ 19.94542    14.42251    96.273926  107.30622  ]\n",
      " [ 20.021183   13.633269   96.03502   108.84748  ]\n",
      " [ 19.249844   15.399748   97.66612   106.870445 ]\n",
      " [ 19.205069   14.021069   96.6321    108.690926 ]\n",
      " [ 19.853476   12.201931   95.68897   108.07628  ]\n",
      " [ 19.281233   17.275486   97.205376  107.3216   ]\n",
      " [ 19.888527   15.316278   93.96022   107.8074   ]\n",
      " [ 20.26252    14.856021   97.05251   106.93475  ]\n",
      " [ 21.314373   21.024002   97.845055  107.67926  ]\n",
      " [ 19.303757   15.062835   97.701195  106.16077  ]\n",
      " [ 18.476133   13.765642   95.166534  107.93526  ]\n",
      " [ 18.82288    11.714334   96.566864  108.565    ]\n",
      " [ 17.268059   12.301884   94.2442    110.14426  ]\n",
      " [ 20.114737   16.999214   99.62277   109.99469  ]\n",
      " [ 16.023975    7.0536327  97.44291   109.60643  ]\n",
      " [ 19.296463   22.380663   92.97801   109.34771  ]\n",
      " [ 21.777287    7.655489   94.21842   106.94122  ]\n",
      " [ 16.973099    7.8574295  98.548546  109.1121   ]\n",
      " [ 16.53174     7.971464   95.94684   109.76426  ]\n",
      " [ 22.542849   23.52893   101.61223   106.36969  ]\n",
      " [ 15.839331   16.26655    93.158714  109.48761  ]\n",
      " [ 23.16167    19.770262   99.63852   106.54036  ]\n",
      " [ 18.188622    4.4693613  98.44281   110.05446  ]] (39, 4)\n",
      "\n",
      "[0.9984591  0.99762124 0.99353653 0.9908997  0.9838545  0.9780316\n",
      " 0.97380835 0.9606014  0.95122504 0.9419923  0.9396456  0.9380172\n",
      " 0.93689924 0.9324505  0.89373326 0.88652724 0.8853686  0.8642105\n",
      " 0.85742086 0.83585775 0.6838387  0.67473435 0.6201853  0.556201\n",
      " 0.54279304 0.5227554  0.49533924 0.45428884 0.34300196 0.2950129\n",
      " 0.16287614 0.13500088 0.12025534 0.09296945 0.08628874 0.04439897\n",
      " 0.02737258 0.02585443 0.0233862 ] (39,)\n",
      "Tensor in gpu\n",
      "test [[[ 85.  79.  60.]\n",
      "  [ 94.  86.  64.]\n",
      "  [ 86.  78.  58.]\n",
      "  ...\n",
      "  [ 79.  75.  57.]\n",
      "  [ 70.  66.  53.]\n",
      "  [ 54.  52.  46.]]\n",
      "\n",
      " [[ 73.  69.  55.]\n",
      "  [ 78.  73.  58.]\n",
      "  [ 68.  64.  52.]\n",
      "  ...\n",
      "  [ 80.  75.  57.]\n",
      "  [ 75.  70.  54.]\n",
      "  [ 61.  58.  49.]]\n",
      "\n",
      " [[ 62.  59.  51.]\n",
      "  [ 66.  63.  54.]\n",
      "  [ 58.  57.  50.]\n",
      "  ...\n",
      "  [ 80.  75.  56.]\n",
      "  [ 76.  72.  54.]\n",
      "  [ 66.  63.  51.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 38.  41.  38.]\n",
      "  [ 39.  42.  38.]\n",
      "  [ 39.  42.  39.]\n",
      "  ...\n",
      "  [ 87.  83.  64.]\n",
      "  [ 82.  77.  56.]\n",
      "  [ 80.  75.  52.]]\n",
      "\n",
      " [[ 40.  43.  39.]\n",
      "  [ 41.  44.  39.]\n",
      "  [ 40.  43.  39.]\n",
      "  ...\n",
      "  [100. 100.  95.]\n",
      "  [ 94.  92.  81.]\n",
      "  [ 88.  84.  69.]]\n",
      "\n",
      " [[ 43.  46.  41.]\n",
      "  [ 45.  47.  41.]\n",
      "  [ 44.  46.  41.]\n",
      "  ...\n",
      "  [110. 114. 123.]\n",
      "  [109. 112. 116.]\n",
      "  [105. 105. 105.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f130>\n",
      "[[ 14.5654335   10.114607    98.57068    107.518135  ]\n",
      " [ 14.000921     9.367828    97.39304    106.32357   ]\n",
      " [ 13.964305    10.240588    97.67935    107.67056   ]\n",
      " [ 13.367549     9.600834    96.70583    106.67569   ]\n",
      " [ 14.301239    11.509129    96.43311    106.05045   ]\n",
      " [ 13.697109     9.574692    96.321045   106.4677    ]\n",
      " [ 14.791854    11.359249    97.34401    109.17282   ]\n",
      " [ 13.645369    10.550051    96.51074    106.35572   ]\n",
      " [ 13.997099    12.383158    98.17174    108.344345  ]\n",
      " [ 13.077639     9.992605    96.57384    107.69295   ]\n",
      " [ 14.311306     9.527761    97.59729    107.245964  ]\n",
      " [ 14.166416    10.549017    96.10486    107.586136  ]\n",
      " [ 13.2925205   10.833299    97.3685     106.94722   ]\n",
      " [ 14.034483    10.888683    97.72393    107.49699   ]\n",
      " [ 13.361407    12.411506    98.13774    107.72506   ]\n",
      " [ 13.323072    11.575148    96.6086     107.204124  ]\n",
      " [ 14.135481     9.619095    97.49131    106.34727   ]\n",
      " [ 14.910585    11.246946    98.692474   106.66164   ]\n",
      " [ 12.84956     10.865118    97.35874    106.62037   ]\n",
      " [ 14.034714     9.418564    98.020584   106.207184  ]\n",
      " [ 14.19462      8.431021    96.282524   108.62928   ]\n",
      " [ 14.633466     9.150897    97.84617    109.110916  ]\n",
      " [ 12.43442     10.466906    97.00871    108.069046  ]\n",
      " [ 13.614481    10.897192    96.978294   106.53467   ]\n",
      " [ 13.587093     9.461378    98.46595    108.60613   ]\n",
      " [ 14.063055    12.134373    97.618324   106.95123   ]\n",
      " [ 14.250326    11.692277    97.399      105.92585   ]\n",
      " [ 14.666273    14.835777    96.56367    106.564865  ]\n",
      " [ 13.072696     7.140871    98.38681    107.81411   ]\n",
      " [ 12.187909     7.914714    95.438705   108.43297   ]\n",
      " [ 12.201143     7.202441    97.54879    108.5427    ]\n",
      " [ 15.699144     4.6195517   96.769264   108.66786   ]\n",
      " [ 15.291325    11.082794   101.60409    110.76387   ]\n",
      " [ 12.517353    12.252995    94.91425    106.941376  ]\n",
      " [ 11.976796    16.591078    94.941986   109.22554   ]\n",
      " [ 16.413921    17.794044    99.2032     108.07511   ]\n",
      " [ 12.541402     1.5639477   98.92701    108.82651   ]\n",
      " [  8.56561      2.4386606   95.58804    109.37211   ]\n",
      " [ 10.072921     1.5216503   98.95772    108.48973   ]\n",
      " [ 15.58773      0.98699856 100.04277    107.18948   ]\n",
      " [ 10.179428    21.59706     91.305855   107.12998   ]\n",
      " [ 17.836674     1.5203519   99.57034    105.70317   ]] (42, 4)\n",
      "\n",
      "[0.9960312  0.99200726 0.9918759  0.99039954 0.9897932  0.98722374\n",
      " 0.98719054 0.98709273 0.98687696 0.9849028  0.98244286 0.981248\n",
      " 0.9791268  0.9772602  0.9762713  0.97460157 0.9655744  0.958991\n",
      " 0.9496843  0.92994946 0.910848   0.90238285 0.8913424  0.88854456\n",
      " 0.8817279  0.8696863  0.8661553  0.6823572  0.63468665 0.5569847\n",
      " 0.5332498  0.23996669 0.18035297 0.16965903 0.15349424 0.12509747\n",
      " 0.06963943 0.06171238 0.0551569  0.0527824  0.02638742 0.02255681] (42,)\n",
      "Tensor in gpu\n",
      "test [[[102.  91.  72.]\n",
      "  [102.  91.  72.]\n",
      "  [102.  92.  72.]\n",
      "  ...\n",
      "  [164. 146. 105.]\n",
      "  [187. 173. 133.]\n",
      "  [188. 175. 136.]]\n",
      "\n",
      " [[102.  91.  72.]\n",
      "  [102.  91.  72.]\n",
      "  [102.  91.  72.]\n",
      "  ...\n",
      "  [154. 135.  93.]\n",
      "  [182. 169. 129.]\n",
      "  [198. 189. 154.]]\n",
      "\n",
      " [[102.  92.  73.]\n",
      "  [102.  92.  72.]\n",
      "  [102.  92.  72.]\n",
      "  ...\n",
      "  [146. 123.  80.]\n",
      "  [173. 158. 116.]\n",
      "  [199. 191. 157.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[102.  94.  79.]\n",
      "  [103.  94.  79.]\n",
      "  [102.  94.  79.]\n",
      "  ...\n",
      "  [ 99.  96.  85.]\n",
      "  [100.  97.  86.]\n",
      "  [100.  97.  85.]]\n",
      "\n",
      " [[102.  94.  80.]\n",
      "  [102.  94.  80.]\n",
      "  [102.  94.  79.]\n",
      "  ...\n",
      "  [ 98.  95.  83.]\n",
      "  [ 98.  95.  83.]\n",
      "  [ 98.  95.  84.]]\n",
      "\n",
      " [[102.  95.  80.]\n",
      "  [102.  94.  80.]\n",
      "  [102.  94.  79.]\n",
      "  ...\n",
      "  [ 97.  94.  82.]\n",
      "  [ 97.  93.  82.]\n",
      "  [ 97.  94.  83.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f400>\n",
      "[[ 23.285366     9.686033   101.2431     104.96888   ]\n",
      " [ 23.326952    10.937616   100.203125   107.55452   ]\n",
      " [ 22.736212     9.22471    100.81029    105.330185  ]\n",
      " [ 22.076584     8.057425   101.72539    106.03507   ]\n",
      " [ 23.271097     9.42852    102.000916   105.63453   ]\n",
      " [ 23.137226     9.791563   100.485565   107.65242   ]\n",
      " [ 21.714779     8.220646   100.125854   104.562645  ]\n",
      " [ 22.056667     9.563948    99.27065    104.13308   ]\n",
      " [ 22.625965     8.700626   100.27008    106.131744  ]\n",
      " [ 21.770828     7.737981   100.39482    105.21167   ]\n",
      " [ 22.6494       8.287993   100.105415   103.77604   ]\n",
      " [ 22.633007     8.46509     99.9534     106.99963   ]\n",
      " [ 22.788359     9.413433    99.652725   105.643394  ]\n",
      " [ 21.670176     9.340134   100.16818    106.68542   ]\n",
      " [ 21.736425     8.111361    99.808624   104.515785  ]\n",
      " [ 21.872063     9.021348   100.610756   105.72878   ]\n",
      " [ 22.094845     7.7160378  100.08877    104.4155    ]\n",
      " [ 22.361576     6.925866   102.04801    104.69499   ]\n",
      " [ 21.878399    11.713526    99.3114     105.24109   ]\n",
      " [ 21.464987    12.269333    99.29131    105.85389   ]\n",
      " [ 20.905218     8.271017    97.335884   105.2287    ]\n",
      " [ 22.052904     7.8901305  101.8863     105.17975   ]\n",
      " [ 20.93412      7.8979344   98.858154   105.97469   ]\n",
      " [ 22.45015      9.7667885  102.47516    106.23951   ]\n",
      " [ 21.41607      7.7860527  101.05433    105.74211   ]\n",
      " [ 22.684368    12.984503   100.06015    106.50407   ]\n",
      " [ 24.877275    14.297434   101.996925   106.11542   ]\n",
      " [ 21.108875     2.8127046  100.08306    108.162544  ]\n",
      " [ 22.92849      4.575432    98.48342    106.931274  ]\n",
      " [ 20.184645     6.0328083  100.248184   106.57818   ]\n",
      " [ 20.224636     6.256872    96.40869    107.449844  ]\n",
      " [ 20.146349     6.3214664  100.15985    107.32591   ]\n",
      " [ 19.1782       6.927091    97.80104    104.20967   ]\n",
      " [ 21.354391     5.5724306  101.98923    106.8269    ]\n",
      " [ 22.006721     9.207894   104.027016   108.995224  ]\n",
      " [ 23.725597     3.3351765  101.25922    108.08525   ]\n",
      " [ 22.958086     1.1121383  100.407394   106.34686   ]\n",
      " [ 24.376549    12.929341   103.856544   105.38697   ]\n",
      " [ 25.284153    14.66101    105.81612    104.76869   ]\n",
      " [ 23.734552     3.9781618  103.27095    109.646576  ]\n",
      " [ 20.389671     0.12941885 100.9115     109.0018    ]\n",
      " [ 27.822502     9.495925   105.29338    105.58265   ]] (42, 4)\n",
      "\n",
      "[0.9954521  0.99217635 0.99159664 0.9870184  0.9824265  0.98188984\n",
      " 0.970553   0.9669945  0.9639505  0.96199954 0.96129775 0.95975995\n",
      " 0.95629346 0.9526129  0.95165604 0.9490522  0.946879   0.9328133\n",
      " 0.86979693 0.7064418  0.6322998  0.58048713 0.56354284 0.5404558\n",
      " 0.52252567 0.505694   0.42940038 0.40427545 0.36854184 0.3651061\n",
      " 0.3426696  0.335348   0.320323   0.31616423 0.300556   0.18086928\n",
      " 0.16734836 0.1187381  0.11623544 0.10394552 0.09038076 0.03934347] (42,)\n",
      "Tensor in gpu\n",
      "test [[[ 60.  55.  46.]\n",
      "  [ 59.  55.  47.]\n",
      "  [ 60.  55.  48.]\n",
      "  ...\n",
      "  [106. 104. 105.]\n",
      "  [ 74.  75.  89.]\n",
      "  [ 57.  63.  84.]]\n",
      "\n",
      " [[ 52.  46.  33.]\n",
      "  [ 54.  47.  36.]\n",
      "  [ 56.  50.  40.]\n",
      "  ...\n",
      "  [ 91.  92.  96.]\n",
      "  [ 63.  69.  88.]\n",
      "  [ 53.  65.  99.]]\n",
      "\n",
      " [[ 51.  43.  25.]\n",
      "  [ 51.  42.  25.]\n",
      "  [ 51.  43.  26.]\n",
      "  ...\n",
      "  [ 70.  67.  62.]\n",
      "  [ 64.  64.  66.]\n",
      "  [ 65.  66.  76.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 21.  20.  15.]\n",
      "  [ 20.  19.  14.]\n",
      "  [ 20.  20.  15.]\n",
      "  ...\n",
      "  [ 87.  83.  45.]\n",
      "  [ 88.  83.  45.]\n",
      "  [ 88.  82.  42.]]\n",
      "\n",
      " [[ 18.  19.  10.]\n",
      "  [ 17.  18.   9.]\n",
      "  [ 16.  17.   8.]\n",
      "  ...\n",
      "  [ 86.  83.  45.]\n",
      "  [ 87.  83.  45.]\n",
      "  [ 90.  84.  45.]]\n",
      "\n",
      " [[ 17.  18.   9.]\n",
      "  [ 16.  17.   8.]\n",
      "  [ 15.  17.   8.]\n",
      "  ...\n",
      "  [ 83.  81.  45.]\n",
      "  [ 83.  81.  45.]\n",
      "  [ 86.  83.  47.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f640>\n",
      "[[ 11.321354   20.378984   88.18684   107.21335  ]\n",
      " [ 11.702918   19.87674    87.66992   107.65352  ]\n",
      " [ 11.411156   19.885466   88.239555  107.180916 ]\n",
      " [ 11.061424   20.029684   87.54678   106.64093  ]\n",
      " [ 11.966572   17.562347   87.57099   107.90463  ]\n",
      " [ 12.126722   17.375267   88.17071   107.13922  ]\n",
      " [ 12.111515   22.857924   88.18787   106.95129  ]\n",
      " [ 11.118759   17.922329   87.23198   106.665115 ]\n",
      " [  9.514814   17.714417   87.2032    106.52597  ]\n",
      " [ 11.061726   16.877682   88.10487   105.57197  ]\n",
      " [ 10.680943   17.783024   86.8814    105.367805 ]\n",
      " [ 11.917749   19.046484   87.86006   107.51823  ]\n",
      " [ 10.496445   22.653664   86.80414   106.736946 ]\n",
      " [  9.763615   17.223873   85.83008   105.716286 ]\n",
      " [  9.889662   18.435486   86.453835  107.029205 ]\n",
      " [  9.801563   16.831137   88.4969    107.618576 ]\n",
      " [ 11.606494   20.980387   89.34451   106.39608  ]\n",
      " [ 10.225147   16.920887   87.311226  107.15864  ]\n",
      " [ 10.829547   16.100084   88.41517   108.49491  ]\n",
      " [ 10.86856    17.914839   88.97167   107.23105  ]\n",
      " [ 11.904488   19.261196   87.669495  106.844574 ]\n",
      " [ 10.026175   16.020962   86.462234  108.46317  ]\n",
      " [ 10.317081   24.037529   86.794205  106.99841  ]\n",
      " [ 11.390781   18.161076   88.488846  107.53854  ]\n",
      " [  9.580523   19.128574   88.123726  106.04028  ]\n",
      " [ 10.9055805  19.248367   88.787186  106.15102  ]\n",
      " [  9.4969425  19.134327   86.616135  105.32408  ]\n",
      " [ 10.4281025  21.442848   85.247505  106.92904  ]\n",
      " [ 10.87392    11.904442   87.27764   109.55069  ]\n",
      " [ 15.5963955  12.231705   90.37957   107.10603  ]\n",
      " [ 10.859772   14.490301   87.660965  109.47926  ]\n",
      " [  6.887751   10.381897   86.44499   110.33871  ]\n",
      " [ 13.1059475   8.219307   90.06588   111.512634 ]\n",
      " [  9.267415    8.201002   91.07282   110.15594  ]\n",
      " [ 15.413895    7.094515   87.61082   109.19164  ]\n",
      " [  6.2150755  13.52537    84.842636  109.177734 ]\n",
      " [ 14.78858    25.343294   91.77221   110.63755  ]\n",
      " [  8.448491    7.92648    90.04042   109.816666 ]\n",
      " [ 11.553345    6.911827   89.83163   108.70325  ]\n",
      " [  3.1698523   3.2862802  84.44953   110.16571  ]\n",
      " [  6.9060993   3.0352063  90.23712   112.437195 ]\n",
      " [ 12.232516    6.3029647  84.6294    106.794464 ]\n",
      " [  6.8450265  29.026402   80.29275   108.93887  ]] (43, 4)\n",
      "\n",
      "[0.9966462  0.99584574 0.9957113  0.99506515 0.96291286 0.93800354\n",
      " 0.93134284 0.92576844 0.917738   0.906634   0.9007279  0.8943448\n",
      " 0.89279413 0.88298124 0.85930777 0.8259143  0.8236322  0.80049294\n",
      " 0.79162115 0.79046035 0.78552496 0.76793784 0.6453462  0.58929896\n",
      " 0.5763936  0.5709922  0.41404602 0.30617416 0.2639087  0.1647598\n",
      " 0.15559451 0.1416807  0.10355275 0.09246182 0.08167566 0.06572886\n",
      " 0.06354064 0.04565005 0.03482837 0.03000239 0.0296057  0.02439961\n",
      " 0.02369761] (43,)\n",
      "Tensor in gpu\n",
      "test [[[148. 136. 111.]\n",
      "  [140. 127. 102.]\n",
      "  [134. 120.  97.]\n",
      "  ...\n",
      "  [ 67.  73.  47.]\n",
      "  [ 67.  74.  46.]\n",
      "  [ 67.  73.  46.]]\n",
      "\n",
      " [[146. 134. 109.]\n",
      "  [139. 126. 101.]\n",
      "  [140. 126. 101.]\n",
      "  ...\n",
      "  [ 65.  72.  44.]\n",
      "  [ 65.  71.  44.]\n",
      "  [ 65.  71.  44.]]\n",
      "\n",
      " [[141. 128. 103.]\n",
      "  [138. 124. 100.]\n",
      "  [139. 126. 103.]\n",
      "  ...\n",
      "  [ 63.  70.  43.]\n",
      "  [ 63.  70.  43.]\n",
      "  [ 63.  70.  43.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[156. 164. 183.]\n",
      "  [163. 171. 189.]\n",
      "  [164. 171. 188.]\n",
      "  ...\n",
      "  [ 69.  68.  49.]\n",
      "  [ 67.  67.  47.]\n",
      "  [ 64.  65.  45.]]\n",
      "\n",
      " [[151. 160. 179.]\n",
      "  [160. 170. 187.]\n",
      "  [164. 171. 188.]\n",
      "  ...\n",
      "  [ 72.  65.  49.]\n",
      "  [ 69.  66.  48.]\n",
      "  [ 67.  65.  47.]]\n",
      "\n",
      " [[147. 154. 173.]\n",
      "  [159. 168. 186.]\n",
      "  [162. 171. 187.]\n",
      "  ...\n",
      "  [ 80.  69.  53.]\n",
      "  [ 78.  69.  53.]\n",
      "  [ 72.  67.  49.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f2e0>\n",
      "[[  9.629426   16.975565   87.337555  110.621155 ]\n",
      " [ 10.311478   18.629059   87.95319   109.54498  ]\n",
      " [  9.518055   16.779266   87.46649   109.41     ]\n",
      " [ 10.0728245  16.342524   87.86583   108.62947  ]\n",
      " [  8.563084   16.871658   86.185326  109.390274 ]\n",
      " [ 10.974016   17.468447   87.24072   109.5587   ]\n",
      " [  9.469219   16.039215   88.19371   110.06703  ]\n",
      " [ 10.407524   18.428505   87.2812    108.147285 ]\n",
      " [  9.986193   16.076622   87.17747   108.7215   ]\n",
      " [  9.336502   17.562214   86.047646  108.73865  ]\n",
      " [ 10.409644   17.71408    88.22309   108.843895 ]\n",
      " [  9.425032   20.376537   86.497665  106.84129  ]\n",
      " [  9.48768    19.595428   86.849724  108.340546 ]\n",
      " [ 10.086603   16.637798   86.59417   107.5023   ]\n",
      " [  9.76325    16.574549   88.47184   110.3235   ]\n",
      " [  9.936306   16.684614   86.553795  110.36892  ]\n",
      " [  9.493778   16.789547   87.262024  108.41484  ]\n",
      " [  8.586529   16.121374   88.08401   108.53429  ]\n",
      " [  9.270563   17.30959    86.04782   107.82161  ]\n",
      " [ 10.107715   18.896164   87.60328   108.75436  ]\n",
      " [  8.419615   17.405815   87.354645  109.184586 ]\n",
      " [ 10.638151   19.256355   89.23378   106.929794 ]\n",
      " [  9.147957   18.19492    86.55488   107.72928  ]\n",
      " [  8.546444   18.860004   86.90082   108.34375  ]\n",
      " [  9.1245575  18.54086    86.942085  107.86587  ]\n",
      " [ 10.157923   21.185127   86.64251   110.947174 ]\n",
      " [ 10.894141   17.681423   85.86074   107.18292  ]\n",
      " [  8.245209   19.853334   87.54089   110.77779  ]\n",
      " [ 10.956593   11.572875   88.413895  107.156395 ]\n",
      " [  6.2202425  12.227232   86.98166   110.415504 ]\n",
      " [  6.417897   13.099612   85.7329    111.83975  ]\n",
      " [  7.2015767  11.559804   91.57842   110.19572  ]\n",
      " [ 10.241309   13.872287   88.77392   106.56277  ]\n",
      " [ 12.863388   12.701469   90.20862   107.42019  ]\n",
      " [  5.1860266  11.121122   89.276024  109.236786 ]\n",
      " [ 11.631548    8.703888   89.84686   109.25888  ]\n",
      " [ 12.698435    9.120469   87.76905   108.033424 ]\n",
      " [  8.411198    9.181889   89.82712   107.57216  ]\n",
      " [  4.000776    8.255242   89.62193   109.749916 ]\n",
      " [  2.3648238   7.4387083  86.05011   110.18145  ]\n",
      " [ 13.1592865  26.225126   91.68099   110.04775  ]] (41, 4)\n",
      "\n",
      "[0.9990771  0.99889356 0.99869543 0.99805605 0.97673506 0.9743814\n",
      " 0.9739501  0.9725884  0.9679079  0.96790075 0.9666463  0.9592059\n",
      " 0.95725864 0.95292056 0.9448662  0.9321871  0.9261795  0.91500574\n",
      " 0.86208004 0.8602649  0.847088   0.77122825 0.73158294 0.7268218\n",
      " 0.669294   0.6688454  0.64808905 0.4274855  0.28774676 0.24850684\n",
      " 0.20338084 0.15540875 0.13702242 0.11779628 0.11040983 0.08122919\n",
      " 0.05613504 0.04972019 0.04698133 0.03036482 0.02408782] (41,)\n",
      "Tensor in gpu\n",
      "test [[[ 88. 127. 148.]\n",
      "  [ 82. 116. 137.]\n",
      "  [ 75. 107. 125.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[114. 162. 190.]\n",
      "  [114. 162. 190.]\n",
      "  [114. 162. 190.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[114. 163. 191.]\n",
      "  [114. 162. 190.]\n",
      "  [114. 162. 190.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 78.  78.  78.]\n",
      "  [ 78.  79.  78.]\n",
      "  [ 79.  80.  79.]\n",
      "  ...\n",
      "  [145. 145. 144.]\n",
      "  [145. 143. 143.]\n",
      "  [141. 139. 139.]]\n",
      "\n",
      " [[ 92.  95.  96.]\n",
      "  [ 90.  92.  94.]\n",
      "  [ 93.  95.  96.]\n",
      "  ...\n",
      "  [123. 118. 115.]\n",
      "  [116. 110. 107.]\n",
      "  [117. 111. 109.]]\n",
      "\n",
      " [[105. 109. 112.]\n",
      "  [105. 109. 112.]\n",
      "  [106. 110. 113.]\n",
      "  ...\n",
      "  [100.  91.  85.]\n",
      "  [ 99.  86.  79.]\n",
      "  [100.  87.  79.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7fa90>\n",
      "[[ 21.0963     20.857718   97.56026   108.542336 ]\n",
      " [ 20.748772   19.659391   97.16266   108.32168  ]\n",
      " [ 20.976536   20.614735   97.54965   108.64305  ]\n",
      " [ 20.82564    19.587173   98.29758   107.61874  ]\n",
      " [ 20.708124   19.896646   96.38541   107.92133  ]\n",
      " [ 21.089859   20.531761   97.467384  108.88167  ]\n",
      " [ 22.661087   19.43782    96.62944   110.04965  ]\n",
      " [ 19.610182   17.54997    98.0184    108.42107  ]\n",
      " [ 19.236292   17.456064   96.35155   107.87048  ]\n",
      " [ 21.58027    21.787983   97.21371   107.31196  ]\n",
      " [ 19.490183   16.67166    96.99715   108.65329  ]\n",
      " [ 20.394415   17.63551    96.534584  107.83801  ]\n",
      " [ 20.038704   17.462963   95.46042   106.96735  ]\n",
      " [ 19.931053   17.60049    97.61984   107.31778  ]\n",
      " [ 20.145859   17.240124   96.472244  109.05239  ]\n",
      " [ 19.226562   17.639717   96.92267   110.301186 ]\n",
      " [ 21.737377   17.021288   97.28141   110.42999  ]\n",
      " [ 21.722439   22.201052   98.74953   108.62741  ]\n",
      " [ 20.159973   18.595015   97.720535  108.35556  ]\n",
      " [ 19.214195   17.51417    97.81566   110.102425 ]\n",
      " [ 20.591463   16.977379   97.277405  109.7577   ]\n",
      " [ 21.269548   14.325695   96.60296   111.05135  ]\n",
      " [ 20.652805   18.754883   98.67725   107.54844  ]\n",
      " [ 20.588465   16.816544   98.05451   106.508514 ]\n",
      " [ 20.105917   17.495415   98.34304   105.770134 ]\n",
      " [ 21.203854   15.164282   96.09862   107.384636 ]\n",
      " [ 21.856228   19.016052  100.13817   110.07761  ]\n",
      " [ 19.907772   15.170748   96.71358   108.21574  ]\n",
      " [ 18.698418   14.704682   95.142876  106.53414  ]\n",
      " [ 18.844713   24.305172   95.393745  109.76466  ]\n",
      " [ 18.520557   13.800903   96.95745   112.00473  ]\n",
      " [ 23.708607   25.913027  101.95356   108.086586 ]\n",
      " [ 23.035873    9.2569475  92.78293   106.215775 ]\n",
      " [ 16.708576    8.647701   98.215706  109.14368  ]\n",
      " [ 25.23367    22.674809   99.56882   106.82541  ]\n",
      " [ 17.615133    9.188982   98.924706  110.81152  ]\n",
      " [ 18.348663    8.053529   99.08756   110.94811  ]\n",
      " [ 16.759209    7.3185987  97.54687   110.4647   ]\n",
      " [ 14.845449   17.76606    94.84799   108.55723  ]\n",
      " [ 19.54179    13.070219  101.62122   114.94334  ]] (40, 4)\n",
      "\n",
      "[0.99604625 0.99461406 0.9908861  0.98125994 0.9590752  0.9570611\n",
      " 0.9533049  0.9177627  0.9146018  0.912571   0.8849579  0.8824726\n",
      " 0.8669576  0.86057323 0.83762145 0.77300495 0.75880396 0.75846964\n",
      " 0.74744344 0.73336625 0.72633123 0.61201215 0.57704324 0.54363734\n",
      " 0.5047924  0.4620909  0.3718997  0.31635746 0.29098448 0.11088309\n",
      " 0.07841824 0.06656738 0.05900484 0.04245003 0.04236563 0.04166878\n",
      " 0.0294398  0.02507207 0.02316377 0.02158   ] (40,)\n",
      "Tensor in gpu\n",
      "test [[[158. 163. 177.]\n",
      "  [160. 165. 177.]\n",
      "  [160. 165. 178.]\n",
      "  ...\n",
      "  [158. 165. 181.]\n",
      "  [158. 165. 181.]\n",
      "  [158. 165. 181.]]\n",
      "\n",
      " [[155. 161. 176.]\n",
      "  [157. 162. 176.]\n",
      "  [159. 164. 177.]\n",
      "  ...\n",
      "  [158. 165. 181.]\n",
      "  [158. 165. 181.]\n",
      "  [158. 166. 182.]]\n",
      "\n",
      " [[153. 159. 174.]\n",
      "  [156. 161. 175.]\n",
      "  [158. 163. 177.]\n",
      "  ...\n",
      "  [158. 165. 181.]\n",
      "  [158. 165. 181.]\n",
      "  [158. 165. 181.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 14.  15.  13.]\n",
      "  [ 13.  15.  13.]\n",
      "  [ 12.  14.  12.]\n",
      "  ...\n",
      "  [ 80.  41.  49.]\n",
      "  [124. 123. 136.]\n",
      "  [140. 146. 158.]]\n",
      "\n",
      " [[ 14.  16.  13.]\n",
      "  [ 14.  16.  13.]\n",
      "  [ 13.  15.  13.]\n",
      "  ...\n",
      "  [ 72.  25.  32.]\n",
      "  [105.  89. 102.]\n",
      "  [137. 143. 156.]]\n",
      "\n",
      " [[ 14.  15.  13.]\n",
      "  [ 14.  16.  13.]\n",
      "  [ 15.  17.  14.]\n",
      "  ...\n",
      "  [ 70.  25.  30.]\n",
      "  [ 90.  51.  61.]\n",
      "  [129. 132. 144.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f1f0>\n",
      "[[ 32.57422   21.734262 102.08194  108.18979 ]\n",
      " [ 32.952312  21.27771  101.76421  108.00357 ]\n",
      " [ 33.237038  22.167057 102.55323  108.139   ]\n",
      " [ 32.61831   21.166243 103.030014 107.62279 ]\n",
      " [ 33.230625  21.96927  102.130135 108.01684 ]\n",
      " [ 33.33808   21.169607 101.67023  109.22541 ]\n",
      " [ 32.50658   21.642569 104.69049  108.70789 ]\n",
      " [ 32.709366  21.146559 102.63351  107.92187 ]\n",
      " [ 32.01963   22.435062 101.96428  108.622955]\n",
      " [ 33.83026   19.587116 101.60146  108.80047 ]\n",
      " [ 30.794487  18.258358 101.76155  109.40573 ]\n",
      " [ 30.151628  17.452406 102.215546 108.314926]\n",
      " [ 30.66586   18.342018 102.62334  108.0222  ]\n",
      " [ 31.014164  18.615602 102.507996 108.17563 ]\n",
      " [ 30.825201  17.839928 101.557106 108.013245]\n",
      " [ 31.833876  18.729454 102.41009  109.30981 ]\n",
      " [ 31.489676  18.538252 103.25873  109.21542 ]\n",
      " [ 31.396326  17.362007 104.46375  107.914215]\n",
      " [ 29.625822  15.346633 101.60752  111.18452 ]\n",
      " [ 30.978897  18.9499   104.11774  108.79037 ]\n",
      " [ 30.663176  17.527298 103.554535 109.31788 ]\n",
      " [ 29.383831  17.345303 102.43107  109.50347 ]\n",
      " [ 31.862835  20.047184 103.68084  110.41202 ]\n",
      " [ 30.192547  17.391088 104.57449  107.89037 ]\n",
      " [ 31.059032  13.145281 101.92482  112.33042 ]\n",
      " [ 34.170822  14.602711 104.944595 112.42508 ]\n",
      " [ 30.87732   25.462305  99.53803  107.88911 ]\n",
      " [ 31.189285  15.713333 104.52405  110.08949 ]\n",
      " [ 29.771702  18.686401 102.76241  107.115005]\n",
      " [ 30.48715   21.911816  97.47565  106.36268 ]\n",
      " [ 34.75115   26.18668  105.204254 110.607185]\n",
      " [ 34.09695   13.709653 105.66337  108.99127 ]\n",
      " [ 35.48886    9.122332 102.14697  108.019615]\n",
      " [ 34.70773   19.041594 108.267555 119.76876 ]\n",
      " [ 30.47089    6.782999 103.531364 111.35183 ]] (35, 4)\n",
      "\n",
      "[0.9966936  0.9960957  0.98835087 0.9879495  0.96528614 0.94254327\n",
      " 0.83552605 0.79541117 0.7707587  0.7426828  0.66160804 0.65560216\n",
      " 0.62719095 0.60461766 0.6002706  0.5672928  0.5650942  0.50739783\n",
      " 0.42657623 0.34452334 0.3318293  0.31577632 0.30478445 0.2890823\n",
      " 0.26880676 0.25128502 0.22615148 0.20699887 0.18338339 0.1153489\n",
      " 0.0896892  0.05702137 0.04650021 0.03094391 0.02525235] (35,)\n",
      "Tensor in gpu\n",
      "test [[[140. 100.  93.]\n",
      "  [136.  87.  64.]\n",
      "  [132.  86.  64.]\n",
      "  ...\n",
      "  [121. 118. 149.]\n",
      "  [121. 117. 148.]\n",
      "  [118. 114. 144.]]\n",
      "\n",
      " [[138.  94.  77.]\n",
      "  [138.  92.  69.]\n",
      "  [134.  89.  68.]\n",
      "  ...\n",
      "  [106.  99. 124.]\n",
      "  [106.  99. 125.]\n",
      "  [104.  97. 121.]]\n",
      "\n",
      " [[140.  97.  76.]\n",
      "  [135.  89.  68.]\n",
      "  [136.  90.  68.]\n",
      "  ...\n",
      "  [ 89.  76.  89.]\n",
      "  [ 89.  75.  88.]\n",
      "  [ 91.  78.  92.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 46.  35.  22.]\n",
      "  [ 61.  33.  30.]\n",
      "  [ 77.  30.  36.]\n",
      "  ...\n",
      "  [ 41.  30.  37.]\n",
      "  [ 39.  28.  36.]\n",
      "  [ 41.  30.  38.]]\n",
      "\n",
      " [[ 76.  34.  39.]\n",
      "  [ 88.  29.  42.]\n",
      "  [ 92.  25.  42.]\n",
      "  ...\n",
      "  [ 42.  30.  38.]\n",
      "  [ 41.  29.  37.]\n",
      "  [ 43.  31.  38.]]\n",
      "\n",
      " [[ 92.  27.  44.]\n",
      "  [ 94.  23.  40.]\n",
      "  [ 94.  21.  39.]\n",
      "  ...\n",
      "  [ 42.  30.  38.]\n",
      "  [ 43.  31.  38.]\n",
      "  [ 43.  31.  38.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f2b0>\n",
      "[[  7.2054753   7.4817333  90.46398   107.55625  ]\n",
      " [  7.091631    6.212225   91.407814  107.14654  ]\n",
      " [  7.698147    6.300291   89.861465  105.46025  ]\n",
      " [  7.465101    7.649414   88.720856  105.78918  ]\n",
      " [  8.058519    7.556034   90.24455   105.47069  ]\n",
      " [  6.13234     6.492368   88.00006   104.56309  ]\n",
      " [  6.6635404   7.1679945  88.16547   105.17894  ]\n",
      " [  6.701245    7.379388   90.09732   107.035995 ]\n",
      " [  7.6090326   6.4362154  89.04515   105.51667  ]\n",
      " [  8.054497    6.7131176  90.19141   107.95065  ]\n",
      " [  6.935289    6.1310315  89.96556   105.47031  ]\n",
      " [  6.758913    7.0495205  90.21304   105.937195 ]\n",
      " [  7.0217695   7.566338   88.99799   105.06262  ]\n",
      " [  7.945686    6.8988094  90.93326   107.630646 ]\n",
      " [  6.88458     7.0646977  90.29321   106.33883  ]\n",
      " [  6.838915    6.3245606  89.34935   105.24197  ]\n",
      " [  7.0538564   6.773042   90.82458   104.56576  ]\n",
      " [  7.2381997   7.525359   87.819336  105.81892  ]\n",
      " [  6.544292    7.814945   88.943695  105.052765 ]\n",
      " [  7.7568765   3.783204   89.71595   106.16288  ]\n",
      " [  7.311696    8.755921   90.67043   105.19446  ]\n",
      " [  6.689008    8.022286   91.23139   107.80807  ]\n",
      " [  7.7395296   4.0713415  90.74049   106.75201  ]\n",
      " [  5.795086    5.090437   87.62198   107.25554  ]\n",
      " [  7.075075    7.7864366  88.90556   104.27463  ]\n",
      " [  6.879423    4.5249534  89.340126  105.561295 ]\n",
      " [  8.343969    9.744165   91.012665  105.3589   ]\n",
      " [  8.1984825   2.3101397  90.3479    109.01798  ]\n",
      " [  6.5302196  10.957064   89.05012   106.578606 ]\n",
      " [  8.226187    5.111639   87.26722   106.76727  ]\n",
      " [  8.315514    5.263869   91.08445   107.13048  ]\n",
      " [  8.587936   13.222546   90.63155   106.060585 ]\n",
      " [ 11.01885     2.7873702  89.760765  108.18282  ]\n",
      " [  8.543079   10.819784   92.852806  105.58525  ]\n",
      " [  6.771036    3.116006   90.7519    106.17433  ]\n",
      " [  4.153523    4.7240534  87.27658   105.514786 ]\n",
      " [ 10.543112    7.1219153  91.5169    106.759796 ]\n",
      " [  4.5386853   1.5679665  88.30383   106.590164 ]\n",
      " [  5.4980197  13.320154   88.65983   105.189445 ]\n",
      " [  5.7899823  11.8670635  88.14581   106.063896 ]\n",
      " [  8.956046    2.4501996  89.43249   108.51887  ]\n",
      " [  4.6030393   7.8385572  86.37953   105.22881  ]] (42, 4)\n",
      "\n",
      "[0.9956216  0.9954685  0.9943837  0.9935567  0.99264646 0.9922168\n",
      " 0.9914771  0.9913516  0.9899273  0.98975986 0.9897531  0.98959243\n",
      " 0.98916477 0.9865013  0.9861702  0.9853424  0.98451114 0.9844616\n",
      " 0.8512646  0.8266093  0.821996   0.7681267  0.7037751  0.645328\n",
      " 0.6338434  0.6205884  0.6117794  0.5838605  0.51827246 0.51151526\n",
      " 0.51004547 0.50336397 0.44765192 0.4389844  0.40421748 0.3810796\n",
      " 0.36986825 0.34644508 0.31903505 0.30215293 0.1848022  0.10123467] (42,)\n",
      "Tensor in gpu\n",
      "test [[[ 61.  11.  11.]\n",
      "  [ 70.  15.  10.]\n",
      "  [ 83.  23.   8.]\n",
      "  ...\n",
      "  [111.  67.  27.]\n",
      "  [112.  68.  26.]\n",
      "  [111.  67.  24.]]\n",
      "\n",
      " [[ 66.  14.  10.]\n",
      "  [ 77.  19.   9.]\n",
      "  [ 90.  26.   8.]\n",
      "  ...\n",
      "  [109.  66.  27.]\n",
      "  [110.  66.  26.]\n",
      "  [110.  65.  24.]]\n",
      "\n",
      " [[ 71.  17.  10.]\n",
      "  [ 81.  22.   8.]\n",
      "  [ 94.  29.   7.]\n",
      "  ...\n",
      "  [105.  62.  24.]\n",
      "  [104.  61.  23.]\n",
      "  [105.  61.  22.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[114.  70.  58.]\n",
      "  [181. 160. 151.]\n",
      "  [210. 198. 191.]\n",
      "  ...\n",
      "  [113.  39.   8.]\n",
      "  [113.  41.  10.]\n",
      "  [111.  41.  10.]]\n",
      "\n",
      " [[131.  93.  82.]\n",
      "  [188. 168. 161.]\n",
      "  [212. 199. 192.]\n",
      "  ...\n",
      "  [113.  39.   8.]\n",
      "  [112.  39.   9.]\n",
      "  [108.  38.   9.]]\n",
      "\n",
      " [[144. 111. 101.]\n",
      "  [196. 180. 172.]\n",
      "  [211. 199. 191.]\n",
      "  ...\n",
      "  [113.  38.   9.]\n",
      "  [111.  37.   8.]\n",
      "  [107.  35.   8.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0046\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f1f0>\n",
      "[[ 32.20707     10.732706   102.27867    107.77089   ]\n",
      " [ 31.927473    11.334011   101.85316    109.501465  ]\n",
      " [ 31.23549      9.82917    102.798904   108.66059   ]\n",
      " [ 32.428726    11.006483   101.1929     108.76982   ]\n",
      " [ 31.244087     8.820812   102.567345   108.44633   ]\n",
      " [ 32.722088    10.441901   100.9626     110.09175   ]\n",
      " [ 32.70152     11.8066025  102.37268    107.55087   ]\n",
      " [ 30.812517     9.190647   101.50163    106.66295   ]\n",
      " [ 31.699917     9.579182   101.071175   106.853035  ]\n",
      " [ 32.276924    11.416626   101.15102    107.97757   ]\n",
      " [ 30.006905     8.75996    100.78945    107.004036  ]\n",
      " [ 31.098646     8.0453415  101.22594    109.25936   ]\n",
      " [ 30.747082     8.733088   101.19983    106.529724  ]\n",
      " [ 30.920477     8.019102   102.36899    107.75705   ]\n",
      " [ 31.732298    10.17829     99.99899    106.29362   ]\n",
      " [ 30.065718     8.35936    102.11578    108.355194  ]\n",
      " [ 31.363605     7.697676   101.61593    107.17112   ]\n",
      " [ 30.275703     9.336268   101.25885    108.75402   ]\n",
      " [ 30.747236    10.6672535  101.2724     109.094124  ]\n",
      " [ 32.536736    12.0180855  103.89772    107.45805   ]\n",
      " [ 31.928658     6.0123005  100.44054    110.26485   ]\n",
      " [ 32.764595    11.599234   105.21603    108.00507   ]\n",
      " [ 30.503586    12.600979   100.1097     109.49652   ]\n",
      " [ 32.40601      5.279567   102.32212    111.09108   ]\n",
      " [ 33.998463     5.317585   103.869286   111.06449   ]\n",
      " [ 30.22439      9.487353   104.20858    108.678024  ]\n",
      " [ 30.235432     8.95936    103.787636   108.59914   ]\n",
      " [ 34.109207     7.768729   104.96562    109.11236   ]\n",
      " [ 30.661793    11.471177   104.293045   109.91805   ]\n",
      " [ 29.846043     1.7486515   99.6425     111.057655  ]\n",
      " [ 28.45784     10.167522   101.1198     108.79272   ]\n",
      " [ 29.64679     14.241077    97.05114    107.59146   ]\n",
      " [ 28.537672    15.373312    96.785835   109.6194    ]\n",
      " [ 26.642635     5.0843954   99.20501    107.18721   ]\n",
      " [ 30.396992     4.622559    98.32409    107.411194  ]\n",
      " [ 29.505201    -0.17782116 102.06441    107.06756   ]\n",
      " [ 28.872713     3.2450542  105.07936    107.39421   ]\n",
      " [ 26.846249     8.091209    95.41153    105.974815  ]\n",
      " [ 29.310862     3.9465857  105.15559    107.88499   ]\n",
      " [ 36.328167    18.99797    106.93942    110.567986  ]\n",
      " [ 26.090227     5.740829   101.559105   109.96651   ]] (41, 4)\n",
      "\n",
      "[0.99765766 0.9927978  0.99266773 0.99241513 0.9767353  0.96627074\n",
      " 0.93059546 0.91376406 0.894474   0.8905382  0.86404127 0.86329395\n",
      " 0.8607841  0.8469193  0.8430158  0.81774396 0.81531703 0.79283166\n",
      " 0.7341306  0.7104453  0.6637548  0.59848416 0.5225836  0.43335\n",
      " 0.42527944 0.3266993  0.2905455  0.25437486 0.21255589 0.20193453\n",
      " 0.19950713 0.19633168 0.12551169 0.1107467  0.09367971 0.09227432\n",
      " 0.06859145 0.05674309 0.04792405 0.02329681 0.02036171] (41,)\n",
      "Tensor in gpu\n",
      "test [[[199. 185. 161.]\n",
      "  [199. 186. 162.]\n",
      "  [199. 186. 162.]\n",
      "  ...\n",
      "  [148. 135. 109.]\n",
      "  [149. 136. 110.]\n",
      "  [149. 136. 109.]]\n",
      "\n",
      " [[193. 178. 153.]\n",
      "  [193. 178. 153.]\n",
      "  [194. 179. 154.]\n",
      "  ...\n",
      "  [148. 136. 109.]\n",
      "  [148. 135. 109.]\n",
      "  [149. 136. 109.]]\n",
      "\n",
      " [[192. 177. 151.]\n",
      "  [190. 175. 148.]\n",
      "  [190. 174. 147.]\n",
      "  ...\n",
      "  [147. 134. 108.]\n",
      "  [147. 134. 107.]\n",
      "  [148. 136. 108.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[240. 236. 231.]\n",
      "  [240. 236. 230.]\n",
      "  [241. 236. 230.]\n",
      "  ...\n",
      "  [182. 175. 162.]\n",
      "  [183. 177. 164.]\n",
      "  [185. 178. 166.]]\n",
      "\n",
      " [[239. 234. 229.]\n",
      "  [238. 233. 228.]\n",
      "  [237. 232. 226.]\n",
      "  ...\n",
      "  [179. 172. 158.]\n",
      "  [180. 174. 160.]\n",
      "  [183. 176. 163.]]\n",
      "\n",
      " [[237. 233. 228.]\n",
      "  [236. 231. 226.]\n",
      "  [234. 229. 224.]\n",
      "  ...\n",
      "  [176. 169. 155.]\n",
      "  [179. 173. 158.]\n",
      "  [182. 175. 162.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f220>\n",
      "[[1.82601681e+01 1.18415527e+01 8.96836929e+01 1.06946289e+02]\n",
      " [1.82657490e+01 1.11660728e+01 8.94075623e+01 1.06934837e+02]\n",
      " [1.85239754e+01 1.29799194e+01 8.95316315e+01 1.07769821e+02]\n",
      " [1.81021099e+01 1.16095276e+01 8.94633026e+01 1.07125473e+02]\n",
      " [1.85565872e+01 1.08854895e+01 8.97418365e+01 1.07774437e+02]\n",
      " [1.85151558e+01 1.19869328e+01 8.93325577e+01 1.06862190e+02]\n",
      " [1.79106102e+01 1.06641998e+01 9.03774490e+01 1.06034805e+02]\n",
      " [1.74108849e+01 1.04835644e+01 8.84706192e+01 1.07235031e+02]\n",
      " [1.74850540e+01 9.95777130e+00 8.85250397e+01 1.07284843e+02]\n",
      " [1.74877357e+01 1.00491982e+01 8.83901062e+01 1.05848511e+02]\n",
      " [1.79293480e+01 9.37551498e+00 8.92192535e+01 1.05272652e+02]\n",
      " [1.93520393e+01 1.15563831e+01 9.05200348e+01 1.07510857e+02]\n",
      " [1.93424911e+01 1.35230904e+01 8.95943832e+01 1.08812462e+02]\n",
      " [1.77185898e+01 1.07258892e+01 8.82676239e+01 1.05862465e+02]\n",
      " [1.70845642e+01 1.01475258e+01 8.97613602e+01 1.07333755e+02]\n",
      " [1.66293125e+01 1.00699997e+01 9.08197098e+01 1.06691360e+02]\n",
      " [1.90803223e+01 1.15728550e+01 9.05764313e+01 1.06551491e+02]\n",
      " [1.84328117e+01 1.08737669e+01 8.88019257e+01 1.07143913e+02]\n",
      " [1.68602333e+01 1.11147709e+01 8.86676559e+01 1.07559616e+02]\n",
      " [1.72702026e+01 8.46782112e+00 8.92281418e+01 1.08914589e+02]\n",
      " [1.84952869e+01 9.89760017e+00 9.10953827e+01 1.06868759e+02]\n",
      " [1.89935799e+01 9.79328823e+00 9.00773315e+01 1.08692497e+02]\n",
      " [1.70749931e+01 9.88355446e+00 8.94571838e+01 1.07019096e+02]\n",
      " [1.87766457e+01 9.62961960e+00 9.01214828e+01 1.08342270e+02]\n",
      " [1.97039261e+01 7.08429098e+00 8.95796585e+01 1.10639473e+02]\n",
      " [1.89479771e+01 7.52640724e+00 9.06003723e+01 1.11012459e+02]\n",
      " [1.87622356e+01 1.21346798e+01 9.05120697e+01 1.09144554e+02]\n",
      " [1.70091667e+01 1.44572563e+01 8.68303528e+01 1.08412384e+02]\n",
      " [1.76149063e+01 1.14711571e+01 9.08138123e+01 1.08426620e+02]\n",
      " [1.87460270e+01 1.12634258e+01 9.03331223e+01 1.06820206e+02]\n",
      " [1.49007683e+01 1.22848272e+01 8.86506271e+01 1.06699074e+02]\n",
      " [1.59583225e+01 3.88185453e+00 9.19165497e+01 1.08295807e+02]\n",
      " [2.19615097e+01 1.72347908e+01 9.22826233e+01 1.11469116e+02]\n",
      " [1.51793098e+01 4.59060240e+00 8.91830292e+01 1.09376564e+02]\n",
      " [1.55480995e+01 4.37720966e+00 9.13246231e+01 1.08365341e+02]\n",
      " [2.01009274e+01 1.27937708e+01 9.55197296e+01 1.15486786e+02]\n",
      " [1.65274944e+01 3.22321463e+00 8.70039444e+01 1.06489220e+02]\n",
      " [1.46976862e+01 1.55762215e+01 8.45082550e+01 1.04122879e+02]\n",
      " [1.02511196e+01 2.94167948e+00 8.59089661e+01 1.09455391e+02]\n",
      " [1.41592360e+01 1.79810448e+01 8.43410568e+01 1.06287376e+02]\n",
      " [1.27856503e+01 7.61032104e-02 9.06188202e+01 1.10059090e+02]] (41, 4)\n",
      "\n",
      "[0.9969022  0.99523324 0.9945056  0.9877061  0.9784849  0.9531387\n",
      " 0.9512083  0.9271395  0.9175683  0.9121666  0.9105762  0.9041041\n",
      " 0.8990726  0.8944049  0.87275827 0.87152386 0.86751735 0.84592426\n",
      " 0.8255724  0.8052209  0.77760005 0.75444245 0.7138603  0.63866675\n",
      " 0.5015796  0.48688018 0.37949008 0.36387423 0.3469124  0.29159513\n",
      " 0.12479868 0.09602048 0.09067052 0.06426817 0.06065049 0.05999424\n",
      " 0.0538675  0.0429295  0.04286799 0.0389667  0.02119464] (41,)\n",
      "Tensor in gpu\n",
      "test [[[161. 139.  74.]\n",
      "  [160. 138.  72.]\n",
      "  [159. 137.  70.]\n",
      "  ...\n",
      "  [202. 189. 139.]\n",
      "  [201. 187. 137.]\n",
      "  [198. 184. 134.]]\n",
      "\n",
      " [[160. 138.  74.]\n",
      "  [160. 138.  73.]\n",
      "  [159. 137.  70.]\n",
      "  ...\n",
      "  [201. 188. 136.]\n",
      "  [200. 186. 135.]\n",
      "  [197. 183. 133.]]\n",
      "\n",
      " [[160. 138.  75.]\n",
      "  [160. 137.  72.]\n",
      "  [159. 136.  69.]\n",
      "  ...\n",
      "  [201. 187. 136.]\n",
      "  [199. 185. 134.]\n",
      "  [196. 182. 131.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[154. 131.  58.]\n",
      "  [153. 130.  58.]\n",
      "  [153. 130.  58.]\n",
      "  ...\n",
      "  [187. 174. 124.]\n",
      "  [186. 173. 123.]\n",
      "  [185. 172. 124.]]\n",
      "\n",
      " [[154. 131.  58.]\n",
      "  [153. 130.  57.]\n",
      "  [153. 130.  57.]\n",
      "  ...\n",
      "  [187. 173. 123.]\n",
      "  [186. 173. 123.]\n",
      "  [185. 172. 124.]]\n",
      "\n",
      " [[154. 131.  58.]\n",
      "  [153. 130.  57.]\n",
      "  [153. 130.  57.]\n",
      "  ...\n",
      "  [186. 173. 123.]\n",
      "  [186. 173. 124.]\n",
      "  [185. 173. 124.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f370>\n",
      "[[ 24.78048    17.184008   97.66204   109.61668  ]\n",
      " [ 25.520031   15.140337   97.41673   109.10526  ]\n",
      " [ 24.84428    16.53653    97.022194  109.80809  ]\n",
      " [ 25.869797   15.156132   96.56382   109.97209  ]\n",
      " [ 26.104158   16.588264   96.67965   110.09018  ]\n",
      " [ 26.183924   16.880276   96.88119   110.16674  ]\n",
      " [ 25.15071    14.950146   96.97684   111.54096  ]\n",
      " [ 23.105408   14.554973   95.99594   110.279526 ]\n",
      " [ 24.035938   15.711811   96.60674   109.53117  ]\n",
      " [ 24.300472   13.99725    97.64151   108.60888  ]\n",
      " [ 25.019718   14.376867   96.08934   107.91817  ]\n",
      " [ 24.265495   12.831385   97.729095  109.05909  ]\n",
      " [ 24.78087    15.002777   97.036026  108.71788  ]\n",
      " [ 24.604603   14.606712   96.73931   109.917885 ]\n",
      " [ 24.417889   16.766615   95.98591   108.52097  ]\n",
      " [ 25.716993   14.351103   96.29744   109.08307  ]\n",
      " [ 24.525925   16.787704   96.54966   109.70605  ]\n",
      " [ 26.610035   16.717346   96.93799   111.448524 ]\n",
      " [ 23.019756   14.158241   97.40338   111.304245 ]\n",
      " [ 23.4048     12.016153   95.982     112.38472  ]\n",
      " [ 24.46051    14.416992   97.34108   110.672134 ]\n",
      " [ 23.989368   14.915318   97.56101   111.95859  ]\n",
      " [ 25.646187   13.872898   97.78192   110.120834 ]\n",
      " [ 25.03249    12.996016   98.19734   108.37932  ]\n",
      " [ 24.213379   13.7692     98.64388   109.67515  ]\n",
      " [ 26.1146     15.217671   99.23508   112.51147  ]\n",
      " [ 24.906939    9.588053   96.88565   109.49716  ]\n",
      " [ 23.131006   11.963856   94.44396   107.38357  ]\n",
      " [ 23.40871     9.015367   96.805244  110.01415  ]\n",
      " [ 25.78603     7.381524   92.95774   111.870995 ]\n",
      " [ 21.988865    6.675333   97.53761   114.45152  ]\n",
      " [ 23.76074     9.882309  100.4326    117.81852  ]\n",
      " [ 27.417343   19.304113   99.92934   108.62361  ]\n",
      " [ 27.676357   20.79563   101.55337   110.01527  ]\n",
      " [ 22.5639     21.348385   92.27707   111.945854 ]\n",
      " [ 23.394243    7.855587   93.82344   114.92996  ]\n",
      " [ 20.31645     6.8319087  97.29117   111.79775  ]\n",
      " [ 22.058853    6.6111693  98.51768   113.199745 ]\n",
      " [ 21.556238    4.3223085  95.84374   114.07062  ]] (39, 4)\n",
      "\n",
      "[0.9954549  0.9947424  0.9915616  0.9838462  0.97630024 0.9069903\n",
      " 0.8967209  0.89669865 0.8952782  0.8912491  0.88918304 0.8870176\n",
      " 0.8594805  0.8478838  0.8462537  0.8305887  0.8026319  0.799596\n",
      " 0.75260097 0.7385179  0.69737726 0.651486   0.44834208 0.43902218\n",
      " 0.43835938 0.42400503 0.31086254 0.22307223 0.21328183 0.12400129\n",
      " 0.07639204 0.06754754 0.06272268 0.06207175 0.03741303 0.03232438\n",
      " 0.02527272 0.02418399 0.02165413] (39,)\n",
      "Tensor in gpu\n",
      "test [[[149. 132.  96.]\n",
      "  [152. 136. 101.]\n",
      "  [153. 137. 102.]\n",
      "  ...\n",
      "  [152. 137.  79.]\n",
      "  [151. 135.  78.]\n",
      "  [150. 135.  78.]]\n",
      "\n",
      " [[146. 129.  93.]\n",
      "  [150. 135. 102.]\n",
      "  [153. 138. 105.]\n",
      "  ...\n",
      "  [152. 137.  77.]\n",
      "  [151. 136.  78.]\n",
      "  [152. 137.  80.]]\n",
      "\n",
      " [[140. 120.  83.]\n",
      "  [145. 128.  95.]\n",
      "  [152. 136. 104.]\n",
      "  ...\n",
      "  [151. 135.  77.]\n",
      "  [152. 137.  80.]\n",
      "  [152. 138.  82.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[173. 181. 192.]\n",
      "  [155. 158. 161.]\n",
      "  [139. 133. 123.]\n",
      "  ...\n",
      "  [121. 104.  55.]\n",
      "  [127. 110.  57.]\n",
      "  [131. 114.  58.]]\n",
      "\n",
      " [[170. 178. 188.]\n",
      "  [155. 157. 160.]\n",
      "  [139. 133. 123.]\n",
      "  ...\n",
      "  [119. 102.  55.]\n",
      "  [123. 106.  55.]\n",
      "  [126. 109.  55.]]\n",
      "\n",
      " [[167. 174. 185.]\n",
      "  [154. 156. 159.]\n",
      "  [141. 135. 125.]\n",
      "  ...\n",
      "  [114.  98.  52.]\n",
      "  [117. 101.  52.]\n",
      "  [122. 104.  52.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f490>\n",
      "[[  7.064297   10.0992565  87.793274  106.95976  ]\n",
      " [  6.2158566   9.404761   89.04325   106.34037  ]\n",
      " [  6.4829454  10.259494   88.2073    107.74898  ]\n",
      " [  6.391775   10.376813   88.6302    106.35518  ]\n",
      " [  7.6022635   9.601599   87.90643   108.12648  ]\n",
      " [  7.119679    8.803562   87.86713   104.27457  ]\n",
      " [  7.291956    9.510342   86.83235   105.3013   ]\n",
      " [  6.2693725  10.33494    86.23781   106.32396  ]\n",
      " [  7.1703644  10.312459   87.35878   105.78751  ]\n",
      " [  5.638971   10.095585   85.408455  104.567505 ]\n",
      " [  7.46962     8.142756   88.27924   108.73841  ]\n",
      " [  6.7667203  10.49773    87.557816  105.45719  ]\n",
      " [  6.7132277   8.344566   87.625046  106.42583  ]\n",
      " [  7.0809965   8.778929   87.26769   106.23492  ]\n",
      " [  5.905669   10.619665   87.45342   105.77078  ]\n",
      " [  6.0274777   9.258186   89.083664  106.2754   ]\n",
      " [  5.9767222   9.797113   87.052635  108.11676  ]\n",
      " [  6.807539    9.673155   86.08429   107.192856 ]\n",
      " [  5.908303   11.35504    87.265625  106.07761  ]\n",
      " [  7.342391   11.642583   89.17178   106.55574  ]\n",
      " [  7.027948   10.937026   89.46884   107.532936 ]\n",
      " [  6.8171787  12.221188   87.32926   105.61166  ]\n",
      " [  6.5222254  13.755432   87.47365   107.26095  ]\n",
      " [  7.3832364   5.505246   87.77158   108.65759  ]\n",
      " [  8.602583   15.738314   88.97722   107.38704  ]\n",
      " [  5.353427    7.9293003  84.81162   107.9872   ]\n",
      " [  3.839664    8.031713   85.25325   107.71674  ]\n",
      " [  5.5769634  15.276041   87.045944  106.32183  ]\n",
      " [  6.804161    5.7538266  88.619354  109.044754 ]\n",
      " [  6.038132   13.861656   85.97231   106.250244 ]\n",
      " [  5.924745    5.2715926  87.60283   107.21168  ]\n",
      " [  8.318098   12.465422   88.99063   105.83466  ]\n",
      " [  9.077515    2.6128235  88.51635   109.99214  ]\n",
      " [  7.94621     7.6834435  89.7231    109.311325 ]\n",
      " [  8.325952   14.499548   91.63111   106.4045   ]\n",
      " [  4.192753    4.4924493  85.52821   108.45763  ]\n",
      " [  8.601245    5.5953217  86.986084  107.36463  ]\n",
      " [ 10.717048    3.6961727  87.92412   109.31198  ]\n",
      " [  5.4625316   5.983034   88.07849   109.012375 ]\n",
      " [  8.699127    4.2906857  86.84881   109.13629  ]\n",
      " [ 11.702397    7.782655   90.8228    106.98147  ]\n",
      " [  4.7700124   9.959454   83.7904    105.98356  ]] (42, 4)\n",
      "\n",
      "[0.99610573 0.9942879  0.9923855  0.9896478  0.9861044  0.98595375\n",
      " 0.9848437  0.98354787 0.98315585 0.98267037 0.9816389  0.9773909\n",
      " 0.9769437  0.9760369  0.9725869  0.97086346 0.9653544  0.96410054\n",
      " 0.80276847 0.76534915 0.7043806  0.6924233  0.69138235 0.69089675\n",
      " 0.6395595  0.60800815 0.4888389  0.48494062 0.46959716 0.46818587\n",
      " 0.46717015 0.43690616 0.36362934 0.35806718 0.35657766 0.32493782\n",
      " 0.32154226 0.308665   0.2724418  0.20629917 0.17740685 0.15755104] (42,)\n",
      "Tensor in gpu\n",
      "test [[[233. 232. 226.]\n",
      "  [234. 232. 226.]\n",
      "  [234. 233. 226.]\n",
      "  ...\n",
      "  [235. 233. 227.]\n",
      "  [234. 233. 226.]\n",
      "  [234. 232. 226.]]\n",
      "\n",
      " [[231. 230. 225.]\n",
      "  [231. 230. 226.]\n",
      "  [232. 231. 226.]\n",
      "  ...\n",
      "  [235. 233. 227.]\n",
      "  [234. 233. 226.]\n",
      "  [234. 232. 226.]]\n",
      "\n",
      " [[229. 229. 225.]\n",
      "  [230. 229. 225.]\n",
      "  [230. 230. 225.]\n",
      "  ...\n",
      "  [234. 233. 227.]\n",
      "  [234. 233. 226.]\n",
      "  [234. 233. 226.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[142. 137. 119.]\n",
      "  [139. 134. 117.]\n",
      "  [137. 132. 114.]\n",
      "  ...\n",
      "  [222. 218. 203.]\n",
      "  [223. 219. 204.]\n",
      "  [223. 219. 205.]]\n",
      "\n",
      " [[144. 139. 121.]\n",
      "  [142. 137. 119.]\n",
      "  [140. 134. 116.]\n",
      "  ...\n",
      "  [217. 212. 196.]\n",
      "  [218. 213. 196.]\n",
      "  [218. 213. 197.]]\n",
      "\n",
      " [[145. 139. 121.]\n",
      "  [143. 138. 119.]\n",
      "  [140. 134. 116.]\n",
      "  ...\n",
      "  [210. 205. 186.]\n",
      "  [210. 205. 186.]\n",
      "  [211. 205. 187.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f2e0>\n",
      "[[ 19.18837    17.110676   95.58567   107.852974 ]\n",
      " [ 18.435566   17.260841   95.21445   107.40535  ]\n",
      " [ 18.508871   17.155052   95.8308    107.53877  ]\n",
      " [ 18.284576   17.977758   95.87398   108.49715  ]\n",
      " [ 19.498938   17.539204   95.954384  108.19608  ]\n",
      " [ 18.325506   17.884571   95.42097   108.49637  ]\n",
      " [ 18.734825   18.311705   96.93971   105.90352  ]\n",
      " [ 17.646046   15.866808   95.01425   107.26362  ]\n",
      " [ 18.185925   16.41114    94.47485   106.348175 ]\n",
      " [ 18.302057   15.16469    94.78517   106.40669  ]\n",
      " [ 17.007046   15.042187   93.91418   106.42428  ]\n",
      " [ 17.812513   16.245068   94.29761   107.78771  ]\n",
      " [ 18.721046   19.750479   94.4206    106.66159  ]\n",
      " [ 17.55532    16.154985   95.76364   106.49881  ]\n",
      " [ 17.670319   16.461983   95.392166  107.76378  ]\n",
      " [ 18.031017   16.08967    94.06633   107.58122  ]\n",
      " [ 19.578678   13.875037   95.03516   108.08765  ]\n",
      " [ 17.681726   16.519274   95.40088   109.29012  ]\n",
      " [ 18.423689   15.435404   94.645386  106.934906 ]\n",
      " [ 18.336342   15.757463   96.46413   106.23343  ]\n",
      " [ 18.039234   15.468345   92.85772   108.61615  ]\n",
      " [ 17.705338   12.961275   95.98837   108.14412  ]\n",
      " [ 17.025984   15.378797   93.56041   109.647896 ]\n",
      " [ 18.265537   18.224867   96.27361   107.26662  ]\n",
      " [ 19.082903   12.399142   94.907715  108.88033  ]\n",
      " [ 17.440193   16.436762   95.56079   106.7057   ]\n",
      " [ 18.958279   15.603111   95.4562    107.061264 ]\n",
      " [ 20.009266   22.456606   96.96428   107.93782  ]\n",
      " [ 17.77071    14.497728   95.53944   113.33588  ]\n",
      " [ 17.213238   21.493263   92.03216   109.180626 ]\n",
      " [ 19.7795     17.70028    98.74979   109.570755 ]\n",
      " [ 15.4534645   8.970606   96.28041   109.3444   ]\n",
      " [ 20.922325    7.666227   94.002014  106.296814 ]\n",
      " [ 15.112482    8.44735    95.62698   108.48642  ]\n",
      " [ 15.715533    9.249367   97.57344   109.235435 ]\n",
      " [ 15.204657   16.361008   91.58554   108.7861   ]\n",
      " [ 22.48999    24.781101  100.9282    106.44222  ]] (37, 4)\n",
      "\n",
      "[0.9982658  0.99601245 0.9883307  0.98501146 0.98303497 0.98025644\n",
      " 0.97972643 0.9542693  0.94297296 0.94085157 0.93217695 0.93036777\n",
      " 0.916698   0.90278006 0.86653394 0.8630215  0.83289486 0.8222067\n",
      " 0.7981987  0.7577081  0.7335436  0.64105785 0.6294033  0.62816423\n",
      " 0.6034388  0.5597918  0.5130633  0.468233   0.2894532  0.2783292\n",
      " 0.19154097 0.12219498 0.10297687 0.10001789 0.08182842 0.06474739\n",
      " 0.03068425] (37,)\n",
      "Tensor in gpu\n",
      "test [[[ 69.  35.  14.]\n",
      "  [ 67.  34.  14.]\n",
      "  [ 67.  33.  14.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[ 67.  35.  14.]\n",
      "  [ 67.  34.  14.]\n",
      "  [ 65.  34.  14.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[ 66.  34.  14.]\n",
      "  [ 64.  32.  14.]\n",
      "  [ 66.  34.  15.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[150. 122. 100.]\n",
      "  [165. 138. 111.]\n",
      "  [158. 129. 101.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[161. 139. 116.]\n",
      "  [165. 141. 116.]\n",
      "  [157. 128. 102.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[166. 145. 122.]\n",
      "  [163. 140. 116.]\n",
      "  [155. 128. 101.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7fa90>\n",
      "[[  2.6743903   11.459742    73.94789    106.65276   ]\n",
      " [  1.9877357   11.193901    74.05244    107.110245  ]\n",
      " [  3.5649314   12.058948    74.81992    109.20913   ]\n",
      " [  4.2438755   11.410288    73.03996    108.94131   ]\n",
      " [  3.0353765   12.900539    73.81513    107.91107   ]\n",
      " [  3.7261868   15.967762    73.89247    106.94003   ]\n",
      " [  3.3541455   12.3961115   75.36427    107.13075   ]\n",
      " [  3.0496225   13.157364    75.69918    106.01918   ]\n",
      " [  2.9166422    9.975779    73.932396   104.52688   ]\n",
      " [  2.3773508   11.030132    73.02455    107.50705   ]\n",
      " [  3.3584714   10.3123255   73.33259    105.159744  ]\n",
      " [  3.7208996    9.887529    72.26125    107.583694  ]\n",
      " [  2.1091437   11.526666    72.42058    106.0032    ]\n",
      " [  3.157806    10.228405    69.94768    108.978355  ]\n",
      " [  1.5086961   10.897312    73.44133    105.067184  ]\n",
      " [  1.9173937    9.281007    71.95983    109.91966   ]\n",
      " [  3.2344666    9.600349    72.625374   111.1544    ]\n",
      " [  3.1182323   10.253946    75.02046    105.70321   ]\n",
      " [  2.3061743    9.621509    74.16092    106.91833   ]\n",
      " [  2.4337773    9.3679085   73.575264   105.9491    ]\n",
      " [  1.9226408    9.238512    72.525856   109.6631    ]\n",
      " [  5.1477647    8.116697    75.66594    109.1945    ]\n",
      " [  2.859548     7.1881986   73.69198    109.72334   ]\n",
      " [  2.0609217   11.255778    75.12724    105.935234  ]\n",
      " [  5.1216426    7.4471464   75.818596   106.6301    ]\n",
      " [  5.6289873    7.1683183   74.801025   113.207985  ]\n",
      " [  1.7341418   13.3908      74.83449    107.93981   ]\n",
      " [  2.032186    13.778383    73.90634    107.39961   ]\n",
      " [  1.9008179   16.838226    72.85666    109.387764  ]\n",
      " [  0.8893995   12.856195    74.619774   107.606     ]\n",
      " [  6.5150123   18.66764     77.02785    110.477585  ]\n",
      " [ -1.2131252   14.149062    71.14735    110.56912   ]\n",
      " [  0.8374424    2.698176    74.662964   108.0968    ]\n",
      " [ -0.32463694   5.940393    75.391205   112.31912   ]\n",
      " [  3.915697    11.777079    78.03089    112.18213   ]\n",
      " [ -0.51613      4.2840667   75.007034   109.958755  ]\n",
      " [ 11.20545      3.0897536   78.68738    107.03938   ]\n",
      " [  1.8240237    4.7296743   71.704056   108.86246   ]\n",
      " [ 12.675123    16.620026    80.60843    103.789566  ]] (39, 4)\n",
      "\n",
      "[0.9967366  0.99518895 0.98633087 0.9623591  0.9560224  0.9473669\n",
      " 0.9470717  0.9267479  0.89378345 0.8830531  0.88222826 0.8814209\n",
      " 0.86734617 0.8377072  0.8322405  0.79084504 0.7906744  0.7843883\n",
      " 0.7842246  0.75247496 0.7475546  0.73203033 0.68863595 0.59267205\n",
      " 0.44768837 0.44421896 0.37955362 0.37688568 0.33961967 0.3128488\n",
      " 0.16623256 0.13578539 0.0873738  0.07703251 0.06608953 0.05089548\n",
      " 0.03127971 0.02756943 0.02023203] (39,)\n",
      "Tensor in gpu\n",
      "test [[[206. 176.  63.]\n",
      "  [206. 177.  62.]\n",
      "  [208. 178.  65.]\n",
      "  ...\n",
      "  [226. 206. 124.]\n",
      "  [227. 206. 124.]\n",
      "  [227. 207. 124.]]\n",
      "\n",
      " [[207. 177.  65.]\n",
      "  [207. 177.  64.]\n",
      "  [208. 178.  66.]\n",
      "  ...\n",
      "  [226. 206. 123.]\n",
      "  [227. 207. 124.]\n",
      "  [227. 206. 124.]]\n",
      "\n",
      " [[208. 179.  71.]\n",
      "  [207. 178.  67.]\n",
      "  [207. 178.  65.]\n",
      "  ...\n",
      "  [226. 205. 123.]\n",
      "  [227. 206. 124.]\n",
      "  [227. 206. 124.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[187. 158.  65.]\n",
      "  [187. 158.  66.]\n",
      "  [188. 158.  67.]\n",
      "  ...\n",
      "  [179. 149.  53.]\n",
      "  [179. 148.  52.]\n",
      "  [179. 148.  52.]]\n",
      "\n",
      " [[186. 157.  64.]\n",
      "  [187. 157.  65.]\n",
      "  [187. 157.  66.]\n",
      "  ...\n",
      "  [180. 149.  55.]\n",
      "  [179. 149.  53.]\n",
      "  [180. 149.  53.]]\n",
      "\n",
      " [[185. 156.  62.]\n",
      "  [186. 156.  64.]\n",
      "  [186. 156.  65.]\n",
      "  ...\n",
      "  [180. 150.  56.]\n",
      "  [180. 150.  54.]\n",
      "  [180. 150.  54.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f640>\n",
      "[[ 23.636703    10.596561    93.744606   105.98069   ]\n",
      " [ 23.871101    10.786048    92.96669    107.345924  ]\n",
      " [ 23.64298      8.316101    93.85205    106.49631   ]\n",
      " [ 23.223665     9.893598    93.57889    105.94232   ]\n",
      " [ 24.549873     9.1244545   94.03735    107.386246  ]\n",
      " [ 22.868797    10.587515    92.54679    105.513626  ]\n",
      " [ 23.605473     9.4356365   93.29519    109.11741   ]\n",
      " [ 21.257515     6.834462    92.58721    107.30803   ]\n",
      " [ 22.529041     7.132346    94.07024    107.331505  ]\n",
      " [ 23.017853     8.267599    92.955505   104.82034   ]\n",
      " [ 22.550877     7.874546    91.93707    105.019295  ]\n",
      " [ 22.205225     8.706438    92.47623    106.25048   ]\n",
      " [ 23.326773    10.089981    93.53898    107.31005   ]\n",
      " [ 23.519863     8.243664    92.895615   104.35888   ]\n",
      " [ 24.585546    11.2689495   93.47705    109.202576  ]\n",
      " [ 23.577755     7.159433    94.08741    108.354935  ]\n",
      " [ 22.12554      8.04981     93.00731    107.56079   ]\n",
      " [ 23.06351      7.0232115   93.3277     110.465965  ]\n",
      " [ 22.278734     7.6501684   93.22768    107.64573   ]\n",
      " [ 21.809729     7.781513    93.80531    107.97748   ]\n",
      " [ 22.551136     7.521447    92.33101    106.01027   ]\n",
      " [ 23.73863      8.40829     92.80653    106.23854   ]\n",
      " [ 22.983633     6.9613175   94.15854    105.25774   ]\n",
      " [ 23.577682     5.9143476   92.47763    111.53854   ]\n",
      " [ 21.919184     5.2776175   92.886665   108.39948   ]\n",
      " [ 22.731668     5.140655    94.47508    105.82234   ]\n",
      " [ 26.343317    13.035114    95.46166    110.3132    ]\n",
      " [ 22.743734     7.9440904   96.27876    109.67854   ]\n",
      " [ 24.205227     9.230621    96.02249    108.68866   ]\n",
      " [ 23.03493      7.84796     95.02721    107.1285    ]\n",
      " [ 25.283583     9.924526    99.42944    114.10508   ]\n",
      " [ 21.224411     3.4952235   94.23839    109.75876   ]\n",
      " [ 19.520214     3.7744088   92.981735   109.53638   ]\n",
      " [ 20.707443     0.47602558  94.62422    113.62284   ]\n",
      " [ 21.054247     3.1449986   95.208855   108.64412   ]\n",
      " [ 24.942497     1.2224813   95.66056    110.61583   ]\n",
      " [ 21.099295    16.091934    88.098145   109.34078   ]\n",
      " [ 25.520464    -1.1306334   98.24353    111.76351   ]\n",
      " [ 24.45634      3.7542582   99.65024    117.533905  ]\n",
      " [ 20.248394     0.9088292   87.97337    105.63574   ]\n",
      " [ 28.807957    14.630128    99.03311    105.53035   ]] (41, 4)\n",
      "\n",
      "[0.9913003  0.98637426 0.98498976 0.97228754 0.9246328  0.91245455\n",
      " 0.90319735 0.8765881  0.8497267  0.8439134  0.83994246 0.8326437\n",
      " 0.828492   0.8129355  0.79442006 0.7917365  0.78570485 0.7771806\n",
      " 0.7704056  0.7540125  0.7448095  0.7308541  0.60833955 0.5959097\n",
      " 0.4558654  0.4357873  0.30354702 0.22538576 0.19569144 0.19489506\n",
      " 0.16709092 0.09824379 0.09700068 0.08257845 0.08053469 0.07335777\n",
      " 0.03140295 0.03122955 0.02760043 0.02570344 0.02208098] (41,)\n",
      "Tensor in gpu\n",
      "test [[[77. 42. 11.]\n",
      "  [75. 41. 10.]\n",
      "  [70. 35.  8.]\n",
      "  ...\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[80. 43. 12.]\n",
      "  [77. 43. 11.]\n",
      "  [70. 36.  9.]\n",
      "  ...\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[81. 44. 11.]\n",
      "  [78. 43. 10.]\n",
      "  [69. 36.  9.]\n",
      "  ...\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[42. 21.  8.]\n",
      "  [69. 35. 12.]\n",
      "  [91. 48. 16.]\n",
      "  ...\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 9.  6.  3.]\n",
      "  [17. 10.  4.]\n",
      "  [29. 17.  6.]\n",
      "  ...\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 6.  5.  2.]\n",
      "  [ 7.  6.  3.]\n",
      "  [ 7.  6.  3.]\n",
      "  ...\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f400>\n",
      "[[ 3.86743832e+00  9.81924629e+00  7.17003632e+01  1.02690414e+02]\n",
      " [ 2.83432722e+00  1.05151634e+01  7.21716003e+01  1.03188873e+02]\n",
      " [ 4.50231600e+00  1.10631065e+01  7.22608490e+01  1.03118660e+02]\n",
      " [ 4.46147060e+00  9.60920906e+00  7.22770844e+01  1.03330109e+02]\n",
      " [ 3.89266253e+00  1.04732399e+01  7.31464920e+01  1.03772240e+02]\n",
      " [ 4.78987932e+00  1.07960911e+01  7.26624222e+01  1.02046585e+02]\n",
      " [ 4.91519260e+00  1.19879074e+01  7.33074265e+01  1.02521935e+02]\n",
      " [ 3.95871210e+00  9.98601341e+00  7.06149521e+01  1.02869751e+02]\n",
      " [ 4.37968636e+00  1.30003014e+01  7.18824997e+01  1.04227928e+02]\n",
      " [ 6.10009956e+00  8.47324753e+00  7.41979141e+01  1.03591354e+02]\n",
      " [ 3.96806812e+00  7.87985325e+00  7.13883362e+01  1.02479118e+02]\n",
      " [ 3.10755110e+00  7.84669161e+00  7.22887268e+01  1.02526993e+02]\n",
      " [ 2.82535505e+00  7.75036764e+00  7.19851456e+01  1.02417007e+02]\n",
      " [ 2.00004911e+00  1.00447655e+01  7.15211563e+01  1.03456757e+02]\n",
      " [ 2.81424665e+00  8.17853165e+00  7.11772385e+01  1.01059059e+02]\n",
      " [ 1.03148890e+00  9.48941231e+00  7.19728775e+01  1.02916183e+02]\n",
      " [ 1.79505777e+00  6.63652039e+00  7.22876587e+01  1.03805847e+02]\n",
      " [ 1.51347923e+00  7.84758615e+00  7.03725433e+01  1.04535583e+02]\n",
      " [ 6.25003958e+00  8.45938301e+00  7.17286530e+01  1.04293800e+02]\n",
      " [ 1.95480108e+00  5.49568319e+00  7.31095657e+01  1.04079872e+02]\n",
      " [ 1.94955397e+00  6.89010096e+00  7.22093582e+01  1.02583252e+02]\n",
      " [ 2.09566212e+00  6.57798100e+00  7.26159134e+01  1.01899284e+02]\n",
      " [ 2.65693998e+00  6.02887964e+00  7.25554810e+01  1.03736328e+02]\n",
      " [ 1.03755045e+00  6.03880310e+00  7.19556808e+01  1.03890030e+02]\n",
      " [ 2.66817856e+00  8.09979153e+00  7.44552917e+01  1.04122444e+02]\n",
      " [ 4.52377844e+00  4.39491367e+00  7.41425629e+01  1.03260323e+02]\n",
      " [ 5.19794941e-01  1.17216740e+01  7.38530807e+01  1.05595276e+02]\n",
      " [ 1.35333872e+00  1.03919468e+01  7.61671524e+01  1.06084900e+02]\n",
      " [ 1.35115242e+00  1.60309906e+01  6.99012070e+01  1.06803284e+02]\n",
      " [ 7.72521019e-01  1.47539759e+00  7.24904480e+01  1.03373650e+02]\n",
      " [-4.65564728e-02  9.39916420e+00  7.41854019e+01  1.05768761e+02]\n",
      " [ 3.06028032e+00  5.23443222e+00  7.01047134e+01  1.03017044e+02]\n",
      " [-2.59280968e+00  2.22435665e+00  7.28664703e+01  1.03550598e+02]\n",
      " [ 1.31083736e+01  3.12898684e+00  7.65677490e+01  1.00364716e+02]\n",
      " [-9.33996677e-01  3.42764854e+00  7.37865067e+01  1.05862503e+02]\n",
      " [-4.10630894e+00  1.18474636e+01  7.14123993e+01  1.07909882e+02]\n",
      " [-1.73688555e+00  1.59534960e+01  6.77849274e+01  9.98753510e+01]\n",
      " [ 9.85972214e+00  1.85022087e+01  7.66867752e+01  1.07913376e+02]\n",
      " [-3.70107269e+00 -2.90450907e+00  7.20009995e+01  1.02903107e+02]\n",
      " [ 1.59942513e+01  1.45881443e+01  7.94935303e+01  9.95842972e+01]\n",
      " [ 2.16411133e+01  6.47140980e+00  8.27635193e+01  9.47609863e+01]] (41, 4)\n",
      "\n",
      "[0.9960891  0.9948644  0.9895259  0.97076225 0.95876765 0.9484484\n",
      " 0.9050781  0.89505416 0.85946614 0.78768    0.78591806 0.76394403\n",
      " 0.7323112  0.73211455 0.73171806 0.71725875 0.7127012  0.67501175\n",
      " 0.65782285 0.6530495  0.65142983 0.62497604 0.55666524 0.5441686\n",
      " 0.4016639  0.36351502 0.15061614 0.1396132  0.12615472 0.10347675\n",
      " 0.0990537  0.09629574 0.07774724 0.07514581 0.07050617 0.04475033\n",
      " 0.04248951 0.03618615 0.03348597 0.02968286 0.02178053] (41,)\n",
      "Tensor in gpu\n",
      "test [[[ 70.  64.  53.]\n",
      "  [ 65.  62.  50.]\n",
      "  [ 60.  55.  43.]\n",
      "  ...\n",
      "  [240. 241. 239.]\n",
      "  [241. 241. 239.]\n",
      "  [241. 241. 239.]]\n",
      "\n",
      " [[ 72.  65.  51.]\n",
      "  [ 66.  61.  50.]\n",
      "  [ 63.  58.  46.]\n",
      "  ...\n",
      "  [241. 241. 239.]\n",
      "  [242. 242. 239.]\n",
      "  [242. 242. 239.]]\n",
      "\n",
      " [[ 70.  64.  52.]\n",
      "  [ 62.  54.  43.]\n",
      "  [ 72.  67.  53.]\n",
      "  ...\n",
      "  [242. 242. 239.]\n",
      "  [242. 242. 239.]\n",
      "  [243. 243. 240.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[127. 123. 123.]\n",
      "  [129. 123. 121.]\n",
      "  [129. 122. 117.]\n",
      "  ...\n",
      "  [113. 108.  94.]\n",
      "  [115. 111.  93.]\n",
      "  [117. 112.  94.]]\n",
      "\n",
      " [[124. 118. 119.]\n",
      "  [127. 119. 117.]\n",
      "  [128. 119. 113.]\n",
      "  ...\n",
      "  [117. 112. 101.]\n",
      "  [115. 111.  97.]\n",
      "  [115. 111.  95.]]\n",
      "\n",
      " [[117. 111. 113.]\n",
      "  [124. 116. 114.]\n",
      "  [126. 116. 111.]\n",
      "  ...\n",
      "  [123. 120. 108.]\n",
      "  [120. 117. 100.]\n",
      "  [120. 116. 101.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f1f0>\n",
      "[[  6.1084275   6.3893185  87.78468   108.105576 ]\n",
      " [  6.106081    5.4644876  88.61971   108.32204  ]\n",
      " [  7.5950804   5.808808   87.227684  105.67311  ]\n",
      " [  7.339297    6.9985046  87.30104   106.36473  ]\n",
      " [  5.849927    6.710434   87.00172   107.95434  ]\n",
      " [  6.863742    7.0671277  85.97056   105.95986  ]\n",
      " [  5.9507737   6.5486646  85.390076  106.03965  ]\n",
      " [  6.796671    6.398721   88.17339   108.45053  ]\n",
      " [  5.836946    6.712163   85.14435   106.49704  ]\n",
      " [  7.1584215   6.4229307  87.965385  108.70813  ]\n",
      " [  6.155071    5.9556537  87.03081   106.27562  ]\n",
      " [  7.0594406   6.5764556  86.730865  106.31317  ]\n",
      " [  6.4038115   6.9876533  87.84272   106.88695  ]\n",
      " [  6.37824     6.742047   86.42732   106.03319  ]\n",
      " [  5.9072413   6.86727    87.70323   107.405754 ]\n",
      " [  6.230036    5.9013333  87.11297   106.47862  ]\n",
      " [  6.5047016   6.4484053  86.6828    105.5244   ]\n",
      " [  6.868602    8.172143   86.011284  106.97558  ]\n",
      " [  6.591723    8.234978   85.969635  105.90249  ]\n",
      " [  6.460882    8.522768   87.46953   106.590996 ]\n",
      " [  5.5570164   6.0390067  84.892494  107.387505 ]\n",
      " [  6.751019   10.631645   86.40527   107.432686 ]\n",
      " [  8.060848    3.029552   87.88213   106.87951  ]\n",
      " [  6.547937    8.874613   88.3862    108.77344  ]\n",
      " [  8.081533   13.363009   87.100876  107.30074  ]\n",
      " [  7.0246167   4.370544   88.68251   107.9347   ]\n",
      " [  3.9538488   5.783023   85.03885   107.2974   ]\n",
      " [  6.8394322   8.245489   85.484375  105.416916 ]\n",
      " [  5.961475    4.4033384  86.96217   106.48065  ]\n",
      " [  3.9596167   3.314465   85.58999   107.681984 ]\n",
      " [  5.0777497  10.19212    86.709305  107.73404  ]\n",
      " [  5.1283817  11.725021   86.225655  107.04718  ]\n",
      " [  8.122879    4.361388   86.30681   106.8483   ]\n",
      " [  8.887444    0.9204984  88.85494   109.2637   ]\n",
      " [ 10.123592    2.4222217  87.89383   109.40911  ]\n",
      " [  8.750437   10.499326   88.80502   106.588455 ]\n",
      " [  5.8917336   4.497169   88.02219   107.07909  ]\n",
      " [  8.114668    3.1326585  87.268524  109.64338  ]\n",
      " [  8.965659    5.922018   89.09175   108.21095  ]\n",
      " [  9.169349   12.202756   90.52183   105.77701  ]\n",
      " [ 11.2299595   7.56786    90.27055   106.71872  ]\n",
      " [  4.199936    7.117336   85.037315  106.85234  ]] (42, 4)\n",
      "\n",
      "[0.9968125  0.9953577  0.9939803  0.9938736  0.99333054 0.99326056\n",
      " 0.9917174  0.9907644  0.9900017  0.9891228  0.98877627 0.9885443\n",
      " 0.98742825 0.9872067  0.98555136 0.9835443  0.980075   0.9800633\n",
      " 0.802259   0.77485126 0.7505302  0.7040273  0.69554687 0.6632363\n",
      " 0.6392244  0.63879627 0.63260984 0.6258753  0.6063345  0.5022031\n",
      " 0.443742   0.42560276 0.4095257  0.4015333  0.38867682 0.37164927\n",
      " 0.35976592 0.29546714 0.28282222 0.23477598 0.22307664 0.19814886] (42,)\n",
      "Tensor in gpu\n",
      "test [[[224. 225. 227.]\n",
      "  [235. 236. 238.]\n",
      "  [234. 234. 237.]\n",
      "  ...\n",
      "  [168. 135.  90.]\n",
      "  [167. 136.  92.]\n",
      "  [164. 134.  90.]]\n",
      "\n",
      " [[221. 222. 225.]\n",
      "  [233. 234. 237.]\n",
      "  [231. 232. 234.]\n",
      "  ...\n",
      "  [165. 131.  85.]\n",
      "  [164. 131.  88.]\n",
      "  [165. 133.  90.]]\n",
      "\n",
      " [[224. 225. 229.]\n",
      "  [236. 236. 239.]\n",
      "  [233. 234. 236.]\n",
      "  ...\n",
      "  [163. 129.  83.]\n",
      "  [161. 128.  84.]\n",
      "  [163. 130.  86.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[100. 112.  61.]\n",
      "  [106. 119.  64.]\n",
      "  [114. 126.  64.]\n",
      "  ...\n",
      "  [174. 134. 100.]\n",
      "  [168. 124.  90.]\n",
      "  [160. 115.  78.]]\n",
      "\n",
      " [[108. 121.  59.]\n",
      "  [107. 120.  58.]\n",
      "  [108. 120.  56.]\n",
      "  ...\n",
      "  [171. 131.  98.]\n",
      "  [161. 119.  89.]\n",
      "  [162. 127. 105.]]\n",
      "\n",
      " [[127. 139.  65.]\n",
      "  [119. 131.  62.]\n",
      "  [113. 126.  57.]\n",
      "  ...\n",
      "  [164. 123.  89.]\n",
      "  [158. 122.  92.]\n",
      "  [168. 149. 137.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f220>\n",
      "[[ 25.96212     7.0623846 101.648575  106.40502  ]\n",
      " [ 27.300447    7.806023  101.58992   106.818115 ]\n",
      " [ 26.036226    8.327547  101.42108   108.65988  ]\n",
      " [ 26.575539    6.6577425 102.35278   106.753876 ]\n",
      " [ 26.815477    7.2885213 101.647026  109.52232  ]\n",
      " [ 26.501003    5.6848164 102.63425   106.34415  ]\n",
      " [ 25.578066    6.6180787 101.267914  104.80594  ]\n",
      " [ 25.732048    6.632485  100.67983   106.08268  ]\n",
      " [ 25.77752     8.04707    99.136955  104.70515  ]\n",
      " [ 25.611431    5.7507825 100.855995  108.11359  ]\n",
      " [ 26.0904      6.3379455 100.7191    104.25581  ]\n",
      " [ 26.986607    7.3621345 100.385284  104.06885  ]\n",
      " [ 25.804426    5.741647  101.29859   104.880684 ]\n",
      " [ 25.846777    6.762638  101.034164  105.567665 ]\n",
      " [ 26.293571    7.0900655 100.62387   106.672745 ]\n",
      " [ 25.383135    7.2000747 101.20086   106.31792  ]\n",
      " [ 25.932276    6.525049  101.8411    106.65257  ]\n",
      " [ 26.138956    5.4444804 102.33404   105.49749  ]\n",
      " [ 28.34221    11.183494  102.12191   106.00774  ]\n",
      " [ 24.644556    2.463828   99.25725   109.39772  ]\n",
      " [ 25.739822    3.1231556  99.36695   108.925575 ]\n",
      " [ 26.381458   11.071045  100.872345  107.11985  ]\n",
      " [ 25.705444    4.311357   99.14012   104.113075 ]\n",
      " [ 25.810371    2.6007671 101.2649    110.84873  ]\n",
      " [ 26.28141     8.259809  103.38361   107.00123  ]\n",
      " [ 24.816303   10.262995   98.77697   105.6649   ]\n",
      " [ 25.724724    6.9314604 103.10559   106.54454  ]\n",
      " [ 24.671185    7.3623714 102.00402   105.4232   ]\n",
      " [ 23.608467    3.806409  101.725     106.98649  ]\n",
      " [ 23.375027    4.216552  100.73286   106.897804 ]\n",
      " [ 26.346165    8.646012  104.54173   110.251396 ]\n",
      " [ 25.680294    3.8919916 102.863945  107.86031  ]\n",
      " [ 24.422895    5.807643   98.2875    103.78564  ]\n",
      " [ 23.154842    4.079429   98.424164  105.63124  ]\n",
      " [ 25.240541   11.945183   99.52648   106.75424  ]\n",
      " [ 24.830654    0.6451683  99.50655   106.92378  ]\n",
      " [ 27.247173    3.4949164 103.76747   109.567955 ]\n",
      " [ 26.92408    10.95991   103.74871   106.26998  ]\n",
      " [ 23.229307   -0.1525302  99.76962   110.35812  ]\n",
      " [ 27.390915   11.612001  106.47191   106.54503  ]\n",
      " [ 23.664343    3.513939   99.238144  103.338684 ]\n",
      " [ 28.429916    6.963397  105.39897   108.34579  ]] (42, 4)\n",
      "\n",
      "[0.9967069  0.99580246 0.99219406 0.9921841  0.9906563  0.98896164\n",
      " 0.98007786 0.97896534 0.9781582  0.9774784  0.968548   0.9666196\n",
      " 0.96382    0.96164143 0.96113473 0.95907974 0.95900416 0.9521982\n",
      " 0.77496094 0.65728796 0.6150998  0.57438624 0.53153914 0.49977595\n",
      " 0.48275888 0.47919387 0.47328818 0.45279753 0.42865288 0.40913528\n",
      " 0.36166483 0.3548304  0.3378864  0.307064   0.28896046 0.24979532\n",
      " 0.24531993 0.24177006 0.24112739 0.19207919 0.16531675 0.07325304] (42,)\n",
      "Tensor in gpu\n",
      "test [[[ 39.  43.  22.]\n",
      "  [ 41.  46.  23.]\n",
      "  [ 40.  44.  21.]\n",
      "  ...\n",
      "  [ 69.  82.  28.]\n",
      "  [ 78.  92.  34.]\n",
      "  [ 78.  92.  36.]]\n",
      "\n",
      " [[ 40.  44.  22.]\n",
      "  [ 41.  43.  20.]\n",
      "  [ 40.  43.  20.]\n",
      "  ...\n",
      "  [ 66.  80.  27.]\n",
      "  [ 75.  90.  33.]\n",
      "  [ 75.  90.  34.]]\n",
      "\n",
      " [[ 39.  41.  20.]\n",
      "  [ 36.  38.  17.]\n",
      "  [ 38.  39.  17.]\n",
      "  ...\n",
      "  [ 65.  79.  27.]\n",
      "  [ 75.  90.  33.]\n",
      "  [ 77.  91.  34.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[124.  45.  59.]\n",
      "  [124.  46.  60.]\n",
      "  [122.  44.  58.]\n",
      "  ...\n",
      "  [110.  36.  49.]\n",
      "  [108.  36.  48.]\n",
      "  [105.  34.  46.]]\n",
      "\n",
      " [[121.  43.  57.]\n",
      "  [121.  44.  58.]\n",
      "  [122.  45.  59.]\n",
      "  ...\n",
      "  [109.  36.  48.]\n",
      "  [109.  36.  49.]\n",
      "  [106.  35.  47.]]\n",
      "\n",
      " [[121.  44.  58.]\n",
      "  [121.  44.  58.]\n",
      "  [121.  44.  56.]\n",
      "  ...\n",
      "  [108.  36.  47.]\n",
      "  [108.  35.  47.]\n",
      "  [106.  35.  47.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f370>\n",
      "[[ 28.236992   20.251045   95.25211   103.68923  ]\n",
      " [ 29.063536   19.859324   95.59122   103.34378  ]\n",
      " [ 27.602306   20.513878   94.97281   103.233406 ]\n",
      " [ 28.018791   20.514666   95.76875   103.546936 ]\n",
      " [ 28.56717    19.727518   95.58597   103.41896  ]\n",
      " [ 29.205866   23.166492   94.94336   104.4046   ]\n",
      " [ 27.68484    18.687977   94.56485   103.956764 ]\n",
      " [ 28.652601   24.619081   95.54314   104.786514 ]\n",
      " [ 28.57696    21.766983   95.134605  103.969734 ]\n",
      " [ 28.017797   20.535223   94.6025    103.460724 ]\n",
      " [ 26.46633    16.04497    96.30796   104.03815  ]\n",
      " [ 27.318983   12.787856   97.86061   105.47133  ]\n",
      " [ 26.158642   16.264458   96.51802   102.824    ]\n",
      " [ 26.25235    15.241844   96.407104  104.054    ]\n",
      " [ 24.828646   12.273959   96.10043   105.93646  ]\n",
      " [ 26.889622   16.536797   95.09251   102.74907  ]\n",
      " [ 26.728054   17.989521   96.41382   104.95068  ]\n",
      " [ 25.879965   15.424355   96.702415  103.74568  ]\n",
      " [ 26.63107    15.745064   95.78822   103.36597  ]\n",
      " [ 25.974089   15.150006   97.39657   104.59092  ]\n",
      " [ 26.385544   15.264866   96.82286   103.07999  ]\n",
      " [ 26.756083   15.8238735  97.63078   104.026276 ]\n",
      " [ 28.38867    25.584547   98.65059   105.53439  ]\n",
      " [ 27.543694   21.40036    97.107834  103.40733  ]\n",
      " [ 27.787506   10.309706   92.14843   104.514465 ]\n",
      " [ 27.013649   19.847754   98.5146    105.99851  ]\n",
      " [ 27.04065    20.548943   99.629265  109.655304 ]\n",
      " [ 26.035078   17.51392    97.01477   103.540215 ]\n",
      " [ 26.620258   17.803978   98.348724  104.62629  ]\n",
      " [ 25.99088    10.923      94.38571   104.17216  ]\n",
      " [ 26.006638   11.914528   93.048294  103.09979  ]\n",
      " [ 23.132793    5.1056943  92.13548   106.4901   ]\n",
      " [ 23.74482    12.327438   94.38585   103.84677  ]\n",
      " [ 25.263672   27.937159   89.79659   106.390434 ]\n",
      " [ 29.716715    8.332518   95.72395   104.45     ]\n",
      " [ 24.3004      7.343262   98.56284   109.20189  ]\n",
      " [ 24.005058    3.3737454  97.19879   107.39947  ]] (37, 4)\n",
      "\n",
      "[0.9982091  0.9978866  0.9971107  0.996935   0.9758301  0.95921177\n",
      " 0.93447423 0.9168707  0.9045357  0.87897843 0.4194086  0.40507883\n",
      " 0.38658625 0.38056412 0.36048618 0.3373289  0.33585793 0.33379674\n",
      " 0.33358306 0.3220646  0.31799862 0.28631806 0.28098255 0.1863418\n",
      " 0.11280935 0.10865725 0.10853772 0.09297425 0.08350968 0.08228593\n",
      " 0.07974641 0.04210741 0.02883677 0.02636153 0.02537492 0.02223274\n",
      " 0.02108211] (37,)\n",
      "Tensor in gpu\n",
      "test [[[ 64.  39.  25.]\n",
      "  [ 71.  43.  29.]\n",
      "  [ 74.  43.  30.]\n",
      "  ...\n",
      "  [107.  90.  73.]\n",
      "  [108.  91.  74.]\n",
      "  [103.  87.  72.]]\n",
      "\n",
      " [[ 65.  39.  27.]\n",
      "  [ 71.  42.  30.]\n",
      "  [ 72.  42.  29.]\n",
      "  ...\n",
      "  [106.  90.  73.]\n",
      "  [107.  91.  73.]\n",
      "  [106.  90.  73.]]\n",
      "\n",
      " [[ 68.  40.  27.]\n",
      "  [ 72.  43.  29.]\n",
      "  [ 70.  41.  27.]\n",
      "  ...\n",
      "  [106.  89.  72.]\n",
      "  [107.  90.  73.]\n",
      "  [108.  92.  74.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  2.   2.   3.]\n",
      "  [  2.   2.   4.]\n",
      "  [  2.   3.   4.]\n",
      "  ...\n",
      "  [ 98.  78.  50.]\n",
      "  [ 96.  77.  50.]\n",
      "  [ 96.  77.  51.]]\n",
      "\n",
      " [[  3.   3.   4.]\n",
      "  [  2.   3.   4.]\n",
      "  [  2.   2.   4.]\n",
      "  ...\n",
      "  [ 98.  79.  50.]\n",
      "  [ 98.  79.  50.]\n",
      "  [ 97.  79.  51.]]\n",
      "\n",
      " [[  2.   3.   4.]\n",
      "  [  2.   2.   3.]\n",
      "  [  2.   3.   4.]\n",
      "  ...\n",
      "  [100.  81.  49.]\n",
      "  [ 98.  79.  49.]\n",
      "  [ 97.  79.  50.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f490>\n",
      "[[  9.251324    8.936556   84.363464  107.54364  ]\n",
      " [  9.333198    8.410146   85.48359   108.55333  ]\n",
      " [  8.558945    8.704222   84.466194  108.01739  ]\n",
      " [  9.416374    9.794706   85.0093    108.1519   ]\n",
      " [  9.332407    9.339046   85.41476   106.77412  ]\n",
      " [ 10.0318985   8.648445   85.259186  108.972855 ]\n",
      " [ 10.200173    7.7169123  84.80957   106.313774 ]\n",
      " [  8.97393     8.207391   83.64307   106.84925  ]\n",
      " [  9.123657    8.880711   84.407394  106.851326 ]\n",
      " [  8.385072    8.662518   82.75109   106.58077  ]\n",
      " [  8.646066    9.112378   82.663055  106.41841  ]\n",
      " [  9.105879    8.867443   84.54471   108.4649   ]\n",
      " [  8.983614    8.642477   84.487526  106.113686 ]\n",
      " [  8.106297    7.8823466  84.813515  107.209145 ]\n",
      " [  6.209201    7.986618   83.81339   109.06816  ]\n",
      " [  8.186209    7.4923244  83.66437   106.76597  ]\n",
      " [  9.168364    9.960838   83.88957   107.69062  ]\n",
      " [  9.336191    8.960489   83.426346  105.245384 ]\n",
      " [  8.66429    12.412985   83.61457   107.05765  ]\n",
      " [ 10.347747   14.057047   84.53732   106.91972  ]\n",
      " [  5.392907    7.732126   80.80989   108.980156 ]\n",
      " [  7.455648   12.909378   83.00715   107.64093  ]\n",
      " [  7.266772   12.091051   82.9941    108.01354  ]\n",
      " [  3.810905    8.135597   80.84165   109.15949  ]\n",
      " [  7.904867   10.676109   83.02847   105.65     ]\n",
      " [  8.337263    9.763414   84.03462   105.90804  ]\n",
      " [  8.548186    9.681844   84.82771   105.96548  ]\n",
      " [ 10.195687    3.8348908  85.66098   107.79476  ]\n",
      " [ 11.472779   11.782166   85.696815  106.855515 ]\n",
      " [ 12.506808    3.488214   85.7151    108.7818   ]\n",
      " [  3.5782094   4.33076    82.22518   109.50923  ]\n",
      " [  9.023895   10.0935755  85.528755  107.46607  ]\n",
      " [  6.827326    3.7401724  85.22828   107.70234  ]\n",
      " [ 10.200594    3.2512026  85.14225   109.92171  ]\n",
      " [ 11.833906   13.601553   87.01556   106.29716  ]\n",
      " [  7.1317086   3.0306134  87.38536   109.37169  ]\n",
      " [  5.663297    4.2057304  86.36484   110.38358  ]\n",
      " [ 14.231478    8.114558   88.22832   105.55981  ]\n",
      " [ 12.167999    1.5902233  87.21971   110.582306 ]\n",
      " [  9.664457    4.2148194  84.52386   107.32511  ]\n",
      " [  4.9258537   8.070565   81.87572   108.04026  ]\n",
      " [ 11.068491    6.4899216  86.400116  107.38628  ]] (42, 4)\n",
      "\n",
      "[0.9979907  0.99607605 0.9954661  0.993704   0.99093366 0.9894593\n",
      " 0.9838096  0.98241526 0.981384   0.97460574 0.96974033 0.96904534\n",
      " 0.9634548  0.9602694  0.95596206 0.948228   0.93443406 0.9342887\n",
      " 0.82499707 0.77887213 0.7099375  0.6560051  0.6299099  0.5665705\n",
      " 0.5298651  0.50818056 0.47769243 0.43982282 0.41663873 0.38870728\n",
      " 0.38863653 0.29296178 0.2912635  0.2828279  0.28112638 0.27029282\n",
      " 0.25562602 0.17427903 0.16639838 0.16121224 0.15131499 0.12253036] (42,)\n",
      "Tensor in gpu\n",
      "test [[[32. 35. 22.]\n",
      "  [31. 34. 21.]\n",
      "  [30. 34. 21.]\n",
      "  ...\n",
      "  [39. 43. 25.]\n",
      "  [40. 45. 26.]\n",
      "  [41. 47. 27.]]\n",
      "\n",
      " [[31. 34. 21.]\n",
      "  [30. 34. 21.]\n",
      "  [30. 34. 21.]\n",
      "  ...\n",
      "  [41. 46. 27.]\n",
      "  [43. 49. 28.]\n",
      "  [45. 53. 29.]]\n",
      "\n",
      " [[31. 34. 21.]\n",
      "  [30. 34. 21.]\n",
      "  [30. 34. 21.]\n",
      "  ...\n",
      "  [44. 50. 30.]\n",
      "  [45. 52. 31.]\n",
      "  [47. 55. 32.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[57. 68. 44.]\n",
      "  [62. 73. 48.]\n",
      "  [73. 83. 57.]\n",
      "  ...\n",
      "  [52. 65. 49.]\n",
      "  [62. 75. 59.]\n",
      "  [67. 80. 64.]]\n",
      "\n",
      " [[55. 67. 42.]\n",
      "  [58. 70. 45.]\n",
      "  [63. 74. 49.]\n",
      "  ...\n",
      "  [53. 66. 51.]\n",
      "  [62. 75. 60.]\n",
      "  [69. 82. 66.]]\n",
      "\n",
      " [[58. 70. 45.]\n",
      "  [59. 71. 45.]\n",
      "  [59. 70. 45.]\n",
      "  ...\n",
      "  [48. 61. 46.]\n",
      "  [58. 72. 56.]\n",
      "  [67. 81. 65.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f2e0>\n",
      "[[ 17.494709   18.174454  100.07129   107.28488  ]\n",
      " [ 16.447048   17.509996   99.76136   106.89427  ]\n",
      " [ 16.74947    19.146883   99.68019   106.81848  ]\n",
      " [ 16.904392   19.24894   100.92973   105.312935 ]\n",
      " [ 16.383919   19.078884   99.57539   107.22786  ]\n",
      " [ 16.245836   18.40221    99.59399   107.96621  ]\n",
      " [ 17.10922    16.646412   98.80972   105.67489  ]\n",
      " [ 16.41373    18.081749   99.50554   106.74394  ]\n",
      " [ 16.77794    17.393139   98.48642   105.254036 ]\n",
      " [ 16.026358   16.584412   98.16438   105.24452  ]\n",
      " [ 17.361635   18.349598   99.63507   107.734634 ]\n",
      " [ 16.59463    17.260418   97.94613   105.85978  ]\n",
      " [ 16.39864    17.865398  100.07763   105.084885 ]\n",
      " [ 17.412905   17.786732   98.339005  106.317894 ]\n",
      " [ 16.017359   16.75708    99.612495  106.75265  ]\n",
      " [ 15.9922085  17.296146   99.26308   105.89672  ]\n",
      " [ 17.522066   18.488234   99.252975  106.16017  ]\n",
      " [ 16.638279   21.234524   99.0315    105.63333  ]\n",
      " [ 17.278198   15.785628   99.846     108.40034  ]\n",
      " [ 16.884743   18.321932   99.97263   105.03226  ]\n",
      " [ 17.057417   14.839689   98.42034   107.29716  ]\n",
      " [ 16.860752   18.837584   99.376595  104.6142   ]\n",
      " [ 17.044346   18.047031   98.521255  105.976135 ]\n",
      " [ 15.672571   15.993233   97.10365   106.49041  ]\n",
      " [ 16.826344   20.284489   99.759     105.53378  ]\n",
      " [ 18.009304   24.011217  100.55794   106.02403  ]\n",
      " [ 15.200758   15.786459   97.631325  106.60133  ]\n",
      " [ 15.262022   14.826899   99.374596  107.836205 ]\n",
      " [ 14.259829   14.106501   96.158325  106.92286  ]\n",
      " [ 17.51475    19.208843  101.56282   107.82233  ]\n",
      " [ 14.694308   22.910091   96.896706  108.772285 ]\n",
      " [ 13.786437    8.596422  100.77525   106.46786  ]\n",
      " [ 14.117069   10.668896   99.43184   106.92143  ]\n",
      " [ 18.890944   25.879894  104.149536  105.14369  ]\n",
      " [ 14.544636   10.716084  100.959625  107.41903  ]\n",
      " [ 14.217117   18.141603   95.62298   107.805565 ]\n",
      " [ 19.548958   22.660421  102.82759   105.90699  ]\n",
      " [ 19.543848    9.675085   95.41831   104.76336  ]\n",
      " [ 15.301481    8.713974  100.35804   108.6541   ]\n",
      " [ 18.942293    2.5811706 105.49895   108.19263  ]\n",
      " [ 13.3930435  26.677761   91.09798   105.86255  ]] (41, 4)\n",
      "\n",
      "[0.99821836 0.9975278  0.9954359  0.99332505 0.9910617  0.9897406\n",
      " 0.9769134  0.9762187  0.9761958  0.9723635  0.96732503 0.9656083\n",
      " 0.954103   0.9335701  0.92941904 0.92543864 0.9193778  0.87922955\n",
      " 0.8750389  0.8734037  0.8283605  0.8156083  0.8120509  0.8112463\n",
      " 0.7876311  0.72379905 0.6542152  0.46257344 0.44567657 0.44347134\n",
      " 0.31573287 0.1659021  0.16187018 0.1331061  0.12846991 0.0658257\n",
      " 0.0558903  0.04333766 0.03995981 0.02428063 0.02265159] (41,)\n",
      "Tensor in gpu\n",
      "test [[[173. 148.  96.]\n",
      "  [166. 140.  88.]\n",
      "  [156. 127.  75.]\n",
      "  ...\n",
      "  [124.  93.  66.]\n",
      "  [122.  93.  66.]\n",
      "  [122.  95.  65.]]\n",
      "\n",
      " [[171. 145.  94.]\n",
      "  [162. 135.  85.]\n",
      "  [149. 121.  71.]\n",
      "  ...\n",
      "  [120.  89.  61.]\n",
      "  [114.  87.  61.]\n",
      "  [117.  92.  62.]]\n",
      "\n",
      " [[168. 142.  91.]\n",
      "  [155. 128.  80.]\n",
      "  [143. 113.  67.]\n",
      "  ...\n",
      "  [111.  84.  57.]\n",
      "  [105.  81.  56.]\n",
      "  [110.  86.  60.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 93.  79.  72.]\n",
      "  [ 67.  47.  37.]\n",
      "  [ 52.  28.  15.]\n",
      "  ...\n",
      "  [ 78.  71.  44.]\n",
      "  [ 74.  65.  36.]\n",
      "  [ 76.  63.  33.]]\n",
      "\n",
      " [[ 98.  87.  82.]\n",
      "  [ 77.  61.  52.]\n",
      "  [ 57.  34.  22.]\n",
      "  ...\n",
      "  [ 73.  67.  40.]\n",
      "  [ 73.  63.  33.]\n",
      "  [ 78.  64.  32.]]\n",
      "\n",
      " [[102.  92.  89.]\n",
      "  [ 87.  75.  69.]\n",
      "  [ 64.  44.  35.]\n",
      "  ...\n",
      "  [ 60.  54.  31.]\n",
      "  [ 67.  59.  31.]\n",
      "  [ 77.  66.  35.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7fa90>\n",
      "[[  5.3251686  13.124777   91.46535   106.825264 ]\n",
      " [  4.710752   11.722294   91.67912   106.425224 ]\n",
      " [  4.7621684  13.148252   91.33717   105.85751  ]\n",
      " [  5.796915   11.312302   90.83324   104.65477  ]\n",
      " [  5.143272   12.686913   91.14573   105.09616  ]\n",
      " [  5.6531167  12.759781   90.15381   104.62997  ]\n",
      " [  5.889444   12.20372    90.223236  105.20456  ]\n",
      " [  3.993259   12.3139     89.35194   104.90866  ]\n",
      " [  4.412287   11.485928   89.61097   105.0528   ]\n",
      " [  5.1814437  11.873363   90.25871   104.82824  ]\n",
      " [  5.824626   12.153439   89.42001   105.64577  ]\n",
      " [  4.944399   12.713388   90.85341   105.64477  ]\n",
      " [  4.7174144  11.48786    90.74695   105.77657  ]\n",
      " [  5.8492126  11.169758   90.551094  108.23268  ]\n",
      " [  5.7229114  12.517319   91.390854  107.638214 ]\n",
      " [  4.735245   11.655985   89.65468   104.39057  ]\n",
      " [  4.5047927  13.149923   90.18535   106.35365  ]\n",
      " [  5.9717355  13.006149   89.492004  106.61667  ]\n",
      " [  4.426253   13.427139   89.3645    104.512115 ]\n",
      " [  5.2145185  14.178165   91.61826   105.08884  ]\n",
      " [  4.0385704  12.43749    91.724174  105.002205 ]\n",
      " [  5.2205567  13.339767   88.461655  105.07278  ]\n",
      " [  6.7383385  14.451061   91.39809   105.727    ]\n",
      " [  6.785506   15.810489   92.8866    104.57499  ]\n",
      " [  4.610169   17.048714   90.00827   105.86713  ]\n",
      " [  6.8764725   8.328571   91.55187   105.069214 ]\n",
      " [  4.648711   16.106947   90.06574   106.21379  ]\n",
      " [  5.333076    9.200498   92.38155   107.86092  ]\n",
      " [  6.5069447  17.969147   91.103035  105.26187  ]\n",
      " [  3.4517646   9.742993   88.5449    107.07799  ]\n",
      " [  4.340363   15.083759   89.67256   106.82585  ]\n",
      " [  4.118382    8.36643    90.2562    107.00288  ]\n",
      " [  1.8061996   9.745821   88.996     107.314255 ]\n",
      " [  7.3730593   6.0026374  91.83968   108.33825  ]\n",
      " [  6.171897   10.514563   92.32389   105.68906  ]\n",
      " [  6.2842293   8.096991   89.88747   107.16277  ]\n",
      " [ 10.131891   10.794275   92.66484   106.61602  ]\n",
      " [  3.9058704   6.355466   91.38338   106.50864  ]\n",
      " [  2.156942    5.361955   89.67835   106.837944 ]\n",
      " [  9.778835    5.323069   90.39152   107.33617  ]\n",
      " [  2.3756218  11.872281   87.73956   105.28407  ]\n",
      " [  6.6924396   5.2141213  89.95852   106.710144 ]] (42, 4)\n",
      "\n",
      "[0.9961541  0.9949227  0.99271387 0.99220204 0.9917191  0.9903205\n",
      " 0.98869497 0.9870952  0.98499113 0.9847621  0.9843478  0.98126614\n",
      " 0.9771394  0.97492075 0.9734605  0.97287714 0.97140163 0.9710994\n",
      " 0.90375113 0.88078827 0.7737191  0.7651415  0.72404814 0.65097684\n",
      " 0.6413674  0.6410354  0.6349812  0.61148506 0.5786393  0.5719101\n",
      " 0.55790466 0.52990913 0.47900188 0.38619027 0.36377892 0.30261225\n",
      " 0.28457797 0.24285628 0.22064069 0.10807371 0.09351821 0.0425244 ] (42,)\n",
      "Tensor in gpu\n",
      "test [[[  6.   5.   7.]\n",
      "  [  5.   5.   7.]\n",
      "  [  5.   5.   6.]\n",
      "  ...\n",
      "  [  7.   2.   2.]\n",
      "  [  6.   1.   1.]\n",
      "  [  6.   1.   1.]]\n",
      "\n",
      " [[  5.   5.   7.]\n",
      "  [  5.   5.   7.]\n",
      "  [  5.   5.   6.]\n",
      "  ...\n",
      "  [  7.   2.   2.]\n",
      "  [  7.   1.   1.]\n",
      "  [  7.   1.   1.]]\n",
      "\n",
      " [[  6.   5.   7.]\n",
      "  [  5.   5.   7.]\n",
      "  [  5.   5.   6.]\n",
      "  ...\n",
      "  [  7.   2.   2.]\n",
      "  [  7.   2.   2.]\n",
      "  [  7.   2.   2.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[121. 120. 119.]\n",
      "  [120. 118. 117.]\n",
      "  [118. 117. 115.]\n",
      "  ...\n",
      "  [ 17.   8.   4.]\n",
      "  [ 16.   8.   4.]\n",
      "  [ 16.   6.   3.]]\n",
      "\n",
      " [[122. 121. 119.]\n",
      "  [121. 120. 118.]\n",
      "  [119. 118. 116.]\n",
      "  ...\n",
      "  [ 14.   6.   3.]\n",
      "  [ 13.   5.   3.]\n",
      "  [ 12.   4.   2.]]\n",
      "\n",
      " [[123. 121. 120.]\n",
      "  [122. 121. 119.]\n",
      "  [120. 119. 117.]\n",
      "  ...\n",
      "  [ 12.   4.   2.]\n",
      "  [ 12.   3.   2.]\n",
      "  [ 12.   2.   2.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0039\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f640>\n",
      "[[ 43.06708     13.975229   103.36857    106.07687   ]\n",
      " [ 43.077816    13.232462   104.477135   105.39586   ]\n",
      " [ 42.213985    12.82453    103.91702    106.84462   ]\n",
      " [ 43.881283    16.415722   104.12041    106.33173   ]\n",
      " [ 42.665356    13.914627   103.31868    106.14841   ]\n",
      " [ 42.851498    15.7512455  103.36308    105.204865  ]\n",
      " [ 43.153736    15.463161   103.18878    104.23393   ]\n",
      " [ 43.209946    15.057924   103.71833    107.75909   ]\n",
      " [ 42.658527    11.393178   104.75858    107.960075  ]\n",
      " [ 40.87433     10.711683   102.33101    105.20232   ]\n",
      " [ 40.605976     6.276025   102.223526   110.87717   ]\n",
      " [ 41.458225     7.088877   103.10543    109.02037   ]\n",
      " [ 40.808537     7.497064   105.48034    103.84083   ]\n",
      " [ 42.056816    10.05496    104.25502    104.37745   ]\n",
      " [ 44.264343    19.521378   104.57427    107.88706   ]\n",
      " [ 41.47944     10.045687   103.2516     105.2203    ]\n",
      " [ 39.986767     9.585954   104.33054    105.77471   ]\n",
      " [ 42.260925     6.992323   104.60542    109.955414  ]\n",
      " [ 41.13311     11.874767   104.194916   104.639114  ]\n",
      " [ 39.7013      10.636723   104.81284    105.45586   ]\n",
      " [ 40.286064     7.124522   105.088264   106.354126  ]\n",
      " [ 42.18554      9.974096   105.48644    104.33411   ]\n",
      " [ 41.770035     8.462156   106.859085   103.29376   ]\n",
      " [ 40.897976    10.312662   103.50339    106.85341   ]\n",
      " [ 39.480797     6.5316315  104.25246    105.191154  ]\n",
      " [ 40.810642     3.3124523  102.571815   109.40217   ]\n",
      " [ 39.952503    20.930595    99.053      107.24543   ]\n",
      " [ 39.247215     8.9663     104.69224    103.608665  ]\n",
      " [ 39.80149     10.986763   107.83899    107.99455   ]\n",
      " [ 35.494106     2.1507702   98.14211    103.68202   ]\n",
      " [ 39.65711     14.477728   106.02376    109.57471   ]\n",
      " [ 38.57444     13.535727   104.99832    106.83367   ]\n",
      " [ 41.40194      0.32833195 105.828186   109.342735  ]] (33, 4)\n",
      "\n",
      "[0.9857782  0.9800494  0.9711482  0.93544376 0.88347775 0.8624087\n",
      " 0.84465265 0.8150726  0.6316184  0.52070653 0.41818693 0.33025184\n",
      " 0.2649941  0.25564685 0.23582233 0.2119373  0.20538588 0.20366669\n",
      " 0.20325626 0.20232338 0.19163252 0.19157016 0.18699521 0.17742237\n",
      " 0.13552272 0.13272023 0.09799357 0.08980996 0.04721981 0.04252783\n",
      " 0.0370091  0.03291326 0.03149702] (33,)\n",
      "Tensor in gpu\n",
      "test [[[138. 156. 158.]\n",
      "  [137. 155. 157.]\n",
      "  [136. 154. 156.]\n",
      "  ...\n",
      "  [121.  89.  68.]\n",
      "  [125.  90.  70.]\n",
      "  [122.  87.  67.]]\n",
      "\n",
      " [[138. 156. 158.]\n",
      "  [137. 155. 157.]\n",
      "  [136. 154. 156.]\n",
      "  ...\n",
      "  [132. 101.  81.]\n",
      "  [121.  88.  69.]\n",
      "  [121.  88.  69.]]\n",
      "\n",
      " [[137. 155. 157.]\n",
      "  [137. 155. 157.]\n",
      "  [136. 154. 156.]\n",
      "  ...\n",
      "  [125.  98.  81.]\n",
      "  [104.  77.  60.]\n",
      "  [107.  80.  63.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[223. 226. 217.]\n",
      "  [223. 226. 217.]\n",
      "  [223. 226. 217.]\n",
      "  ...\n",
      "  [  8.  11.  16.]\n",
      "  [  9.  12.  17.]\n",
      "  [ 10.  13.  18.]]\n",
      "\n",
      " [[228. 231. 222.]\n",
      "  [228. 231. 222.]\n",
      "  [227. 230. 221.]\n",
      "  ...\n",
      "  [  8.  11.  16.]\n",
      "  [  9.  12.  17.]\n",
      "  [ 10.  13.  18.]]\n",
      "\n",
      " [[232. 235. 226.]\n",
      "  [232. 235. 226.]\n",
      "  [230. 233. 224.]\n",
      "  ...\n",
      "  [ 11.  14.  19.]\n",
      "  [ 11.  14.  19.]\n",
      "  [ 12.  15.  20.]]] (1200, 1600, 3)\n",
      "torch.Size([1, 3, 1200, 1600])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f400>\n",
      "[[1054.4619    274.2902   1243.742     539.3539  ]\n",
      " [1054.3895    276.70245  1242.1023    542.2662  ]\n",
      " [ 633.1747    346.006     840.0192    658.1032  ]\n",
      " ...\n",
      " [ 860.3392    116.78042   955.2087    251.7895  ]\n",
      " [1234.0321     62.69602  1269.4814    108.25069 ]\n",
      " [1462.7709     52.721966 1478.3484     71.53779 ]] (500, 4)\n",
      "\n",
      "[0.9998429  0.9998241  0.99981815 0.99979705 0.9997819  0.99977905\n",
      " 0.9997646  0.99973184 0.999728   0.9997211  0.9996586  0.99964464\n",
      " 0.9996182  0.99961334 0.9996069  0.9995933  0.99958056 0.9995776\n",
      " 0.9995407  0.9994413  0.99941623 0.99940217 0.99939823 0.99938655\n",
      " 0.99937683 0.99937457 0.9993591  0.9993451  0.9993412  0.99934036\n",
      " 0.99933714 0.9993273  0.99932516 0.99931645 0.99919695 0.99918\n",
      " 0.9991721  0.99915445 0.9991492  0.9991491  0.99914706 0.99914527\n",
      " 0.9991437  0.99914145 0.99913365 0.9991185  0.99911517 0.99911433\n",
      " 0.99910897 0.99907565 0.99906987 0.9990613  0.9990571  0.99902654\n",
      " 0.9990208  0.99897194 0.99893874 0.9989188  0.9989127  0.9988888\n",
      " 0.9988864  0.9988702  0.998868   0.99883157 0.9988238  0.99879056\n",
      " 0.99878436 0.99878234 0.99877316 0.99875116 0.99874926 0.99874616\n",
      " 0.9987357  0.99872905 0.99871325 0.99870944 0.99866116 0.99865025\n",
      " 0.99864143 0.9986399  0.9985983  0.9984794  0.9984444  0.99841976\n",
      " 0.9983882  0.9983222  0.9982804  0.99812716 0.99806076 0.99802715\n",
      " 0.9979995  0.9979918  0.9979615  0.99793494 0.99784744 0.9978035\n",
      " 0.9977392  0.99772006 0.99758303 0.99756575 0.9974841  0.9974255\n",
      " 0.997391   0.9973483  0.9973394  0.9971373  0.99709857 0.997092\n",
      " 0.9970372  0.99701726 0.9967794  0.9967159  0.99668735 0.9966204\n",
      " 0.9965739  0.9965513  0.9964619  0.99637043 0.99616075 0.99604404\n",
      " 0.99599385 0.9959765  0.9957812  0.99559903 0.99559826 0.9953734\n",
      " 0.9953478  0.9953419  0.9953252  0.995285   0.995083   0.99490297\n",
      " 0.9948891  0.9947817  0.994739   0.99466264 0.9944616  0.994189\n",
      " 0.9939614  0.9938797  0.993612   0.99359    0.99321073 0.9931525\n",
      " 0.9929837  0.9924745  0.99196154 0.9919303  0.9916688  0.99103725\n",
      " 0.99096245 0.99058867 0.9904422  0.99014574 0.9901252  0.98990715\n",
      " 0.9898492  0.98942786 0.9889482  0.9887233  0.9883449  0.9880334\n",
      " 0.9879082  0.9878     0.9870024  0.9868838  0.98679477 0.98642933\n",
      " 0.9863987  0.98638505 0.9862322  0.9861152  0.98610187 0.9860844\n",
      " 0.9860145  0.9847831  0.984571   0.9844461  0.9842561  0.98414004\n",
      " 0.9838923  0.98326945 0.98309016 0.9824179  0.98227525 0.98226523\n",
      " 0.9822649  0.9818585  0.981669   0.9815152  0.9810306  0.980717\n",
      " 0.9792322  0.97898406 0.9788992  0.9777551  0.97671676 0.9766005\n",
      " 0.97657436 0.97586447 0.97536474 0.97513956 0.97488266 0.97403485\n",
      " 0.9738825  0.9735367  0.9733281  0.9730477  0.972998   0.97283506\n",
      " 0.9724629  0.9719283  0.9712008  0.97018045 0.9684664  0.96825904\n",
      " 0.96609527 0.96606624 0.9658345  0.96555537 0.9653171  0.96487147\n",
      " 0.9634978  0.9629478  0.961126   0.95942855 0.95834845 0.9574455\n",
      " 0.9571367  0.95707816 0.9533737  0.9530031  0.95129555 0.9487508\n",
      " 0.94855064 0.947906   0.94755805 0.9458867  0.9456849  0.9453441\n",
      " 0.9447891  0.94472307 0.944348   0.9438018  0.9432933  0.943068\n",
      " 0.9425256  0.9408334  0.9405396  0.9400489  0.9389075  0.9376332\n",
      " 0.93674725 0.93657905 0.93567044 0.9355536  0.93510634 0.9348787\n",
      " 0.9326692  0.9304044  0.9285953  0.92802775 0.9268963  0.9264412\n",
      " 0.9263798  0.92549706 0.9243119  0.9242899  0.92354935 0.9214457\n",
      " 0.921179   0.92080057 0.92066514 0.9185995  0.9143156  0.9136156\n",
      " 0.9134947  0.913208   0.91175836 0.9116855  0.90809405 0.90519375\n",
      " 0.9036309  0.9032688  0.9015635  0.90030724 0.8988884  0.89881045\n",
      " 0.89445883 0.89300483 0.89150184 0.89031494 0.88915485 0.8884311\n",
      " 0.8883361  0.8866393  0.88615716 0.8840212  0.88353294 0.88131297\n",
      " 0.8794985  0.8752199  0.8668504  0.8625434  0.8619823  0.8604332\n",
      " 0.8580598  0.85471666 0.8537915  0.85286397 0.85256094 0.85178167\n",
      " 0.8511511  0.85025376 0.8490803  0.84862626 0.8448092  0.83740187\n",
      " 0.83715975 0.834307   0.8340889  0.8315953  0.8295644  0.82923096\n",
      " 0.8286369  0.82745737 0.8240959  0.82186127 0.82180667 0.8214413\n",
      " 0.8169564  0.81686103 0.8095508  0.80883616 0.80463135 0.802867\n",
      " 0.7999764  0.79873496 0.79211724 0.79112047 0.7873956  0.7838872\n",
      " 0.7831129  0.7831051  0.7813532  0.77941394 0.7769357  0.7758111\n",
      " 0.77547246 0.7734521  0.77265364 0.7694128  0.769339   0.76228946\n",
      " 0.7616696  0.76021814 0.7595871  0.75626135 0.7546618  0.7535599\n",
      " 0.7530991  0.75286335 0.7431775  0.7419318  0.7413515  0.7366953\n",
      " 0.7323069  0.72783065 0.7241823  0.7234958  0.7214852  0.71880895\n",
      " 0.7182956  0.7145321  0.71362877 0.71047777 0.71009827 0.7071576\n",
      " 0.70383304 0.7025514  0.7016859  0.69329125 0.6930413  0.69176155\n",
      " 0.6911411  0.6860702  0.68292564 0.6764061  0.67593217 0.6740607\n",
      " 0.67077976 0.6693163  0.66803265 0.66612977 0.6639234  0.6622249\n",
      " 0.65774626 0.65509284 0.6538407  0.65159565 0.649336   0.64841396\n",
      " 0.6459748  0.6458588  0.63119096 0.6298321  0.6241993  0.6227046\n",
      " 0.6221621  0.6220476  0.6170736  0.61193216 0.6118703  0.6111121\n",
      " 0.6022203  0.6013424  0.60059464 0.5944172  0.58533823 0.583805\n",
      " 0.5835795  0.58354056 0.5830997  0.57984346 0.57913464 0.57854855\n",
      " 0.553403   0.5484851  0.54208934 0.5404869  0.5399041  0.53511816\n",
      " 0.5343469  0.530774   0.5290776  0.52512985 0.5242173  0.52066505\n",
      " 0.51863813 0.5178263  0.5163618  0.5157635  0.51137435 0.5098497\n",
      " 0.50964606 0.50229436 0.500544   0.500511   0.49879965 0.4964019\n",
      " 0.49576524 0.49396223 0.49126458 0.48627687 0.48333827 0.47572193\n",
      " 0.47345242 0.4728887  0.4722003  0.4691414  0.45823434 0.45713267\n",
      " 0.45499548 0.44800392 0.44054386 0.43815637 0.43735254 0.4365094\n",
      " 0.4270736  0.4223506  0.41446295 0.41334397 0.41234383 0.41191372\n",
      " 0.41088906 0.41029513 0.40599138 0.4050977  0.40423608 0.4005761\n",
      " 0.39764988 0.39339793 0.39213184 0.38996884 0.3882168  0.38778442\n",
      " 0.38441572 0.38377106 0.38322583 0.37912646 0.37795106 0.37368625\n",
      " 0.37335086 0.37043858 0.36550617 0.3650071  0.364289   0.3632809\n",
      " 0.36288774 0.35998952] (500,)\n",
      "Tensor in gpu\n",
      "test [[[ 80.  86.  63.]\n",
      "  [108. 113.  84.]\n",
      "  [134. 139. 108.]\n",
      "  ...\n",
      "  [149. 152. 122.]\n",
      "  [155. 157. 128.]\n",
      "  [160. 161. 131.]]\n",
      "\n",
      " [[ 77.  82.  58.]\n",
      "  [106. 111.  81.]\n",
      "  [128. 133.  98.]\n",
      "  ...\n",
      "  [152. 155. 129.]\n",
      "  [158. 160. 133.]\n",
      "  [160. 162. 134.]]\n",
      "\n",
      " [[ 73.  77.  53.]\n",
      "  [101. 106.  75.]\n",
      "  [126. 131.  98.]\n",
      "  ...\n",
      "  [154. 159. 135.]\n",
      "  [158. 162. 137.]\n",
      "  [162. 165. 141.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[111.  97.  55.]\n",
      "  [105.  92.  52.]\n",
      "  [ 97.  83.  47.]\n",
      "  ...\n",
      "  [134. 125. 100.]\n",
      "  [134. 125. 100.]\n",
      "  [135. 125. 100.]]\n",
      "\n",
      " [[111.  98.  58.]\n",
      "  [105.  93.  54.]\n",
      "  [ 98.  86.  49.]\n",
      "  ...\n",
      "  [134. 125. 101.]\n",
      "  [134. 125. 101.]\n",
      "  [133. 124. 100.]]\n",
      "\n",
      " [[109.  98.  59.]\n",
      "  [104.  93.  56.]\n",
      "  [ 94.  84.  51.]\n",
      "  ...\n",
      "  [134. 126. 102.]\n",
      "  [133. 125. 102.]\n",
      "  [133. 125. 101.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0046\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7fa90>\n",
      "[[ 28.293825   21.49372    98.33612   105.94236  ]\n",
      " [ 28.95103    21.251057   98.76795   105.20848  ]\n",
      " [ 29.203873   20.482918   98.770874  105.19024  ]\n",
      " [ 28.786844   20.77386    97.87683   105.48153  ]\n",
      " [ 29.007126   20.900375   98.14959   105.528854 ]\n",
      " [ 28.520733   20.238834   98.21902   106.92597  ]\n",
      " [ 29.062124   21.423758   98.112755  106.99807  ]\n",
      " [ 28.797585   21.316927   97.90522   106.743576 ]\n",
      " [ 27.637625   22.39358    97.42808   106.17229  ]\n",
      " [ 28.099771   20.714767   96.64859   104.93932  ]\n",
      " [ 27.58397    16.809824   99.14582   106.141525 ]\n",
      " [ 25.88669    16.919373   98.604164  105.29996  ]\n",
      " [ 27.482983   17.261827   99.11755   107.274765 ]\n",
      " [ 26.26887    17.687124   98.38319   106.99166  ]\n",
      " [ 29.661364   22.675415  101.70333   106.855385 ]\n",
      " [ 27.462181   17.36519    97.92798   104.64161  ]\n",
      " [ 27.572897   16.633713   98.43758   103.90687  ]\n",
      " [ 27.183332   15.987462  100.78315   106.10286  ]\n",
      " [ 27.061039   16.608267   97.993065  105.355736 ]\n",
      " [ 25.863827   15.144692   98.581375  108.76781  ]\n",
      " [ 27.208784   15.654934  100.1611    107.244606 ]\n",
      " [ 29.664303   21.976404  100.25305   105.61892  ]\n",
      " [ 25.44599    17.713667   98.92192   106.828224 ]\n",
      " [ 26.337042   17.89519    99.16421   105.40647  ]\n",
      " [ 28.474764   18.82977   101.129456  110.67458  ]\n",
      " [ 27.140184   17.583454  100.275475  107.22884  ]\n",
      " [ 25.842745   16.097137   98.96586   105.35939  ]\n",
      " [ 26.596033   16.304     100.7183    106.816315 ]\n",
      " [ 24.552944   11.0274315  98.10315   105.604996 ]\n",
      " [ 25.674679   10.599112   99.92892   110.43505  ]\n",
      " [ 27.589474   12.870686  102.28253   113.019    ]\n",
      " [ 24.838493   14.319584   93.92463   104.12044  ]\n",
      " [ 28.783562    9.796399   93.690285  104.949486 ]\n",
      " [ 32.927773    9.456078   98.74225   104.00427  ]\n",
      " [ 20.907173    7.9810038  94.81761   107.80976  ]\n",
      " [ 23.797      12.757591   98.27206   105.755745 ]] (36, 4)\n",
      "\n",
      "[0.99386287 0.9926541  0.9911771  0.99094135 0.92010164 0.9055741\n",
      " 0.8989144  0.83849865 0.7817074  0.6274419  0.5810574  0.57237214\n",
      " 0.5586043  0.55729085 0.5424525  0.51158684 0.49787033 0.4722655\n",
      " 0.449651   0.40813798 0.3915056  0.3839972  0.37138885 0.35233593\n",
      " 0.2531569  0.2442089  0.2257435  0.21144532 0.07209986 0.06769782\n",
      " 0.04099993 0.03685254 0.03221377 0.02727272 0.02627525 0.02317456] (36,)\n",
      "Tensor in gpu\n",
      "test [[[ 18.  19.  21.]\n",
      "  [ 19.  20.  21.]\n",
      "  [ 20.  20.  21.]\n",
      "  ...\n",
      "  [ 75.  51.  31.]\n",
      "  [ 74.  50.  32.]\n",
      "  [ 68.  45.  31.]]\n",
      "\n",
      " [[ 18.  19.  21.]\n",
      "  [ 18.  19.  20.]\n",
      "  [ 19.  19.  20.]\n",
      "  ...\n",
      "  [ 73.  50.  31.]\n",
      "  [ 73.  48.  31.]\n",
      "  [ 68.  45.  30.]]\n",
      "\n",
      " [[ 18.  18.  20.]\n",
      "  [ 19.  19.  21.]\n",
      "  [ 20.  20.  22.]\n",
      "  ...\n",
      "  [ 71.  48.  30.]\n",
      "  [ 71.  48.  30.]\n",
      "  [ 70.  47.  30.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 69.  17.  30.]\n",
      "  [ 67.  17.  28.]\n",
      "  [ 67.  17.  29.]\n",
      "  ...\n",
      "  [124. 112. 113.]\n",
      "  [129. 124. 122.]\n",
      "  [130. 126. 124.]]\n",
      "\n",
      " [[ 69.  18.  29.]\n",
      "  [ 68.  17.  29.]\n",
      "  [ 65.  16.  27.]\n",
      "  ...\n",
      "  [110.  72.  81.]\n",
      "  [120.  99. 103.]\n",
      "  [124. 115. 115.]]\n",
      "\n",
      " [[ 67.  17.  28.]\n",
      "  [ 68.  17.  28.]\n",
      "  [ 64.  16.  26.]\n",
      "  ...\n",
      "  [ 98.  37.  53.]\n",
      "  [103.  51.  65.]\n",
      "  [113.  80.  88.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f6d0>\n",
      "[[ 21.63877    14.749968   98.130554  105.38492  ]\n",
      " [ 21.60166    14.311489   98.08787   105.24946  ]\n",
      " [ 20.632933   14.240366   98.03796   104.88834  ]\n",
      " [ 21.671127   14.686317   98.3726    104.85225  ]\n",
      " [ 21.978527   14.333796   97.75779   106.71376  ]\n",
      " [ 20.90594    15.684431   97.138954  104.75496  ]\n",
      " [ 22.121992   17.055504   97.92808   105.016594 ]\n",
      " [ 20.38314    12.909334   98.291794  103.75299  ]\n",
      " [ 20.61668    12.5131035  96.74778   103.78941  ]\n",
      " [ 21.068577   13.448568   96.91075   104.03696  ]\n",
      " [ 21.217632   12.385397   97.19201   107.66803  ]\n",
      " [ 20.180693   13.112249   97.13249   104.74846  ]\n",
      " [ 19.901693   12.865328   97.56608   105.213425 ]\n",
      " [ 21.560123   13.574814   98.45886   104.96347  ]\n",
      " [ 19.926891   12.1521435  96.216835  104.31419  ]\n",
      " [ 20.954561   11.542207   97.7648    105.51062  ]\n",
      " [ 21.02499    12.618904   97.664154  105.53206  ]\n",
      " [ 21.844889   17.156645   97.522675  105.782875 ]\n",
      " [ 20.420277   12.508827   98.33484   105.65055  ]\n",
      " [ 20.297508   10.347603   95.71871   106.9612   ]\n",
      " [ 20.83939    13.044954   98.17703   105.5108   ]\n",
      " [ 19.761513   10.281297   96.21898   104.66048  ]\n",
      " [ 22.83126    19.255037   98.792725  106.91787  ]\n",
      " [ 21.818047   15.433144   98.59358   106.29262  ]\n",
      " [ 21.910017   11.727314   97.34286   104.50062  ]\n",
      " [ 21.13132    13.316466   99.141815  104.696686 ]\n",
      " [ 20.404219   12.300996   98.25163   103.956566 ]\n",
      " [ 19.884033    9.479233   96.54103   104.92029  ]\n",
      " [ 21.094044    9.751976   97.844376  103.1936   ]\n",
      " [ 22.041296   13.988945  101.25047   110.24512  ]\n",
      " [ 22.552132    6.2737517  94.85456   108.43997  ]\n",
      " [ 19.809462    6.2788253  98.26226   107.15022  ]\n",
      " [ 18.232153    6.8110504  96.80113   107.93869  ]\n",
      " [ 19.433216    5.5494294  99.46306   107.311226 ]\n",
      " [ 16.419912    3.4748259  97.87069   108.29926  ]\n",
      " [ 22.728992    1.4406505 100.25544   108.012474 ]\n",
      " [ 23.528585   21.93275   103.04859   106.22503  ]\n",
      " [ 18.718515   21.125921   93.69663   107.62815  ]\n",
      " [ 23.637781    3.3347826  98.345     107.962    ]\n",
      " [ 23.230202   18.440376   99.925674  104.09354  ]] (40, 4)\n",
      "\n",
      "[0.9979924  0.9971215  0.9943141  0.99198115 0.98919255 0.96359354\n",
      " 0.95931506 0.9537384  0.9496302  0.94463295 0.9416006  0.9408791\n",
      " 0.9285696  0.92153734 0.92131144 0.92015666 0.910925   0.90927714\n",
      " 0.904683   0.9004748  0.87871104 0.62542176 0.6097941  0.5843195\n",
      " 0.55837566 0.52168125 0.48681304 0.43272108 0.33627683 0.30569047\n",
      " 0.26431742 0.17587815 0.16313478 0.11454795 0.07383711 0.04787303\n",
      " 0.04284572 0.04262646 0.03813646 0.03812075] (40,)\n",
      "Tensor in gpu\n",
      "test [[[201. 167. 121.]\n",
      "  [198. 162. 116.]\n",
      "  [196. 159. 113.]\n",
      "  ...\n",
      "  [144. 150. 167.]\n",
      "  [144. 150. 166.]\n",
      "  [144. 150. 166.]]\n",
      "\n",
      " [[203. 168. 122.]\n",
      "  [199. 162. 116.]\n",
      "  [196. 159. 113.]\n",
      "  ...\n",
      "  [144. 151. 167.]\n",
      "  [144. 150. 167.]\n",
      "  [144. 150. 167.]]\n",
      "\n",
      " [[202. 167. 121.]\n",
      "  [200. 165. 117.]\n",
      "  [200. 165. 117.]\n",
      "  ...\n",
      "  [144. 150. 167.]\n",
      "  [144. 150. 167.]\n",
      "  [144. 150. 167.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[175.  67.  51.]\n",
      "  [146.  42.  29.]\n",
      "  [101.  20.  14.]\n",
      "  ...\n",
      "  [ 32.  29.  15.]\n",
      "  [ 28.  25.  13.]\n",
      "  [ 26.  23.  11.]]\n",
      "\n",
      " [[179.  79.  73.]\n",
      "  [151.  53.  44.]\n",
      "  [ 94.  25.  19.]\n",
      "  ...\n",
      "  [ 31.  28.  14.]\n",
      "  [ 28.  25.  13.]\n",
      "  [ 24.  21.  11.]]\n",
      "\n",
      " [[188.  90.  90.]\n",
      "  [178.  79.  76.]\n",
      "  [145.  54.  50.]\n",
      "  ...\n",
      "  [ 30.  27.  13.]\n",
      "  [ 28.  25.  13.]\n",
      "  [ 24.  21.  11.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f220>\n",
      "[[  9.013748    23.928411    79.22795    111.243805  ]\n",
      " [  8.731331    22.051327    77.89106    111.61691   ]\n",
      " [  9.201963    24.623594    79.474434   112.01125   ]\n",
      " [  9.277466    24.080494    79.34243    110.73028   ]\n",
      " [  9.256203    24.719875    77.71265    109.93259   ]\n",
      " [  7.825543    24.058342    77.85659    111.600624  ]\n",
      " [ 10.857262    25.28141     79.56364    110.6794    ]\n",
      " [  7.780959    21.555927    78.54048    112.21544   ]\n",
      " [  6.6868987   22.964273    77.11792    111.64745   ]\n",
      " [  8.849789    21.328356    79.695206   111.16846   ]\n",
      " [  7.823497    21.240446    79.96339    111.18282   ]\n",
      " [  6.988351    22.1426      79.18888    112.30133   ]\n",
      " [  7.5882444   21.096914    79.357925   112.160286  ]\n",
      " [  7.9900928   20.246428    77.24818    111.520805  ]\n",
      " [  7.925482    21.343204    79.69069    110.74807   ]\n",
      " [  7.384982    20.359512    78.30457    110.0983    ]\n",
      " [ 10.549694    19.118698    80.92393    110.62195   ]\n",
      " [  7.972005    21.561842    80.406944   111.26094   ]\n",
      " [  3.8490467   17.390125    76.88099    113.736275  ]\n",
      " [  5.469074    20.174324    80.27296    111.512405  ]\n",
      " [  6.1163116   25.757942    75.97838    111.66142   ]\n",
      " [  4.5523806   17.994377    76.53689    112.854095  ]\n",
      " [  5.3434267   19.871624    79.07074    113.56751   ]\n",
      " [  4.902799    19.346432    79.231384   112.0251    ]\n",
      " [ 13.434971    27.351992    81.898285   110.233536  ]\n",
      " [  7.230259    21.59959     77.061516   109.07463   ]\n",
      " [  6.9457364   19.554062    79.88368    110.233444  ]\n",
      " [  7.349998    20.621918    78.921875   109.222885  ]\n",
      " [  9.080706    20.450928    81.10135    111.69219   ]\n",
      " [ 15.707052    23.515722    83.469025   109.1275    ]\n",
      " [  8.575644    17.9207      81.40981    111.167694  ]\n",
      " [  3.62282     17.316925    76.101265   111.52199   ]\n",
      " [  0.37945795  20.864202    74.855194   114.17452   ]\n",
      " [  0.7845206   10.295305    77.25119    112.97554   ]\n",
      " [ 18.738007    30.90545     85.816055   113.93019   ]] (35, 4)\n",
      "\n",
      "[0.9967879  0.9964102  0.9880334  0.9834383  0.9706398  0.9436349\n",
      " 0.8986424  0.88334817 0.8768993  0.75671035 0.7389426  0.7136762\n",
      " 0.6832534  0.67914677 0.6336652  0.63247615 0.5839435  0.4283291\n",
      " 0.42687505 0.40492782 0.33663616 0.329003   0.32019114 0.27617034\n",
      " 0.2622164  0.25223622 0.25033224 0.2499191  0.2383885  0.15171152\n",
      " 0.10876752 0.05994663 0.05445564 0.04306018 0.02429452] (35,)\n",
      "Tensor in gpu\n",
      "test [[[197. 206. 218.]\n",
      "  [197. 206. 218.]\n",
      "  [198. 207. 219.]\n",
      "  ...\n",
      "  [133. 102.  66.]\n",
      "  [138. 108.  73.]\n",
      "  [141. 114.  81.]]\n",
      "\n",
      " [[198. 207. 218.]\n",
      "  [198. 207. 218.]\n",
      "  [198. 207. 218.]\n",
      "  ...\n",
      "  [130.  98.  62.]\n",
      "  [135. 102.  66.]\n",
      "  [140. 109.  74.]]\n",
      "\n",
      " [[198. 207. 218.]\n",
      "  [198. 207. 218.]\n",
      "  [198. 207. 218.]\n",
      "  ...\n",
      "  [127.  95.  61.]\n",
      "  [130.  98.  63.]\n",
      "  [136. 104.  68.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[189. 187. 185.]\n",
      "  [189. 186. 185.]\n",
      "  [188. 186. 184.]\n",
      "  ...\n",
      "  [184. 185. 186.]\n",
      "  [184. 186. 186.]\n",
      "  [184. 186. 186.]]\n",
      "\n",
      " [[189. 186. 185.]\n",
      "  [189. 186. 184.]\n",
      "  [189. 186. 184.]\n",
      "  ...\n",
      "  [185. 186. 186.]\n",
      "  [184. 185. 185.]\n",
      "  [185. 186. 186.]]\n",
      "\n",
      " [[190. 187. 184.]\n",
      "  [189. 186. 184.]\n",
      "  [189. 186. 184.]\n",
      "  ...\n",
      "  [185. 186. 186.]\n",
      "  [185. 186. 186.]\n",
      "  [184. 185. 185.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f1f0>\n",
      "[[ 24.497429    9.439211  102.9919    107.74977  ]\n",
      " [ 23.72688     8.643649  102.44888   107.99647  ]\n",
      " [ 23.962757    6.756036  103.41783   108.11693  ]\n",
      " [ 24.175089    7.987486  102.74779   107.858826 ]\n",
      " [ 23.089972    7.5078487 100.92799   108.067764 ]\n",
      " [ 23.657143    7.8269114 102.16811   107.202736 ]\n",
      " [ 24.827538    8.860092  102.14229   110.51123  ]\n",
      " [ 24.458286    9.271851  102.43551   110.43657  ]\n",
      " [ 24.304441    9.000533  100.926025  106.84798  ]\n",
      " [ 22.81666     6.969225  100.54465   110.27621  ]\n",
      " [ 24.273249    7.1897206 101.48106   105.80967  ]\n",
      " [ 24.410942    8.588828  101.64437   106.31894  ]\n",
      " [ 23.883171    6.0668144 102.762276  107.06171  ]\n",
      " [ 23.534353    7.3328114 101.96594   108.83092  ]\n",
      " [ 23.529636    7.9224877 101.12168   107.05643  ]\n",
      " [ 24.173458    7.031129  102.17331   108.23075  ]\n",
      " [ 23.744274    7.597557  101.30518   108.57557  ]\n",
      " [ 24.212402    8.384914  102.12295   109.1568   ]\n",
      " [ 25.76637    11.788044  101.799446  108.37347  ]\n",
      " [ 24.325006    8.540362  103.00994   108.407845 ]\n",
      " [ 23.37758     6.48384   103.23031   107.773926 ]\n",
      " [ 24.251       5.761043  101.77753   108.12756  ]\n",
      " [ 23.152155    6.9262633 102.31951   106.90277  ]\n",
      " [ 24.444618   11.0425    101.19801   108.87911  ]\n",
      " [ 21.999748    3.25664   100.191536  111.87019  ]\n",
      " [ 24.618708    8.287132  104.2638    112.389755 ]\n",
      " [ 22.303776   10.45343    99.623276  107.06134  ]\n",
      " [ 21.278849    4.8422337 101.63628   110.22426  ]\n",
      " [ 23.202454    4.7296476 103.00587   110.7235   ]\n",
      " [ 23.193882    3.513989  102.02982   106.82883  ]\n",
      " [ 21.98117     6.0993185  99.16977   107.05319  ]\n",
      " [ 23.954681    3.302055   99.14879   111.49284  ]\n",
      " [ 22.388186   11.700995  100.91674   108.943184 ]\n",
      " [ 24.28154     4.740122  104.84085   112.79998  ]\n",
      " [ 21.62646     5.0455194  98.64963   112.06474  ]\n",
      " [ 21.410069    4.570759  100.187775  110.76554  ]\n",
      " [ 25.140158    3.0847068 102.41169   113.04992  ]\n",
      " [ 23.08184     1.2705665 100.13257   110.97458  ]\n",
      " [ 22.02183     0.3287258 100.35619   112.92938  ]\n",
      " [ 25.871006   12.369262  104.737045  107.581505 ]\n",
      " [ 26.367804   13.340475  106.772675  108.522606 ]\n",
      " [ 27.674759    7.7424436 106.47487   108.992615 ]] (42, 4)\n",
      "\n",
      "[0.9911226  0.98982495 0.9831709  0.9820104  0.9802045  0.9800197\n",
      " 0.97889006 0.97880346 0.97805583 0.9764246  0.97408026 0.9724619\n",
      " 0.9719158  0.96820694 0.96303946 0.9619317  0.96145374 0.95373297\n",
      " 0.7465384  0.7267619  0.72433394 0.6738745  0.66643137 0.6159881\n",
      " 0.61085624 0.6102128  0.5549892  0.39669648 0.3884956  0.37721038\n",
      " 0.3770306  0.36714324 0.35710162 0.32479525 0.28173545 0.24622208\n",
      " 0.21698919 0.19707766 0.14233951 0.13844697 0.13079457 0.03826265] (42,)\n",
      "Tensor in gpu\n",
      "test [[[169. 161. 118.]\n",
      "  [171. 165. 125.]\n",
      "  [169. 161. 121.]\n",
      "  ...\n",
      "  [150. 119.  91.]\n",
      "  [152. 144. 144.]\n",
      "  [135. 130. 135.]]\n",
      "\n",
      " [[137. 126.  82.]\n",
      "  [136. 126.  84.]\n",
      "  [136. 126.  85.]\n",
      "  ...\n",
      "  [139.  99.  60.]\n",
      "  [143. 117.  98.]\n",
      "  [124. 112. 115.]]\n",
      "\n",
      " [[133. 122.  80.]\n",
      "  [133. 122.  80.]\n",
      "  [135. 125.  83.]\n",
      "  ...\n",
      "  [135.  95.  55.]\n",
      "  [142. 103.  69.]\n",
      "  [125.  99.  88.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 67.  51.  28.]\n",
      "  [ 70.  53.  28.]\n",
      "  [ 75.  57.  31.]\n",
      "  ...\n",
      "  [103.  36.  29.]\n",
      "  [107.  37.  30.]\n",
      "  [102.  32.  26.]]\n",
      "\n",
      " [[ 65.  50.  27.]\n",
      "  [ 76.  58.  30.]\n",
      "  [ 75.  57.  30.]\n",
      "  ...\n",
      "  [103.  36.  29.]\n",
      "  [105.  36.  29.]\n",
      "  [101.  32.  25.]]\n",
      "\n",
      " [[ 84.  66.  33.]\n",
      "  [102.  82.  40.]\n",
      "  [ 99.  78.  39.]\n",
      "  ...\n",
      "  [101.  34.  27.]\n",
      "  [101.  34.  27.]\n",
      "  [ 99.  32.  25.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f550>\n",
      "[[ 29.426748   17.103586  102.244934  105.08616  ]\n",
      " [ 29.672985   16.24314   102.38698   105.04549  ]\n",
      " [ 30.345295   17.001577  102.412056  104.52921  ]\n",
      " [ 29.706108   15.106697  102.84473   105.12254  ]\n",
      " [ 29.35682    17.06206   102.43176   107.13101  ]\n",
      " [ 30.28067    16.544287  102.28545   106.93179  ]\n",
      " [ 30.284048   18.508251  102.28616   104.78165  ]\n",
      " [ 27.667852   14.001776  102.06503   104.10596  ]\n",
      " [ 28.491528   13.561719  101.52801   103.85568  ]\n",
      " [ 27.058529   13.051651  100.839966  107.26175  ]\n",
      " [ 28.878693   14.467337  101.80599   104.28999  ]\n",
      " [ 28.07168    14.368629  101.23119   105.06209  ]\n",
      " [ 28.233994   14.590861  102.77777   105.18531  ]\n",
      " [ 28.11095    13.77684   101.57811   104.21422  ]\n",
      " [ 28.692993   13.792969  102.330154  105.632286 ]\n",
      " [ 29.44957    14.067925  101.09045   101.855286 ]\n",
      " [ 28.869326   12.57439   104.484344  104.17011  ]\n",
      " [ 29.076775   14.861191  102.317635  104.12337  ]\n",
      " [ 29.533714   18.238348  105.12977   105.38182  ]\n",
      " [ 29.370464   14.714352  103.521065  105.8428   ]\n",
      " [ 29.112509   18.015251  101.50108   105.681    ]\n",
      " [ 28.473343   17.702251  103.4853    105.48798  ]\n",
      " [ 28.32974    20.116936  100.487465  105.49008  ]\n",
      " [ 28.316944   15.368612  103.897125  105.44615  ]\n",
      " [ 27.36652     9.557638  101.125656  108.464554 ]\n",
      " [ 28.315645   18.542383   99.11614   103.94087  ]\n",
      " [ 28.456663   16.19983   104.190674  108.40238  ]\n",
      " [ 27.911713   13.267664  103.741684  104.75405  ]\n",
      " [ 27.17632    14.015007  102.5569    104.47751  ]\n",
      " [ 29.328856   10.123529  103.375465  109.13902  ]\n",
      " [ 31.1703      8.750541  102.211296  106.91842  ]\n",
      " [ 31.42436    12.204302  105.96207   106.40503  ]\n",
      " [ 26.201313    5.9556236 100.85971   108.46415  ]\n",
      " [ 25.563425    6.882721  101.3252    104.232895 ]\n",
      " [ 28.833931    7.672906   97.697845  104.78158  ]\n",
      " [ 25.48815     3.2177806 101.67279   107.29828  ]\n",
      " [ 25.324514    8.325965  104.758194  106.30909  ]\n",
      " [ 26.0928     12.219435   96.809784  102.45523  ]\n",
      " [ 26.583008    7.987182  104.88902   105.725105 ]] (39, 4)\n",
      "\n",
      "[0.99745184 0.9962845  0.9947126  0.9911265  0.9832894  0.9565387\n",
      " 0.9282776  0.8716832  0.85485816 0.85298085 0.84663373 0.8270759\n",
      " 0.8072117  0.80222094 0.801638   0.7890353  0.7723671  0.7250899\n",
      " 0.6900525  0.68811196 0.68666226 0.64903444 0.3591922  0.35434583\n",
      " 0.32886434 0.31766883 0.3106983  0.30033726 0.21957406 0.17618103\n",
      " 0.15010333 0.09490007 0.08325884 0.06889173 0.06319822 0.04622701\n",
      " 0.04246271 0.0403582  0.03281927] (39,)\n",
      "Tensor in gpu\n",
      "test [[[  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  ...\n",
      "  [106.  78.  56.]\n",
      "  [102.  72.  51.]\n",
      "  [ 94.  64.  43.]]\n",
      "\n",
      " [[  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  ...\n",
      "  [109.  81.  59.]\n",
      "  [106.  76.  55.]\n",
      "  [ 98.  68.  47.]]\n",
      "\n",
      " [[  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  ...\n",
      "  [104.  78.  57.]\n",
      "  [108.  80.  59.]\n",
      "  [103.  74.  53.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  ...\n",
      "  [208. 178. 144.]\n",
      "  [208. 186. 158.]\n",
      "  [207. 184. 159.]]\n",
      "\n",
      " [[  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  ...\n",
      "  [199. 166. 130.]\n",
      "  [191. 166. 138.]\n",
      "  [172. 143. 111.]]\n",
      "\n",
      " [[  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  ...\n",
      "  [151. 105.  76.]\n",
      "  [133.  88.  61.]\n",
      "  [136.  91.  60.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f3d0>\n",
      "[[ 33.0417      12.80562    100.886375   107.41626   ]\n",
      " [ 32.426285    12.394018   101.83388    107.884605  ]\n",
      " [ 33.73866     12.81779    100.34049    108.34344   ]\n",
      " [ 32.740303    11.721893   101.286934   107.678375  ]\n",
      " [ 31.67891     13.493974    99.27797    109.095375  ]\n",
      " [ 32.79374     12.661371    99.37746    109.13925   ]\n",
      " [ 33.15923     15.681517   101.528336   106.579994  ]\n",
      " [ 31.514486    11.041872   100.52059    107.31673   ]\n",
      " [ 32.569115    12.296844    99.24474    107.02309   ]\n",
      " [ 30.928764    10.717228   100.68158    107.32562   ]\n",
      " [ 32.42959     11.22813    100.086716   107.66064   ]\n",
      " [ 32.93387     11.331841    99.78429    106.266014  ]\n",
      " [ 32.734642    15.182934   103.5118     106.47099   ]\n",
      " [ 32.850056    14.843254   101.39858    107.93227   ]\n",
      " [ 32.210926    11.310993   100.530594   107.07117   ]\n",
      " [ 29.97535      9.719164   100.187355   107.95407   ]\n",
      " [ 31.765203    11.369783   101.53959    106.62099   ]\n",
      " [ 31.517406     9.147108   100.089264   105.827415  ]\n",
      " [ 30.500387    10.984974    99.20752    108.091835  ]\n",
      " [ 31.37754      9.7451725  100.356445   108.58916   ]\n",
      " [ 31.415295    11.480857    99.51466    107.69437   ]\n",
      " [ 31.966976    15.454884    99.36309    108.04502   ]\n",
      " [ 31.355877     7.625802    98.85874    110.661285  ]\n",
      " [ 29.462206    14.581502    96.47776    106.10764   ]\n",
      " [ 33.059593     8.087372   102.27959    109.278694  ]\n",
      " [ 34.208763    10.271513   103.49207    109.636635  ]\n",
      " [ 28.96355     15.295059    97.42742    107.854614  ]\n",
      " [ 30.62063      3.592352    99.38805    112.59833   ]\n",
      " [ 30.871454    13.234248   102.354385   107.47298   ]\n",
      " [ 30.637291    15.134729   102.56608    108.942665  ]\n",
      " [ 29.234995    11.43677     99.7369     106.894005  ]\n",
      " [ 29.063046     4.400214    95.38513    106.80544   ]\n",
      " [ 31.645336    10.008463   103.38595    107.92447   ]\n",
      " [ 26.421757     7.7719803   95.52536    105.112206  ]\n",
      " [ 28.615915     3.2794375   98.956406   110.84267   ]\n",
      " [ 27.552784     2.8850527  102.52471    109.13411   ]\n",
      " [ 27.65151      3.5621243   93.7986     105.97388   ]\n",
      " [ 28.072458     3.4450455  102.49878    108.719894  ]\n",
      " [ 35.98072     22.93702    105.09944    108.95841   ]\n",
      " [ 25.14249      4.660013    98.06586    109.1492    ]\n",
      " [ 29.316442    -0.45713663 101.133545   108.10656   ]\n",
      " [ 24.641508     5.3526325   92.85065    107.293335  ]] (42, 4)\n",
      "\n",
      "[0.9990606  0.9984315  0.9968071  0.99526995 0.99463755 0.9809038\n",
      " 0.9801072  0.89775246 0.85499775 0.84928983 0.8343287  0.82057047\n",
      " 0.8166334  0.80870765 0.78390276 0.7708126  0.7700182  0.76258254\n",
      " 0.7571911  0.7464097  0.6856822  0.6786284  0.47066107 0.38033316\n",
      " 0.33299306 0.26237115 0.26060525 0.2470128  0.19959626 0.19605522\n",
      " 0.16893432 0.16280466 0.16007762 0.09962854 0.0949201  0.06370853\n",
      " 0.05576288 0.04413542 0.04408903 0.03771681 0.0308354  0.02054353] (42,)\n",
      "Tensor in gpu\n",
      "test [[[142. 110.  73.]\n",
      "  [137. 104.  66.]\n",
      "  [146. 113.  74.]\n",
      "  ...\n",
      "  [139. 126. 102.]\n",
      "  [138. 124. 100.]\n",
      "  [136. 122.  98.]]\n",
      "\n",
      " [[145. 113.  74.]\n",
      "  [142. 110.  72.]\n",
      "  [148. 116.  75.]\n",
      "  ...\n",
      "  [139. 125. 102.]\n",
      "  [138. 124.  99.]\n",
      "  [137. 123.  98.]]\n",
      "\n",
      " [[145. 114.  76.]\n",
      "  [145. 114.  77.]\n",
      "  [147. 113.  73.]\n",
      "  ...\n",
      "  [140. 126. 102.]\n",
      "  [138. 124.  99.]\n",
      "  [138. 124. 100.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 10.   9.  10.]\n",
      "  [ 10.  10.  10.]\n",
      "  [ 10.  10.  11.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[  9.   8.   9.]\n",
      "  [ 10.  10.  10.]\n",
      "  [ 10.  10.  11.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[  9.   9.  10.]\n",
      "  [ 10.  10.  11.]\n",
      "  [  9.   9.  10.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f130>\n",
      "[[ 7.91636944e-01  5.39831114e+00  8.06765060e+01  1.03388870e+02]\n",
      " [ 5.43764114e-01  5.54511356e+00  8.13530731e+01  1.04844879e+02]\n",
      " [ 1.57496595e+00  5.66387129e+00  8.02937851e+01  1.06117302e+02]\n",
      " [ 1.83961153e+00  4.82927942e+00  8.03137207e+01  1.02072243e+02]\n",
      " [ 2.77130175e+00  4.59841299e+00  7.90587006e+01  1.02835388e+02]\n",
      " [ 1.79969072e+00  4.86620617e+00  8.10265961e+01  1.00422798e+02]\n",
      " [ 1.20877934e+00  4.56360912e+00  8.01806946e+01  1.04151001e+02]\n",
      " [ 1.29411840e+00  5.36884451e+00  7.93814697e+01  1.03252258e+02]\n",
      " [ 1.16871834e+00  4.61325312e+00  7.92975922e+01  1.06136444e+02]\n",
      " [ 2.70096970e+00  5.66237593e+00  8.04836578e+01  1.02819443e+02]\n",
      " [ 9.04086113e-01  6.22383738e+00  8.32089233e+01  1.03642387e+02]\n",
      " [-7.55691528e-02  5.23949242e+00  8.00066681e+01  1.02017433e+02]\n",
      " [ 1.66747808e+00  4.68139887e+00  7.87635269e+01  1.02853317e+02]\n",
      " [-6.79932117e-01  6.18504810e+00  8.05334702e+01  1.03076958e+02]\n",
      " [ 1.62548780e+00  5.37950897e+00  7.66607361e+01  1.06494034e+02]\n",
      " [ 1.10724497e+00  7.60699654e+00  8.24887619e+01  1.03805328e+02]\n",
      " [ 1.32321453e+00  6.55005312e+00  8.01898804e+01  1.05000038e+02]\n",
      " [ 3.02304983e+00  5.79879093e+00  8.18353043e+01  1.06550186e+02]\n",
      " [ 1.32581806e+00  6.08347702e+00  8.15149841e+01  1.03149612e+02]\n",
      " [ 1.02557421e+00  8.49559212e+00  8.03512421e+01  1.05223328e+02]\n",
      " [ 1.36545849e+00  3.90530968e+00  7.82871475e+01  1.06243958e+02]\n",
      " [ 1.17963314e+00  3.93329096e+00  7.84702530e+01  1.06013786e+02]\n",
      " [ 3.36456299e-02  6.72958326e+00  8.11529083e+01  1.02971916e+02]\n",
      " [ 7.48862267e-01  5.58800173e+00  7.84040070e+01  1.07393036e+02]\n",
      " [ 4.05007267e+00  3.69218731e+00  7.99548416e+01  1.08460236e+02]\n",
      " [ 2.37853909e+00  1.03604202e+01  7.98240814e+01  1.05089905e+02]\n",
      " [ 1.42173481e+00  5.85082150e+00  8.19332581e+01  1.04591133e+02]\n",
      " [ 1.19733381e+00  5.42606544e+00  8.09780197e+01  1.04779190e+02]\n",
      " [ 1.29733944e+00  6.13593817e+00  8.03397064e+01  1.04835846e+02]\n",
      " [ 1.19731045e+00  3.96466684e+00  7.97407303e+01  1.05002296e+02]\n",
      " [ 1.33577156e+00  3.63659859e+00  8.10982132e+01  1.06395958e+02]\n",
      " [ 1.01659536e+00  4.08614826e+00  8.06589890e+01  1.08741493e+02]\n",
      " [ 7.24077988e+00  4.71155643e-01  8.36316528e+01  1.06742188e+02]\n",
      " [ 4.60911751e-01  7.01059771e+00  8.50101776e+01  1.10380898e+02]\n",
      " [ 2.20062113e+00 -7.56712914e-01  8.70235291e+01  1.07299454e+02]\n",
      " [ 2.75658846e+00  2.08745766e+00  8.30300827e+01  1.03280731e+02]\n",
      " [ 4.62940168e+00  1.31753578e+01  8.32967148e+01  1.07977371e+02]\n",
      " [ 5.20457840e+00 -2.09450722e+00  8.92517929e+01  1.07563461e+02]\n",
      " [-2.87221193e+00 -4.11557817e+00  7.80859146e+01  1.05605743e+02]\n",
      " [ 7.38605690e+00  1.18258476e+01  8.69015656e+01  1.01863022e+02]\n",
      " [-3.89074326e+00  7.42478609e+00  7.76049042e+01  1.08923042e+02]\n",
      " [-2.02588081e-01  1.45473328e+01  7.65671082e+01  1.07873947e+02]\n",
      " [ 1.17330856e+01  6.05716801e+00  8.96579971e+01  1.01258095e+02]\n",
      " [ 1.92019415e+00  2.11102962e+00  7.56945114e+01  1.05245476e+02]\n",
      " [ 4.36555386e+00  3.49976635e+00  8.91321564e+01  1.10658577e+02]\n",
      " [ 8.70726871e+00  1.66364861e+01  8.90943909e+01  1.04454376e+02]] (46, 4)\n",
      "\n",
      "[0.99112016 0.9821817  0.9812695  0.9686637  0.96232057 0.9621784\n",
      " 0.9608257  0.9513041  0.94645053 0.9453636  0.94461584 0.937994\n",
      " 0.9361195  0.9270049  0.9043976  0.90102535 0.8949093  0.890864\n",
      " 0.853962   0.83444375 0.82870084 0.8271063  0.80179524 0.7638959\n",
      " 0.69228023 0.6431948  0.60485554 0.5339219  0.5268732  0.50036603\n",
      " 0.39872363 0.3894548  0.17838593 0.13974768 0.13831775 0.12926693\n",
      " 0.10144717 0.0819948  0.06373317 0.05586457 0.05224948 0.04393613\n",
      " 0.03551726 0.03484396 0.02601129 0.02155723] (46,)\n",
      "Tensor in gpu\n",
      "test [[[143. 166. 186.]\n",
      "  [143. 166. 185.]\n",
      "  [143. 166. 185.]\n",
      "  ...\n",
      "  [ 34.  24.  17.]\n",
      "  [ 33.  23.  17.]\n",
      "  [ 35.  25.  18.]]\n",
      "\n",
      " [[144. 167. 186.]\n",
      "  [143. 167. 186.]\n",
      "  [143. 167. 186.]\n",
      "  ...\n",
      "  [ 36.  25.  17.]\n",
      "  [ 34.  23.  17.]\n",
      "  [ 34.  23.  17.]]\n",
      "\n",
      " [[144. 167. 186.]\n",
      "  [144. 167. 186.]\n",
      "  [143. 167. 186.]\n",
      "  ...\n",
      "  [ 35.  25.  17.]\n",
      "  [ 34.  24.  17.]\n",
      "  [ 34.  24.  17.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 31.  32.  29.]\n",
      "  [ 31.  32.  29.]\n",
      "  [ 30.  31.  29.]\n",
      "  ...\n",
      "  [ 29.  29.  28.]\n",
      "  [ 28.  29.  27.]\n",
      "  [ 28.  30.  28.]]\n",
      "\n",
      " [[ 32.  32.  29.]\n",
      "  [ 30.  31.  28.]\n",
      "  [ 31.  31.  29.]\n",
      "  ...\n",
      "  [ 31.  25.  24.]\n",
      "  [ 29.  30.  29.]\n",
      "  [ 27.  29.  27.]]\n",
      "\n",
      " [[ 32.  32.  29.]\n",
      "  [ 32.  32.  30.]\n",
      "  [ 30.  31.  28.]\n",
      "  ...\n",
      "  [ 34.  16.  16.]\n",
      "  [ 29.  24.  23.]\n",
      "  [ 27.  28.  26.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0041\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f1f0>\n",
      "[[ 26.660406   14.27749   102.66902   108.0636   ]\n",
      " [ 27.076805   14.364661  102.66641   108.88936  ]\n",
      " [ 26.265238   13.662609  102.91533   108.14615  ]\n",
      " [ 26.07578    13.209508  103.748825  107.995415 ]\n",
      " [ 27.334702   13.174543  102.42853   109.78386  ]\n",
      " [ 28.103043   13.192725  102.07107   109.51847  ]\n",
      " [ 26.806181   14.318609  101.042595  108.44749  ]\n",
      " [ 25.678768   11.89873   101.54286   106.39025  ]\n",
      " [ 25.347603   12.556709  100.77901   107.184586 ]\n",
      " [ 25.350891   12.443739  101.210205  105.34192  ]\n",
      " [ 25.679302   10.440947  103.48338   107.53905  ]\n",
      " [ 26.509912   13.473933  100.53565   106.318756 ]\n",
      " [ 25.24922    12.716599  100.37335   106.29105  ]\n",
      " [ 25.173891   10.155951  100.06497   108.940414 ]\n",
      " [ 27.382914   16.525284  102.70647   108.873795 ]\n",
      " [ 25.966549   12.404833  101.76539   107.89411  ]\n",
      " [ 26.242653   11.639523  101.627815  107.25196  ]\n",
      " [ 26.902534   12.08717   102.88449   108.590614 ]\n",
      " [ 26.530327   12.476364  101.281876  108.36173  ]\n",
      " [ 25.825407   15.637314  102.285675  109.07255  ]\n",
      " [ 25.686186   14.0577755 103.37159   108.15512  ]\n",
      " [ 25.023823   11.999527  103.55183   106.981606 ]\n",
      " [ 24.89191    17.773535   99.569786  109.03805  ]\n",
      " [ 25.24606    11.612705  102.468056  106.81131  ]\n",
      " [ 27.96592    16.035995  104.68322   107.19518  ]\n",
      " [ 25.213484    8.126724   99.82373   111.70429  ]\n",
      " [ 25.290976   16.304585   98.663795  108.41744  ]\n",
      " [ 27.992353   17.105217  106.582375  108.23247  ]\n",
      " [ 26.328552   14.893742  103.66273   110.2226   ]\n",
      " [ 28.047058    8.820522  104.27285   112.416855 ]\n",
      " [ 25.210484    9.042126  101.59216   107.90549  ]\n",
      " [ 28.781597    4.8523607 102.57442   110.98053  ]\n",
      " [ 27.005104    5.040499   98.49979   108.28999  ]\n",
      " [ 23.624207   10.706607   97.501076  105.920044 ]\n",
      " [ 24.565035    6.0970187 103.569435  108.79936  ]\n",
      " [ 24.036537    8.17963   100.89503   107.7244   ]\n",
      " [ 25.063734    3.2254076 100.23849   112.65141  ]\n",
      " [ 25.496693    0.7068186 101.16079   110.16611  ]\n",
      " [ 30.505629    9.574158  106.54914   108.16456  ]\n",
      " [ 24.821573    6.274693  103.92382   108.85351  ]\n",
      " [ 24.1637      3.389944  101.806816  109.33723  ]\n",
      " [ 21.976345    5.7482624  99.08826   110.94792  ]\n",
      " [ 32.073997   23.14586   107.202644  111.38398  ]] (43, 4)\n",
      "\n",
      "[0.99570435 0.99263245 0.98897433 0.98864555 0.9750495  0.9518418\n",
      " 0.94463986 0.93987614 0.9317137  0.9259784  0.91655385 0.91274714\n",
      " 0.90354437 0.8996381  0.8931045  0.8803518  0.87372214 0.83477855\n",
      " 0.81993705 0.75325096 0.62108207 0.5867393  0.5213218  0.48625818\n",
      " 0.4801646  0.46684942 0.46653944 0.4423297  0.43701813 0.31954435\n",
      " 0.26533687 0.16207117 0.09893764 0.09328263 0.09112005 0.08892995\n",
      " 0.08737475 0.07603167 0.0725905  0.07208437 0.05678077 0.04168447\n",
      " 0.02301979] (43,)\n",
      "Tensor in gpu\n",
      "test [[[204. 188. 173.]\n",
      "  [205. 189. 175.]\n",
      "  [206. 191. 176.]\n",
      "  ...\n",
      "  [ 88.  58.  24.]\n",
      "  [ 90.  60.  25.]\n",
      "  [ 92.  62.  26.]]\n",
      "\n",
      " [[204. 188. 173.]\n",
      "  [205. 189. 174.]\n",
      "  [206. 191. 176.]\n",
      "  ...\n",
      "  [ 88.  57.  24.]\n",
      "  [ 89.  58.  24.]\n",
      "  [ 91.  61.  25.]]\n",
      "\n",
      " [[204. 188. 173.]\n",
      "  [205. 190. 175.]\n",
      "  [206. 191. 176.]\n",
      "  ...\n",
      "  [ 88.  58.  25.]\n",
      "  [ 89.  59.  25.]\n",
      "  [ 91.  61.  25.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[199. 182. 168.]\n",
      "  [201. 184. 170.]\n",
      "  [202. 185. 171.]\n",
      "  ...\n",
      "  [ 60.  43.  22.]\n",
      "  [ 57.  37.  19.]\n",
      "  [ 53.  28.  15.]]\n",
      "\n",
      " [[198. 181. 167.]\n",
      "  [200. 183. 169.]\n",
      "  [200. 183. 170.]\n",
      "  ...\n",
      "  [ 57.  34.  18.]\n",
      "  [ 52.  26.  15.]\n",
      "  [ 48.  18.  12.]]\n",
      "\n",
      " [[196. 178. 164.]\n",
      "  [198. 181. 167.]\n",
      "  [201. 183. 170.]\n",
      "  ...\n",
      "  [ 48.  20.  13.]\n",
      "  [ 47.  16.  11.]\n",
      "  [ 49.  13.  10.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f6d0>\n",
      "[[ 37.095966   15.625391  102.51164   108.21638  ]\n",
      " [ 36.292053   14.948223  103.31018   108.95698  ]\n",
      " [ 36.807022   15.925358  102.53566   109.18712  ]\n",
      " [ 37.94348    16.065903  102.18628   109.89023  ]\n",
      " [ 36.697197   15.000704  103.04222   108.05429  ]\n",
      " [ 37.053574   18.07742   102.786026  108.101326 ]\n",
      " [ 35.935436   16.817787  103.08586   107.83724  ]\n",
      " [ 36.10927    16.826296  104.39873   108.805626 ]\n",
      " [ 37.23012    13.474524  102.03932   108.895454 ]\n",
      " [ 35.186287   14.075369  102.13716   107.07807  ]\n",
      " [ 34.242542   13.307091  102.543625  107.49868  ]\n",
      " [ 37.144436   14.601139  103.69285   109.05347  ]\n",
      " [ 34.809906   13.490393  102.88478   107.358    ]\n",
      " [ 35.41354    14.502929  101.76116   106.90603  ]\n",
      " [ 36.41522    14.854029  101.73459   107.51708  ]\n",
      " [ 35.256523   19.02517   100.446556  108.87613  ]\n",
      " [ 35.13066    13.834669  102.19808   107.95466  ]\n",
      " [ 35.280693   12.408161  103.95491   108.434044 ]\n",
      " [ 34.58882    12.082623  103.865     107.43912  ]\n",
      " [ 34.789787   12.584904  103.39598   107.808395 ]\n",
      " [ 35.066467   10.540528  101.3032    109.958664 ]\n",
      " [ 34.175453   11.278115  102.426056  108.12347  ]\n",
      " [ 37.29449    10.127942  103.89875   110.09505  ]\n",
      " [ 35.204678   11.260147  102.54198   109.00963  ]\n",
      " [ 36.80213    11.411947  104.880615  109.52683  ]\n",
      " [ 36.31871     8.470692  102.18927   112.637695 ]\n",
      " [ 34.049664   14.369465  105.0685    108.432144 ]\n",
      " [ 34.092556   18.121273  104.59291   110.22327  ]\n",
      " [ 34.35831    14.753842  104.122406  108.31039  ]\n",
      " [ 37.88325    23.143938  105.671234  109.401505 ]\n",
      " [ 33.15642     6.6809173 100.95811   109.96645  ]\n",
      " [ 31.945662   16.924503  100.92254   108.40276  ]\n",
      " [ 32.4774     20.530146   96.200226  108.676254 ]\n",
      " [ 33.634224   17.760363   95.59407   106.45022  ]\n",
      " [ 34.107674    4.9868765  97.38655   106.56274  ]\n",
      " [ 37.619774   16.615074  106.81285   117.6958   ]] (36, 4)\n",
      "\n",
      "[0.99921596 0.9983701  0.9952237  0.99178606 0.9849562  0.984823\n",
      " 0.9429746  0.91132253 0.8864819  0.75892496 0.74081457 0.7194212\n",
      " 0.66403234 0.6625117  0.6505404  0.62248915 0.6059472  0.5863084\n",
      " 0.52483135 0.51283014 0.4847006  0.47887766 0.4135819  0.40453193\n",
      " 0.40063334 0.31731588 0.22856471 0.17472161 0.14849615 0.1420465\n",
      " 0.12262392 0.0732853  0.04992747 0.04790645 0.03165903 0.02016844] (36,)\n",
      "Tensor in gpu\n",
      "test [[[155. 177. 212.]\n",
      "  [155. 176. 212.]\n",
      "  [155. 176. 212.]\n",
      "  ...\n",
      "  [151. 173. 210.]\n",
      "  [152. 174. 210.]\n",
      "  [152. 173. 210.]]\n",
      "\n",
      " [[155. 176. 212.]\n",
      "  [155. 176. 212.]\n",
      "  [155. 177. 212.]\n",
      "  ...\n",
      "  [152. 174. 210.]\n",
      "  [152. 174. 210.]\n",
      "  [152. 174. 210.]]\n",
      "\n",
      " [[154. 175. 211.]\n",
      "  [154. 176. 212.]\n",
      "  [155. 176. 212.]\n",
      "  ...\n",
      "  [152. 174. 210.]\n",
      "  [151. 173. 210.]\n",
      "  [152. 174. 210.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 70.  78. 107.]\n",
      "  [ 72.  81. 110.]\n",
      "  [ 75.  85. 115.]\n",
      "  ...\n",
      "  [ 57.  57.  59.]\n",
      "  [ 56.  57.  58.]\n",
      "  [ 57.  57.  57.]]\n",
      "\n",
      " [[ 65.  71.  96.]\n",
      "  [ 66.  73.  99.]\n",
      "  [ 67.  74. 100.]\n",
      "  ...\n",
      "  [ 54.  55.  57.]\n",
      "  [ 56.  56.  57.]\n",
      "  [ 57.  57.  57.]]\n",
      "\n",
      " [[ 61.  66.  90.]\n",
      "  [ 62.  67.  92.]\n",
      "  [ 63.  69.  93.]\n",
      "  ...\n",
      "  [ 53.  54.  58.]\n",
      "  [ 55.  56.  58.]\n",
      "  [ 55.  55.  56.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f2b0>\n",
      "[[  8.463578   20.155663   89.981     104.713776 ]\n",
      " [  9.024786   20.423155   89.57535   104.36476  ]\n",
      " [  8.442263   19.342957   90.22385   103.73715  ]\n",
      " [  8.097986   20.210373   90.2734    103.82744  ]\n",
      " [  9.606655   19.02963    89.55575   105.65354  ]\n",
      " [  9.523189   19.573519   89.36609   104.8965   ]\n",
      " [  8.577192   18.010866   89.02878   103.38577  ]\n",
      " [  8.159593   17.67546    89.847565  102.384384 ]\n",
      " [  7.177117   18.037292   88.53235   103.85693  ]\n",
      " [  8.733889   17.980064   88.98664   102.438156 ]\n",
      " [  8.373526   18.263765   90.08731   104.29855  ]\n",
      " [  6.9292307  17.973692   87.35818   102.85261  ]\n",
      " [  9.992815   23.18271    90.87197   104.47243  ]\n",
      " [  8.5949135  21.116856   91.66378   104.11659  ]\n",
      " [  8.764189   20.369501   88.85647   104.12439  ]\n",
      " [  7.559015   18.288527   88.36539   103.36418  ]\n",
      " [  8.390329   22.45027    89.43919   104.81037  ]\n",
      " [  8.588104   18.551497   88.76187   103.53378  ]\n",
      " [  6.923396   17.859787   89.372116  104.03423  ]\n",
      " [  7.9710236  17.4504     87.62362   105.180565 ]\n",
      " [  8.032831   18.630877   89.815834  103.93297  ]\n",
      " [  8.937344   17.213495   90.860435  103.44456  ]\n",
      " [  9.000914   23.316492   89.03177   103.2259   ]\n",
      " [  7.7609754  19.377483   89.56602   103.84586  ]\n",
      " [  8.833567   19.608175   91.13007   103.0699   ]\n",
      " [  8.689768   18.51515    90.74583   103.973206 ]\n",
      " [  7.8704505  22.024006   87.34883   103.741936 ]\n",
      " [  8.735865   18.811134   88.86792   103.28528  ]\n",
      " [  8.237605   13.990901   88.53754   105.14534  ]\n",
      " [  5.403408   11.512733   87.194725  105.84134  ]\n",
      " [ 14.259775   15.200475   91.17038   104.307335 ]\n",
      " [  7.7408915  16.30607    89.28521   106.3904   ]\n",
      " [ 10.612032    9.412401   92.58321   107.73468  ]\n",
      " [  5.4925056  10.925814   91.07062   105.22481  ]\n",
      " [  5.062095   14.16474    86.577     105.50821  ]\n",
      " [ 12.077122   26.749886   94.039505  108.658005 ]\n",
      " [  5.138819   10.781715   91.02507   104.80391  ]\n",
      " [ 14.468124   10.655428   89.53715   103.8595   ]\n",
      " [  7.774123    9.585286   92.6973    105.19795  ]\n",
      " [  2.6811562   7.962008   86.835266  105.49877  ]\n",
      " [  5.089886   17.291126   82.43811   100.339294 ]\n",
      " [  2.9782891   7.0919313  93.67173   105.987015 ]\n",
      " [ 10.612669   10.835288   83.046104   98.3141   ]] (43, 4)\n",
      "\n",
      "[0.99772614 0.99735945 0.9964013  0.9962075  0.9505791  0.9409469\n",
      " 0.93979496 0.9395465  0.9339855  0.92534727 0.90663993 0.8960509\n",
      " 0.87804586 0.86084795 0.85367393 0.8485019  0.8446416  0.8417097\n",
      " 0.83240986 0.82832295 0.82703495 0.79171795 0.76156294 0.6187988\n",
      " 0.5837497  0.57759756 0.5039288  0.45287025 0.25501    0.12970205\n",
      " 0.12816285 0.12783653 0.12298994 0.08043338 0.05654712 0.05157025\n",
      " 0.04480266 0.03387858 0.0338467  0.03295575 0.03123913 0.02614151\n",
      " 0.02071761] (43,)\n",
      "Tensor in gpu\n",
      "test [[[ 55. 135.  72.]\n",
      "  [ 54. 135.  72.]\n",
      "  [ 54. 135.  72.]\n",
      "  ...\n",
      "  [ 82.  47.  24.]\n",
      "  [ 86.  51.  27.]\n",
      "  [ 88.  53.  28.]]\n",
      "\n",
      " [[ 55. 135.  73.]\n",
      "  [ 54. 135.  73.]\n",
      "  [ 54. 135.  73.]\n",
      "  ...\n",
      "  [ 81.  47.  24.]\n",
      "  [ 87.  52.  28.]\n",
      "  [ 89.  54.  29.]]\n",
      "\n",
      " [[ 55. 136.  73.]\n",
      "  [ 54. 135.  72.]\n",
      "  [ 55. 135.  73.]\n",
      "  ...\n",
      "  [ 81.  47.  25.]\n",
      "  [ 86.  52.  28.]\n",
      "  [ 89.  54.  29.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 79. 169.  96.]\n",
      "  [ 78. 168.  96.]\n",
      "  [ 78. 168.  95.]\n",
      "  ...\n",
      "  [ 97.  65.  39.]\n",
      "  [101.  69.  43.]\n",
      "  [103.  70.  45.]]\n",
      "\n",
      " [[ 78. 168.  96.]\n",
      "  [ 78. 168.  96.]\n",
      "  [ 78. 168.  95.]\n",
      "  ...\n",
      "  [100.  67.  41.]\n",
      "  [102.  69.  44.]\n",
      "  [105.  70.  46.]]\n",
      "\n",
      " [[ 78. 168.  96.]\n",
      "  [ 78. 168.  96.]\n",
      "  [ 78. 167.  95.]\n",
      "  ...\n",
      "  [103.  68.  43.]\n",
      "  [104.  69.  44.]\n",
      "  [106.  70.  46.]]] (112, 112, 3)\n",
      "torch.Size([1, 3, 112, 112])\n",
      "Forward time: 0.0040\n",
      "<layers.functions.prior_box.PriorBox object at 0x7f0475c7f220>\n",
      "[[ 3.43603210e+01  4.27641296e+00  1.05374786e+02  1.05164154e+02]\n",
      " [ 3.44861450e+01  6.25969601e+00  1.04822762e+02  1.08159317e+02]\n",
      " [ 3.49515343e+01  3.69025135e+00  1.06003296e+02  1.06688293e+02]\n",
      " [ 3.50325089e+01  6.71003342e+00  1.04688179e+02  1.05606903e+02]\n",
      " [ 3.50069618e+01  5.24781704e+00  1.04762657e+02  1.07406082e+02]\n",
      " [ 3.32077484e+01  3.85614634e+00  1.04158409e+02  1.04411964e+02]\n",
      " [ 3.43978119e+01  4.93065691e+00  1.06295021e+02  1.05306427e+02]\n",
      " [ 3.42786102e+01  3.02428818e+00  1.04308434e+02  1.07272270e+02]\n",
      " [ 3.29011269e+01  3.47466898e+00  1.04032539e+02  1.04937447e+02]\n",
      " [ 3.29056244e+01  3.71604967e+00  1.05320419e+02  1.04527626e+02]\n",
      " [ 3.30296631e+01  4.39014721e+00  1.04430855e+02  1.06001389e+02]\n",
      " [ 3.45859032e+01  4.45612335e+00  1.03601128e+02  1.04364761e+02]\n",
      " [ 3.44958267e+01  1.78335524e+00  1.01969788e+02  1.08796402e+02]\n",
      " [ 3.47923317e+01  5.68428898e+00  1.06541252e+02  1.05916046e+02]\n",
      " [ 3.37403069e+01  6.07359695e+00  1.04811440e+02  1.05753159e+02]\n",
      " [ 3.64121704e+01  6.93603992e+00  1.05863731e+02  1.06317902e+02]\n",
      " [ 3.43168335e+01  6.67465878e+00  1.03255096e+02  1.04195427e+02]\n",
      " [ 3.68792229e+01  5.77796602e+00  1.06080582e+02  1.03612869e+02]\n",
      " [ 3.49584312e+01  3.64277697e+00  1.04238945e+02  1.06420914e+02]\n",
      " [ 3.48301239e+01  2.99376678e+00  1.03510002e+02  1.10180519e+02]\n",
      " [ 3.58522949e+01  6.07449484e+00  1.07503281e+02  1.08157104e+02]\n",
      " [ 3.40440826e+01  5.42199326e+00  1.04830910e+02  1.06871262e+02]\n",
      " [ 3.53797760e+01  3.17262936e+00  1.05661530e+02  1.02640045e+02]\n",
      " [ 3.56035919e+01  4.83155251e+00  1.06637711e+02  1.08812088e+02]\n",
      " [ 3.26192055e+01  1.42973232e+00  1.00835411e+02  1.11556381e+02]\n",
      " [ 3.67300644e+01  2.62395191e+00  1.05387886e+02  1.10110535e+02]\n",
      " [ 3.19038372e+01 -4.77247238e-01  1.04599136e+02  1.07707748e+02]\n",
      " [ 3.26717300e+01  1.14106083e+00  1.01113258e+02  1.07540253e+02]\n",
      " [ 3.32006149e+01  9.38322544e-01  1.06627556e+02  1.06678116e+02]\n",
      " [ 3.27250824e+01 -7.48949051e-02  1.07352890e+02  1.07067810e+02]\n",
      " [ 3.42481918e+01  6.30848885e+00  1.08182076e+02  1.09488716e+02]\n",
      " [ 3.43245621e+01  4.29000807e+00  1.08750549e+02  1.07280708e+02]\n",
      " [ 3.24910011e+01  4.91011906e+00  1.06669250e+02  1.06855263e+02]\n",
      " [ 3.33182106e+01  1.12828655e+01  1.01846764e+02  1.07879692e+02]\n",
      " [ 2.92847862e+01  8.22979450e-01  1.00758514e+02  1.08026611e+02]\n",
      " [ 2.75263634e+01  3.21911573e+00  9.54121475e+01  1.01467117e+02]\n",
      " [ 3.01787415e+01  9.14941788e+00  9.70144806e+01  1.01999168e+02]\n",
      " [ 2.82866058e+01  4.88253832e+00  1.03894325e+02  1.04996719e+02]\n",
      " [ 3.92650642e+01  1.30903893e+01  1.09127678e+02  1.09893600e+02]\n",
      " [ 3.68630219e+01 -1.65139627e+00  1.07258247e+02  1.07720459e+02]\n",
      " [ 2.78531685e+01 -4.43829918e+00  9.81503296e+01  1.07362366e+02]\n",
      " [ 3.43607635e+01 -5.53766346e+00  1.07316277e+02  1.09461792e+02]] (42, 4)\n",
      "\n",
      "[0.9947641  0.9928711  0.98861593 0.9658361  0.93193203 0.9280145\n",
      " 0.90338665 0.90246606 0.89535046 0.89172316 0.8909492  0.87355155\n",
      " 0.85826385 0.85691726 0.8563602  0.8514676  0.83820516 0.82489794\n",
      " 0.79546094 0.7859709  0.7807874  0.7667914  0.7449469  0.72900134\n",
      " 0.66893584 0.63729805 0.29353222 0.27736065 0.25842875 0.2518103\n",
      " 0.23794548 0.21470451 0.15851285 0.08684881 0.08224431 0.05825108\n",
      " 0.04685271 0.04486496 0.04282844 0.03058835 0.02561081 0.02512033] (42,)\n",
      "Tensor in gpu\n",
      "Total time: 3.7879\n"
     ]
    }
   ],
   "source": [
    "# Testing folder\n",
    "test_folder = \"test/\"\n",
    "files = os.listdir(test_folder)\n",
    "images = [file_name for file_name in files if not file_name.startswith('.')]\n",
    "num_images = len(images)\n",
    "\n",
    "print(\"Number of images: \", num_images)\n",
    "\n",
    "t_tic = time.time()\n",
    "\n",
    "net, cfg, device = detection_model()\n",
    "\n",
    "for i, img_name in enumerate(images):\n",
    "    image_path = os.path.join(test_folder, img_name)\n",
    "    img_raw = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    img_raw_rgb = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    img = np.float32(img_raw_rgb)\n",
    "    print(\"test\", img, img.shape)\n",
    "    cropped_face_tensor = face_detection(net, cfg, device, img, img_name)\n",
    "    #print(cropped_face_tensor.is_cuda())\n",
    "    \n",
    "    if cropped_face_tensor.is_cuda: print(\"Tensor in gpu\")\n",
    "print('Total time: {:.4f}'.format(time.time() - t_tic))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1754b525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
